{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CatFlow","text":"<p>Part of Analyzer is published here and Tasker is to be open.</p> <p> </p> <p>Machine learning aided catalysis reaction free energy calculation and post-analysis workflow, thus, analyzer for catalysis.</p> <p>As is known to all, cat is fluid and thus cat flows. \ud83d\udc31</p> <p>Former Miko-Analyzer</p>"},{"location":"#installation","title":"Installation","text":"<p>To install, clone the repository:</p> <pre><code>git clone https://github.com/cloudac7/catflow.git\n</code></pre> <p>and then install with <code>pip</code>:</p> <pre><code>cd catflow\npip install .\n</code></pre>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This project is inspired by and built upon the following projects: - ai2-kit: A toolkit featured artificial intelligence \u00d7 ab initio for computational chemistry research. - DP-GEN: A concurrent learning platform for the generation of reliable deep learning based potential energy models. - ASE: Atomic Simulation Environment. - DPDispatcher: Generate and submit HPC jobs. - Metadynminer: Reading, analysis and visualization of metadynamics HILLS files produced by Plumed. As well as its Python implementation Metadynminer.py. - stringmethod: Python implementation of the string method to compute the minimum energy path.</p>"},{"location":"#usage","title":"Usage","text":"<p>Please refer to Usage.</p>"},{"location":"gen_ref/","title":"Gen ref","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"catflow\").glob(\"**/*.py\")):\n    module_path = path.relative_to(\".\").with_suffix(\"\")\n    doc_path = path.relative_to(\".\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = list(module_path.parts)\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n    nav_parts = list(parts)\n    nav[nav_parts] = doc_path\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        print(\"::: \" + ident, file=fd)\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, path)\n</pre> for path in sorted(Path(\"catflow\").glob(\"**/*.py\")):     module_path = path.relative_to(\".\").with_suffix(\"\")     doc_path = path.relative_to(\".\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = list(module_path.parts)     if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue     nav_parts = list(parts)     nav[nav_parts] = doc_path      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         print(\"::: \" + ident, file=fd)      mkdocs_gen_files.set_edit_path(full_doc_path, path) <p>add pages manually: nav[\"package\", \"module\"] = \"path/to/file.md\"</p> In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"Usage/","title":"\u4f7f\u7528\u8bf4\u660e","text":"<p>\u672c\u8f6f\u4ef6\u5305\u542b\u4e86\u4e00\u4e9b\u53ef\u80fd\u6709\u7528\u7684\u5206\u6790\u6a21\u5757\uff0c\u5177\u4f53\u4f7f\u7528\u8bf4\u660e\u5982\u4e0b\uff1a</p> <ul> <li>\u56e2\u7c07\u7ed3\u6784\u5206\u6790</li> <li>DP-GEN\u5206\u6790</li> <li>Metadynamics\u5206\u6790</li> </ul>"},{"location":"Usage/cluster_structures/","title":"\u56e2\u7c07\u7ed3\u6784\u5206\u6790","text":""},{"location":"Usage/cluster_structures/#_2","title":"\u8f7d\u5165\u56e2\u7c07\u7ed3\u6784","text":"<p>\u9996\u5148\u5c06\u9700\u8981\u5206\u6790\u7684\u56e2\u7c07\u8f68\u8ff9\u6587\u4ef6\u8bfb\u5165\u5230\u7a0b\u5e8f\u4e2d\uff0c\u7528\u6237\u53ef\u4ee5\u6307\u5b9a <code>path</code> \u53c2\u6570\u4e3a\u6587\u4ef6\u8def\u5f84\uff0c \u5176\u4ed6\u7684\u53c2\u6570\u8bf7\u4ee5\u53ef\u9009\u53c2\u6570\u5f62\u5f0f\u4f20\u5165\u3002</p> <pre><code>from catflow.structure.cluster import Cluster\n\ntrajfile = \"./dump.lammpstrj\"\nc = Cluster(trajfile, topology_format=\"LAMMPSDUMP\", dt=0.0005)\n</code></pre> <p>\u63d0\u793a</p> <p>\u6ce8\u610f\u9ed8\u8ba4\u7684\u683c\u5f0f\u4e3a\"XYZ\"\uff0c\u5982\u9700\u8981\u5bfc\u5165\u5176\u4ed6\u683c\u5f0f\uff0c\u8bf7\u53c2\u8003 MDAnalysis\u6587\u6863\u3002</p> <p>\u6216\u5c06 MDAnalysis \u7684\u4e00\u4e2a <code>Universe</code> \u5b9e\u4f8b\u5bfc\u5165\uff1a</p> <pre><code>from MDAnalysis import Universe\nu = Universe(trajfile, topology_format=\"LAMMPSDUMP\", dt=0.0005))\nd = Cluster.convert_universe(u)\n</code></pre>"},{"location":"Usage/cluster_structures/#lindemann-index","title":"Lindemann Index \u8ba1\u7b97","text":"<p>\u4e3a\u5206\u6790\u4f53\u7cfb\u7684\u76f8\u53d8\u6027\u8d28\uff0cLindemann\u7b49\u4eba[1]\u63d0\u51fa\u4e86\u5bf9\u7ed3\u6784\u968f\u65f6\u95f4\u5747\u65b9\u952e\u957f\u7684\u6f14\u53d8\u8fdb\u884c\u5206\u6790\u6765\u786e\u5b9a\u76f8\u53d8\u6027\u8d28\u7684\u65b9\u6cd5\uff0c \u4e00\u822c\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a</p> \\[&lt; q_i &gt;_{atoms} = \\frac{1}{N(N-1)} \\frac{\\sqrt{&lt;r^2_{ij}&gt; - &lt;r_{ij}&gt;^2}}{&lt;r_{ij}&gt;}\\] <p>\u8fd9\u91cc\u53c2\u7167 Welford \u7b97\u6cd5[2]\u8ba1\u7b97\u65b9\u5dee\uff0c\u7b80\u5355\u5b9e\u73b0\u4e86 Lindemann Index\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8c03\u7528\u5982\u4e0b\uff1a</p> <pre><code>lpf = c.lindemann_per_frames(u, select_lang=\"name Pt\")\n</code></pre> <p>\u5373\u53ef\u5f97\u5230\u5173\u4e8e\u6574\u6761\u8f68\u8ff9Lindemann index\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u5bf9 <code>lpf</code> \u4f5c\u56fe\uff0c\u53ef\u4ee5\u5e2e\u52a9\u5224\u65ad\u76f8\u53d8\u60c5\u51b5\u4ee5\u53ca\u786e\u5b9aMD\u662f\u5426\u6536\u655b\u3002</p> <p>\u6ce8\u610f\u8fd9\u91cc <code>lindemann_per_frames</code> \u8bfb\u5165\u7684\u662fMDAnalysis\u4e2d\u7684Universe\u5bf9\u8c61\uff0c\u901a\u5e38\u7528 <code>select_lang</code> \u6765\u6307\u5b9a\u9700\u8981\u5bf9\u54ea\u4e9b\u539f\u5b50\u8fdb\u884c\u5206\u6790\uff0c \u5373\u7ed9\u5b9a\u5bf9\u5e94\u7684Atom selection language\u6765\u9009\u53d6\uff0c \u8bf7\u53c2\u8003\u5b98\u65b9\u6587\u6863\u7684\u8bf4\u660e\u3002</p>"},{"location":"Usage/cluster_structures/#_3","title":"\u62df\u5408","text":"<p>\u4e3a\u5bf9\u56e2\u7c07\u76f8\u53d8\u884c\u4e3a\u7684\u6e29\u5ea6\u4f9d\u8d56\u8fdb\u884c\u5206\u6790\uff0c\u5e38\u5bf9\u5f97\u5230\u7684\u66f2\u7ebf\u8fdb\u884c\u62df\u5408\uff0c\u53ef\u4ee5\u91c7\u7528\u5982\u4e0b\u51fd\u6570\uff0c\u4ee5dataframe\u5f62\u5f0f\u8f93\u51fa\u62df\u5408\u7684\u66f2\u7ebf\uff1a</p> <pre><code>import numpy as np\n\ntemperature = np.array([300., 400., 500., 600., 700.])\nlindemann = np.array([0.05, 0.10, 0.20, 0.25, 0.32])\nbounds = ([-np.inf, -np.inf, -np.inf, -np.inf, 400, 15.], \n          [np.inf, np.inf, np.inf, np.inf, 700., 100.])\ndf = fitting_lindemann_curve(temperature, lindemann, bounds, function='func2')\n</code></pre> <p>\u5176\u4e2d\uff0c</p> <ul> <li><code>func1</code>\u51fd\u6570\u5f62\u5f0f\u4e3a\uff1a   $$ f(x) = b + (a - b) x + \\frac{d}{1 + \\exp({\\frac{x - x_0}{\\mathrm{d}x})}} + cx $$</li> <li><code>func2</code>\u51fd\u6570\u5f62\u5f0f\u4e3a   $$ f(x) = \\frac{ax+b}{1 + \\exp({\\frac{x - x_0}{\\mathrm{d}x})}} + \\frac{cx+d}{1 + \\exp({\\frac{x_0 - x}{\\mathrm{d}x})}}$$</li> </ul> <p>\u9ed8\u8ba4\u91c7\u7528 <code>func2</code> \u8fdb\u884c\u62df\u5408\uff0c<code>bounds</code>\u4e2d\u4e0a\u4e0b\u754c\u7684\u53c2\u6570\u5bf9\u5e94\u5373\u4e3a<code>a, b, c, d, x0, dx</code>\u7684\u53d6\u503c\u8303\u56f4\u3002</p>"},{"location":"Usage/cluster_structures/#references","title":"References","text":"<p>[1] F. A. Lindemann, Zeitschrift f\u00fcr, Phys. 1910, 11, 609\u2013612.</p> <p>[2] Donald E. Knuth, The art of computer programming, volume 2 (3<sup>rd</sup> ed.): seminumerical algorithms, Addison-Wesley Longman Publishing Co, 1997, 232.</p>"},{"location":"Usage/dpgen_analysis/","title":"\u5206\u6790DP-GEN\u4efb\u52a1","text":""},{"location":"Usage/dpgen_analysis/#_1","title":"\u52a0\u8f7d\u73af\u5883","text":"<p>\u9996\u5148\uff0c\u5bfc\u5165\u73af\u5883\uff1a</p> <pre><code>from catflow.tesla.dpgen import DPTask\n</code></pre> <p>\u52a0\u8f7dDP-GEN\u5de5\u4f5c\u76ee\u5f55\uff1a</p> <pre><code>t = DPTask(\n    path='/path/to/dpgen/', \n    param_file='param.json', \n    machine_file='machine.json',\n    record_file='record.dpgen'\n)\n</code></pre> <p>\u4fbf\u53ef\u6839\u636e\u6240\u9700\u5206\u6790\u7684\u90e8\u5206\uff0c\u5bf9\u8bad\u7ec3\u60c5\u51b5\u8fdb\u884c\u5206\u6790\u3002</p>"},{"location":"Usage/dpgen_analysis/#training","title":"\u8bad\u7ec3\uff08Training\uff09","text":"<p>\u5bfc\u5165\u5206\u6790\u5668\uff08<code>DPAnalyzer</code>\uff09\uff0c\u8fd9\u91cc\u6211\u4eec\u9009\u62e9\u8bad\u7ec3\uff0c\u5373\uff1a</p> <pre><code>from catflow.tesla.dpgen.training import DPTrainingAnalyzer\n</code></pre> <p>\u4ece\u4efb\u52a1\u521d\u59cb\u5316\u5206\u6790\u5668\u5b9e\u4f8b\uff1a</p> <pre><code>ana = DPTrainingAnalyzer(t)\n</code></pre> <p>\u5373\u53ef\u5229\u7528<code>ana</code>\u7684\u5185\u7f6e\u51fd\u6570\u8fdb\u884c\u4f5c\u56fe\uff1a</p> <pre><code>fig = ana.plot_lcurve(\n\u00a0\u00a0\u00a0\u00a0iteration=28, test=False, style='ticks', context='talk'\n)\nfig.set_size_inches((12,12))\n</code></pre> <p></p>"},{"location":"Usage/dpgen_analysis/#exploration","title":"\u63a2\u7d22\uff08Exploration\uff09","text":"<p>\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5bf9\u6a21\u578b\u7684model deviation\u5206\u5e03\u8fdb\u884c\u5206\u6790\uff1a</p> <pre><code>from catflow.tesla.dpgen.exploration import DPExplorationAnalyzer\nana = DPExplorationAnalyzer(t)\n</code></pre> <p>\u5229\u7528\u5206\u6790\u5668\u81ea\u5e26\u7684\u65b9\u6cd5\u8fdb\u884c\u4f5c\u56fe\uff1a</p> <pre><code>fig = ana.plot_single_iteration(\n    iteration=41, \n    temps=[400, 600, 800, 1000, 1200],\n    xlimit=1000000,\n    f_trust_lo=t.param_data['model_devi_f_trust_lo'],\n    f_trust_hi=t.param_data['model_devi_f_trust_hi'],\n    style='ticks',\n    group_by='temps',\n    label_unit='K',\n    context='talk'\n)\n</code></pre> <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p><code>iteration</code> \u5bf9\u5e94\u4e3a\u6240\u9700\u5206\u6790\u7684\u8f6e\u6570\uff0c\u9ed8\u8ba4\u4e3a\u6700\u65b0\u8fdb\u884c\u8fc7Exploartion\u7684\u8f6e\u6570\u3002</p> </li> <li> <p><code>f_trust_lo</code>\u548c<code>f_trust_hi</code>\u5373\u5bf9\u5e94\u7684\u6700\u5927\u529b\u504f\u5dee\u4e0a\u4e0b\u9650\u8bbe\u7f6e\u3002</p> </li> <li> <p>\u901a\u8fc7 <code>group_by</code> \u6307\u5b9a\u6240\u9700\u4f5c\u56fe\u7684\u53c2\u6570\uff0c\u5bf9\u5e94\u5230 <code>param.json</code> \u4e2d <code>model_devi_jobs</code> \u4e2d\u8be5\u8f6e\u6570\u9700\u8981\u8fed\u4ee3\u7684List\uff0c\u4f8b\u5982\uff1a</p> </li> </ul> <pre><code>  {\n      \"template\": {\n          \"lmp\": \"lmp/input-meta.lammps\",\n          \"plm\": \"lmp/input-meta.plumed\"\n      },\n      \"sys_idx\": [\n          53\n      ],\n      \"traj_freq\": 1000,\n      \"rev_mat\": {\n          \"lmp\": {\n              \"V_NSTEPS\": [\n                  1000000\n              ],\n              \"V_TEMP\": [\n                  400,\n                  600,\n                  800,\n                  1000,\n                  1200\n              ]\n          }\n      },\n      \"model_devi_f_trust_lo\": 0.23,\n      \"model_devi_f_trust_hi\": 0.75\n  }\n</code></pre> <p>\u82e5\u6307\u5b9a<code>group_by</code> \u53c2\u6570\u4e3a <code>V_TEMP</code>\uff0c\u5219\u6839\u636e\u8be5\u8f6e\u7684\u70ed\u6d74\u6e29\u5ea6\u5206\u7ec4\u4f5c\u56fe\uff0c\u82e5\u6307\u5b9a<code>V_TEMP=[400, 600, 800, 1000, 1200]</code>\uff0c\u5219\u53ef\u7531400\u3001600\u3001800\u30011000\u30011200K\u5206\u522b\u5bf9model deviation\u4f5c\u56fe\u3002</p> <ul> <li><code>label_unit</code> \u5373 <code>group_by</code> \u53c2\u6570\u7684\u5355\u4f4d\uff0c\u4f8b\u5982\u8fd9\u91cc\u662f\u6e29\u5ea6\uff0c\u6545\u4e3a\"K\"\u3002</li> </ul> <p>\u6548\u679c\u5982\u4e0b\uff1a</p> <p></p>"},{"location":"Usage/metadyn/","title":"Metadynamics \u5206\u6790","text":"In\u00a0[2]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[3]: Copied! <pre>from catflow.metad.hills import Hills\n</pre> from catflow.metad.hills import Hills In\u00a0[4]: Copied! <pre>#load hills\nh1 = Hills(name=\"../../tests/metad/data/hills/acealanme1d\", periodic=[True], cv_per=[[-np.pi, np.pi]])\nh2 = Hills(name=\"../../tests/metad/data/hills/acealanme\", periodic=[True,True], cv_per=[[-np.pi, np.pi], [-np.pi, np.pi]])\nh3 = Hills(name=\"../../tests/metad/data/hills/acealanme3d\", periodic=[True,True,True], cv_per=[[-np.pi, np.pi], [-np.pi, np.pi], [-np.pi, np.pi]])\n</pre> #load hills h1 = Hills(name=\"../../tests/metad/data/hills/acealanme1d\", periodic=[True], cv_per=[[-np.pi, np.pi]]) h2 = Hills(name=\"../../tests/metad/data/hills/acealanme\", periodic=[True,True], cv_per=[[-np.pi, np.pi], [-np.pi, np.pi]]) h3 = Hills(name=\"../../tests/metad/data/hills/acealanme3d\", periodic=[True,True,True], cv_per=[[-np.pi, np.pi], [-np.pi, np.pi], [-np.pi, np.pi]]) <p>For example, here we just use the fast approach to draw the FES of <code>acealanme</code> (with 2 CVs).</p> In\u00a0[5]: Copied! <pre>from catflow.metad.fes import FreeEnergySurface\n\n# do sum_hills\nfes = FreeEnergySurface.from_hills(h2, resolution=256)\n</pre> from catflow.metad.fes import FreeEnergySurface  # do sum_hills fes = FreeEnergySurface.from_hills(h2, resolution=256) <p>For here, there are two approaches. One is the <code>fast</code> approach, quickly do the sum in lack of accuracy. The other is the <code>original</code> approach, just do the same as <code>plumed sum_hills</code> command. Here, we use the original method with 4 workers to accelerate the build of FES.</p> In\u00a0[6]: Copied! <pre>fes.make_fes_original(resolution=256, n_workers=4)\n# plot the FES\nfes.plot(cmap=\"RdYlBu_r\", levels=20, dpi=96, style='ticks', context='talk')\n</pre> fes.make_fes_original(resolution=256, n_workers=4) # plot the FES fes.plot(cmap=\"RdYlBu_r\", levels=20, dpi=96, style='ticks', context='talk') Out[6]: <pre>(&lt;Figure size 960x672 with 2 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='CV2 - psi'&gt;)</pre> In\u00a0[6]: Copied! <pre># do sum_hills\nfes2 = fes.remove_cvs([1])\n</pre> # do sum_hills fes2 = fes.remove_cvs([1]) <pre>2023-07-13 21:58:53,381 - INFO : Removing CV 1.\n</pre> In\u00a0[7]: Copied! <pre># plot the FES\nfes2.plot(cmap=\"RdYlBu\", levels=20, dpi=96, style='ticks', context='talk')\n</pre> # plot the FES fes2.plot(cmap=\"RdYlBu\", levels=20, dpi=96, style='ticks', context='talk') Out[7]: <pre>(&lt;Figure size 960x672 with 1 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='Free Energy (kJ/mol)'&gt;)</pre> <p>Compared with FES from <code>h1</code>, we could see similar trend.</p> In\u00a0[8]: Copied! <pre># do sum_hills\nfes_1d = FreeEnergySurface.from_hills(h1, resolution=256)\n</pre> # do sum_hills fes_1d = FreeEnergySurface.from_hills(h1, resolution=256) In\u00a0[9]: Copied! <pre>fes_1d.make_fes_original(resolution=256, n_workers=4)\n# plot the FES\nfes_1d.plot(cmap=\"RdYlBu\", levels=20, dpi=96, style='ticks', context='talk')\n</pre> fes_1d.make_fes_original(resolution=256, n_workers=4) # plot the FES fes_1d.plot(cmap=\"RdYlBu\", levels=20, dpi=96, style='ticks', context='talk') Out[9]: <pre>(&lt;Figure size 960x672 with 1 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='Free Energy (kJ/mol)'&gt;)</pre> In\u00a0[6]: Copied! <pre>fes.find_minima()\n\n# plot the minimas\nfes.plot_minima(mark_color=\"white\", png_name=None, style='ticks', context='notebook')\n</pre> fes.find_minima()  # plot the minimas fes.plot_minima(mark_color=\"white\", png_name=None, style='ticks', context='notebook') Out[6]: <pre>(&lt;Figure size 960x672 with 2 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='CV2 - psi'&gt;)</pre> <p>Local minima are stored in <code>pandas.DataFrame</code>, as shown in below.</p> In\u00a0[11]: Copied! <pre>fes.minima\n</pre> fes.minima Out[11]: Minimum free energy CV1bin CV2bin CV1 - phi CV2 - psi 0 0 0.000000 78.0 236.0 -1.214913 2.662991 1 1 1.635963 27.0 240.0 -2.466641 2.761165 2 2 2.670061 74.0 117.0 -1.313088 -0.257709 3 3 5.255746 166.0 150.0 0.944932 0.552233 4 4 12.537359 170.0 251.0 1.043107 3.031146 In\u00a0[12]: Copied! <pre>from catflow.metad.profile import FreeEnergyProfile\nfe_profile = FreeEnergyProfile(fes, h2)\nfe_profile.plot(energy_unit=\"kJ/mol\", cmap=\"viridis\", style='ticks', context='notebook')\n</pre> from catflow.metad.profile import FreeEnergyProfile fe_profile = FreeEnergyProfile(fes, h2) fe_profile.plot(energy_unit=\"kJ/mol\", cmap=\"viridis\", style='ticks', context='notebook') In\u00a0[46]: Copied! <pre>#from catflow.metad.string import StringMethod\ns = StringMethod(fes)\n</pre> #from catflow.metad.string import StringMethod s = StringMethod(fes) <p>Load the minima from the upper block.</p> In\u00a0[47]: Copied! <pre>s.load_minima()\n</pre> s.load_minima() <pre>2023-07-14 12:17:02,456 - INFO :    Minimum  free energy  CV1bin  CV2bin  CV1 - phi  CV2 - psi\n0        0     0.000000    78.0   236.0  -1.214913   2.662991\n1        1     1.635963    27.0   240.0  -2.466641   2.761165\n2        2     2.670061    74.0   117.0  -1.313088  -0.257709\n3        3     5.255746   166.0   150.0   0.944932   0.552233\n4        4    12.537359   170.0   251.0   1.043107   3.031146\n</pre> <p>We just try the path from Minima 1 to 2, crossing 0.</p> In\u00a0[48]: Copied! <pre>s.mep_from_minima(begin_index=1, end_index=2, mid_indices=[0], maxsteps=200000)\n</pre> s.mep_from_minima(begin_index=1, end_index=2, mid_indices=[0], maxsteps=200000) <pre>2023-07-14 12:17:15,186 - INFO : Change in string: 0.0069036067\n2023-07-14 12:17:27,184 - INFO : Change in string: 0.0122908930\n2023-07-14 12:17:38,706 - INFO : Change in string: 0.0361591569\n2023-07-14 12:17:50,272 - INFO : Change in string: 0.0056718707\n2023-07-14 12:18:02,275 - INFO : Change in string: 0.0002050943\n2023-07-14 12:18:14,258 - INFO : Change in string: 0.0000045245\n2023-07-14 12:18:27,275 - INFO : Change in string: 0.0000006603\n2023-07-14 12:18:39,405 - INFO : Change in string: 0.0000002474\n2023-07-14 12:18:51,680 - INFO : Change in string: 0.0000000967\n2023-07-14 12:19:03,603 - INFO : Change in string: 0.0000000379\n2023-07-14 12:19:15,659 - INFO : Change in string: 0.0000000148\n2023-07-14 12:19:21,624 - INFO : Change in string lower than tolerance.\n2023-07-14 12:19:21,625 - INFO : Converged in 116 steps.\n</pre> <p>It took 116 iterations for the string to be converged. We could also use the fourth-order Runge-Kutta method to solve the evolution of string.</p> In\u00a0[51]: Copied! <pre>s.mep_from_minima(begin_index=1, end_index=2, mid_indices=[0], maxsteps=200000, integrator=\"rk4\")\n</pre> s.mep_from_minima(begin_index=1, end_index=2, mid_indices=[0], maxsteps=200000, integrator=\"rk4\") <pre>2023-07-14 12:20:56,777 - INFO : Change in string: 0.0072241848\n2023-07-14 12:21:45,994 - INFO : Change in string: 0.0103739428\n2023-07-14 12:22:35,167 - INFO : Change in string: 0.0353083649\n2023-07-14 12:23:22,341 - INFO : Change in string: 0.0084581203\n2023-07-14 12:24:09,113 - INFO : Change in string: 0.0001819289\n2023-07-14 12:24:55,353 - INFO : Change in string: 0.0000021306\n2023-07-14 12:25:41,926 - INFO : Change in string: 0.0000004627\n2023-07-14 12:26:28,478 - INFO : Change in string: 0.0000001716\n2023-07-14 12:27:15,062 - INFO : Change in string: 0.0000000642\n2023-07-14 12:28:01,155 - INFO : Change in string: 0.0000000240\n2023-07-14 12:28:43,129 - INFO : Change in string lower than tolerance.\n2023-07-14 12:28:43,130 - INFO : Converged in 110 steps.\n</pre> <p>After 110 iteration, the string converged. It took more time than forward Euler method, while the former is more stable. We could plot its evolution:</p> In\u00a0[49]: Copied! <pre>s.plot_string_evolution(cmap=\"RdYlBu_r\", levels=20, dpi=96)\n</pre> s.plot_string_evolution(cmap=\"RdYlBu_r\", levels=20, dpi=96) Out[49]: <pre>(&lt;Figure size 960x672 with 2 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='CV2 - psi'&gt;)</pre> <p>And draw the final MEP on the plot:</p> In\u00a0[50]: Copied! <pre>s.plot_mep(cmap=\"RdYlBu_r\", levels=20, dpi=96)\n</pre> s.plot_mep(cmap=\"RdYlBu_r\", levels=20, dpi=96) Out[50]: <pre>(&lt;Figure size 960x672 with 2 Axes&gt;,\n &lt;Axes: xlabel='CV1 - phi', ylabel='CV2 - psi'&gt;)</pre> <p>Last but not least, the free energy profile of the MEP:</p> In\u00a0[11]: Copied! <pre>s.plot_mep_energy_profile(dpi=96)\n</pre> s.plot_mep_energy_profile(dpi=96) Out[11]: <pre>(&lt;Figure size 614.4x460.8 with 1 Axes&gt;,\n &lt;Axes: xlabel='Reaction coordinate', ylabel='Free Energy (kJ/mol)'&gt;)</pre>"},{"location":"Usage/metadyn/#metadynamics","title":"Metadynamics \u5206\u6790\u00b6","text":""},{"location":"Usage/metadyn/#load-environment","title":"Load Environment\u00b6","text":"<p>First, load necessary modules to be load in the following steps.</p>"},{"location":"Usage/metadyn/#load-hills","title":"Load Hills\u00b6","text":"<p>We could load hills from <code>HILLS</code> produced by Plumed, to do more analysis. Here, we just use the examples provided by V. Spiwok, which is trajectories of Alanine Dipeptide in water with 1, 2 or 3 Ramachandran angles, respectively.</p>"},{"location":"Usage/metadyn/#sum-hills-using-fes","title":"Sum Hills using <code>Fes</code>\u00b6","text":"<p>We could just use <code>metadynminer.fes</code> to sum the hills to get the Free Energy Surface (FES).</p>"},{"location":"Usage/metadyn/#remove-cvs","title":"Remove CVs\u00b6","text":"<p>You could use <code>fes.remove_cv(cv_index)</code> or <code>fes.remove_cvs([cv_index_0, cv_index_1])</code> to remove CV(s) from the built FES, to plot the relationship between one or two CVs and free energy surface.</p>"},{"location":"Usage/metadyn/#find-local-minima","title":"Find local minima\u00b6","text":"<p>We could then use <code>fes.find_minima</code> to analyze the FES acquired, and to label them in the plot.</p>"},{"location":"Usage/metadyn/#free-energy-time-dependent-profile","title":"Free Energy Time-dependent Profile\u00b6","text":"<p>We could draw the time-dependent profile of free energies of local minima from <code>FEProfile</code>.</p>"},{"location":"Usage/metadyn/#using-string-method-to-find-minimal-energy-path-mep","title":"Using String Method to Find Minimal Energy Path (MEP)\u00b6","text":"<p>We could use string method to find MEP on the plotted FEP.</p> <p>Reference: Weinan E, et al. \"Simplified and improved string method for computing the minimum energy paths in barrier-crossing events\", J. Chem. Phys. 126, 164103 (2007), https://doi.org/10.1063/1.2720838</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>catflow<ul> <li>atomic<ul> <li>atomic_energy</li> <li>utils</li> </ul> </li> <li>cmdline<ul> <li>base</li> </ul> </li> <li>graph<ul> <li>plotting</li> </ul> </li> <li>metad<ul> <li>fes</li> <li>hills</li> <li>profile</li> <li>string</li> </ul> </li> <li>structure<ul> <li>cluster</li> <li>coordination_number</li> <li>dynamic_selection</li> <li>lindemann_index</li> </ul> </li> <li>tesla<ul> <li>ai2_kit<ul> <li>exploration</li> <li>labeling</li> <li>task</li> <li>training</li> </ul> </li> <li>base<ul> <li>exploration</li> <li>labeling</li> <li>task</li> <li>training</li> </ul> </li> <li>dpgen<ul> <li>exploration</li> <li>labeling</li> <li>task</li> <li>training</li> </ul> </li> </ul> </li> <li>utils<ul> <li>files</li> <li>lammps</li> <li>log_factory</li> <li>output</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/catflow/","title":"catflow","text":""},{"location":"reference/catflow/atomic/","title":"atomic","text":""},{"location":"reference/catflow/atomic/atomic_energy/","title":"atomic_energy","text":""},{"location":"reference/catflow/atomic/atomic_energy/#catflow.atomic.atomic_energy.atomic_ener_model_devi_atomic","title":"<code>atomic_ener_model_devi_atomic(*files, key_name, **kwargs)</code>","text":"<p>Calculate the deviation of atomic energy from a model.</p> Source code in <code>catflow/atomic/atomic_energy.py</code> <pre><code>def atomic_ener_model_devi_atomic(*files, key_name, **kwargs):\n    \"\"\"Calculate the deviation of atomic energy from a model.\"\"\"\n\n    def _atomic_ener_model_devi(f, key_name, **kwargs):\n        reader = load_reader(f, **kwargs)\n        results = reader.read_atomic_property()\n        return results[key_name]\n\n    results = Parallel(n_jobs=-1, verbose=5)(\n        delayed(_atomic_ener_model_devi)(f, key_name, **kwargs) for f in files\n    ) \n    results = np.array(results)\n\n    return np.std(results, axis=0)\n</code></pre>"},{"location":"reference/catflow/atomic/utils/","title":"utils","text":""},{"location":"reference/catflow/atomic/utils/#catflow.atomic.utils.AtomicPropertyReader","title":"<code>AtomicPropertyReader</code>","text":"<p>A class for reading atomic properties from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the file to be read.</p> required <code>format</code> <code>str</code> <p>The format of the file. Defaults to \"lammps-dump\".</p> <code>'lammps-dump'</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the specified format is not implemented.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>The path to the file to be read.</p> <code>format</code> <code>str</code> <p>The format of the file.</p> Source code in <code>catflow/atomic/utils.py</code> <pre><code>class AtomicPropertyReader:\n    \"\"\"\n    A class for reading atomic properties from a file.\n\n    Args:\n        path (str): The path to the file to be read.\n        format (str, optional): The format of the file. Defaults to \"lammps-dump\".\n\n    Raises:\n        NotImplementedError: If the specified format is not implemented.\n\n    Attributes:\n        path (str): The path to the file to be read.\n        format (str): The format of the file.\n    \"\"\"\n\n    def __init__(self, path, format=\"lammps-dump\"):\n        self.path = path\n        self.format = format\n\n    def read_atomic_property(self):\n        pass\n</code></pre>"},{"location":"reference/catflow/atomic/utils/#catflow.atomic.utils.LAMMPSDumpReader","title":"<code>LAMMPSDumpReader</code>","text":"<p>             Bases: <code>AtomicPropertyReader</code></p> <p>A class for reading atomic properties from LAMMPS dump files.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>The path to the LAMMPS dump file.</p> <p>Methods:</p> Name Description <code>read_atomic_property</code> <p>Reads all frames from the LAMMPS dump file and returns the atomic properties.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If results keys do not match atomic properties in file.</p> Source code in <code>catflow/atomic/utils.py</code> <pre><code>class LAMMPSDumpReader(AtomicPropertyReader):\n    \"\"\"\n    A class for reading atomic properties from LAMMPS dump files.\n\n    Attributes:\n        path (str): The path to the LAMMPS dump file.\n\n    Methods:\n        read_atomic_property(): Reads all frames from the LAMMPS dump file and returns the atomic properties.\n\n    Raises:\n        ValueError: If results keys do not match atomic properties in file.\n    \"\"\"\n    def _read_single_frame(self, f, results=None):\n        \"\"\"\n        Reads a single frame from the LAMMPS dump file.\n\n        Args:\n            f (file): The file object to read from.\n            results (dict, optional): The dictionary to store the atomic properties. Defaults to None.\n\n        Returns:\n            bool: True if a frame is successfully read, False otherwise.\n        \"\"\"\n        if not f.readline():  # ITEM TIMESTEP\n            return False\n        f.readline()\n        f.readline()  # ITEM NUMBER OF ATOMS\n        n_atoms = int(f.readline())\n\n        # triclinic = len(f.readline().split()) == 9  # ITEM BOX BOUNDS\n        for _ in range(4):\n            f.readline()\n\n        indices = np.zeros(n_atoms, dtype=int)\n        atom_line = f.readline()  # ITEM ATOMS etc\n        attrs = atom_line.split()[2:]  # attributes on coordinate line\n        attr_to_col_ix = {x: i for i, x in enumerate(attrs)}\n\n        _has_atomic_properties = any(\"c_\" in ix for ix in attr_to_col_ix)\n        atomic_cols = [(ix, attr_to_col_ix[ix])\n                       for ix in attr_to_col_ix if \"c_\" in ix] if _has_atomic_properties else []\n        ids = \"id\" in attr_to_col_ix\n\n        if results is None:\n            results = {dim[0]: [] for dim in atomic_cols}\n        elif results == {}:\n            for dim in atomic_cols:\n                results[dim[0]] = []\n        elif results.keys() != set([dim[0] for dim in atomic_cols]):\n            raise ValueError(\n                \"Results keys do not match atomic properties in file\")\n\n        data = {dim[0]: np.zeros(n_atoms) for dim in atomic_cols}\n\n        for i in range(n_atoms):\n            fields = f.readline().split()\n            if ids:\n                indices[i] = fields[attr_to_col_ix[\"id\"]]\n            if _has_atomic_properties:\n                for dim in atomic_cols:\n                    data[dim[0]][i] = fields[dim[1]]\n        order = np.argsort(indices)\n        if _has_atomic_properties:\n            for dim in atomic_cols:\n                data[dim[0]] = data[dim[0]][order]\n                results[dim[0]].append(data[dim[0]])\n        return True\n\n    def read_atomic_property(self):\n        \"\"\"\n        Reads all frames from the LAMMPS dump file and returns the atomic properties.\n\n        Returns:\n            dict: A dictionary containing the atomic properties.\n        \"\"\"\n        with open(self.path) as f:\n            # Initialize results with empty lists for each atomic property\n            results = {}\n\n            # Read the rest of the frames\n            while self._read_single_frame(f, results):\n                continue\n\n        # Convert lists to ndarrays\n        for key in results:\n            results[key] = np.array(results[key])\n        return results\n</code></pre>"},{"location":"reference/catflow/atomic/utils/#catflow.atomic.utils.LAMMPSDumpReader.read_atomic_property","title":"<code>read_atomic_property()</code>","text":"<p>Reads all frames from the LAMMPS dump file and returns the atomic properties.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the atomic properties.</p> Source code in <code>catflow/atomic/utils.py</code> <pre><code>def read_atomic_property(self):\n    \"\"\"\n    Reads all frames from the LAMMPS dump file and returns the atomic properties.\n\n    Returns:\n        dict: A dictionary containing the atomic properties.\n    \"\"\"\n    with open(self.path) as f:\n        # Initialize results with empty lists for each atomic property\n        results = {}\n\n        # Read the rest of the frames\n        while self._read_single_frame(f, results):\n            continue\n\n    # Convert lists to ndarrays\n    for key in results:\n        results[key] = np.array(results[key])\n    return results\n</code></pre>"},{"location":"reference/catflow/atomic/utils/#catflow.atomic.utils.NetCDFReader","title":"<code>NetCDFReader</code>","text":"<p>             Bases: <code>AtomicPropertyReader</code></p> <p>A class for reading atomic properties from netCDF files.</p> Source code in <code>catflow/atomic/utils.py</code> <pre><code>class NetCDFReader(AtomicPropertyReader):\n    \"\"\"A class for reading atomic properties from netCDF files.\"\"\"\n\n    def read_atomic_property(self):\n        try:\n            from netCDF4 import Dataset  # type: ignore\n        except ImportError:\n            raise ImportError(\"netCDF4 is not installed\")\n\n        with Dataset(self.path, 'r') as data:\n            return {k: np.asarray(v) for k, v in data.variables.items() if \"c_\" in k}\n</code></pre>"},{"location":"reference/catflow/cmdline/","title":"cmdline","text":""},{"location":"reference/catflow/cmdline/base/","title":"base","text":""},{"location":"reference/catflow/graph/","title":"graph","text":""},{"location":"reference/catflow/graph/plotting/","title":"plotting","text":""},{"location":"reference/catflow/graph/plotting/#catflow.graph.plotting.canvas_style","title":"<code>canvas_style(context='notebook', style='ticks', palette='deep', font='sans-serif', font_scale=1.5, color_codes=True, rc=None, **kwargs)</code>","text":"<p>set basic properties for canvas</p> <p>:param context: select context of the plot. Please refer to seaborn contexts. :param style: select style of the plot. Please refer to seaborn styles. :param palette: Color palette, see color_palette() :param font: Font family, see matplotlib font manager. :param font_scale: Separate scaling factor to independently scale the size of the font elements. :param color_codes: If True and palette is a seaborn palette,     remap the shorthand color codes (e.g. \u201cb\u201d, \u201cg\u201d, \u201cr\u201d, etc.) to the colors from this palette. :param rc: rc dict to optimize the plot. Please refer to matplotlib document for description in detail.</p> Source code in <code>catflow/graph/plotting.py</code> <pre><code>def canvas_style(\n        context='notebook',\n        style='ticks',\n        palette='deep',\n        font='sans-serif',\n        font_scale=1.5,\n        color_codes=True,\n        rc=None,\n        **kwargs\n):\n    \"\"\"set basic properties for canvas\n\n    :param context: select context of the plot. Please refer to seaborn contexts.\n    :param style: select style of the plot. Please refer to seaborn styles.\n    :param palette: Color palette, see color_palette()\n    :param font: Font family, see matplotlib font manager.\n    :param font_scale: Separate scaling factor to independently scale the size of the font elements.\n    :param color_codes: If True and palette is a seaborn palette,\n        remap the shorthand color codes (e.g. \u201cb\u201d, \u201cg\u201d, \u201cr\u201d, etc.) to the colors from this palette.\n    :param rc: rc dict to optimize the plot. Please refer to matplotlib document for description in detail.\n    \"\"\"\n    sns.set_theme(\n        context=context,\n        style=style,\n        palette=palette,\n        font=font,\n        font_scale=font_scale,\n        color_codes=color_codes,\n        rc=rc\n    )\n    sns.set_style({\n        'font.sans-serif': 'DejaVu Sans, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif'\n        })\n</code></pre>"},{"location":"reference/catflow/metad/","title":"metad","text":""},{"location":"reference/catflow/metad/fes/","title":"fes","text":""},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface","title":"<code>FreeEnergySurface</code>","text":"<p>Computes the free energy surface corresponding to the provided Hills object.</p> <p>Usage: <pre><code>from catflow.metad.fes import FreeEnergySurface\nfes = FreeEnergySurface(hills)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>hills</code> <code>Hills</code> <p>The Hills object used for computing the free energy surface.</p> required <code>resolution</code> <code>int</code> <p>The resolution of the free energy surface. Defaults to 256.</p> <code>256</code> <code>time_min</code> <code>int</code> <p>The starting time step of simulation. Defaults to 0.</p> required <code>time_max</code> <code>int</code> <p>The ending time step of simulation. Defaults to None.</p> required Source code in <code>catflow/metad/fes.py</code> <pre><code>class FreeEnergySurface:\n    \"\"\"\n    Computes the free energy surface corresponding to the provided Hills object.\n\n    Usage:\n    ```python\n    from catflow.metad.fes import FreeEnergySurface\n    fes = FreeEnergySurface(hills)\n    ```\n\n    Args:\n        hills (Hills): The Hills object used for computing the free energy surface.\n        resolution (int, optional): \\\n            The resolution of the free energy surface. Defaults to 256.\n        time_min (int): The starting time step of simulation. Defaults to 0.\n        time_max (int, optional): The ending time step of simulation. Defaults to None.\n    \"\"\"\n\n    fes: np.ndarray\n    cvs: int\n    cv_min: np.ndarray\n    cv_max: np.ndarray\n    periodic: np.ndarray\n    resolution: int = 256\n    hills: Optional[Hills] = None\n    cv_fes_range: Optional[np.ndarray] = None\n    cv_name: Optional[List[str]] = None\n    minima: Optional[pd.DataFrame] = None\n\n    def __init__(\n        self,\n        resolution: int = 256\n    ):\n        self.res = resolution\n\n    @classmethod\n    def from_hills(\n        cls, \n        hills: Hills,\n        resolution: int = 256\n    ):\n        \"\"\"Generate a FES object from a Hills object.\"\"\"\n        fes = cls(resolution=resolution)\n\n        fes.cvs = hills.cvs\n\n        fes.hills = hills\n        fes.periodic = hills.periodic\n        fes.cv_name = hills.cv_name\n\n        fes.generate_cv_map()\n\n        return fes\n\n    def generate_cv_map(self):\n        \"\"\"generate CV map\"\"\"\n        if self.hills is not None:\n            cv_min = deepcopy(self.hills.cv_min)\n            cv_max = deepcopy(self.hills.cv_max)\n            cv_range = cv_max - cv_min\n            self.cv_range = cv_range\n\n            cv_min[~self.periodic] -= cv_range[~self.periodic] * 0.15\n            cv_max[~self.periodic] += cv_range[~self.periodic] * 0.15\n            cv_fes_range = np.abs(cv_max - cv_min)\n\n            # generate remapped cv_min and cv_max\n            self.cv_min = cv_min\n            self.cv_max = cv_max\n            self.cv_fes_range = cv_fes_range\n\n    @classmethod\n    def from_array(\n        cls,\n        fes_array: ArrayLike,\n        cv_min: ArrayLike,\n        cv_max: ArrayLike,\n        periodic: ArrayLike,\n        cv_name: List[str],\n        resolution: int = 256\n    ):\n        fes = cls(resolution=resolution)\n        fes.fes = np.array(fes_array)\n        fes.cv_min = np.array(cv_min)\n        fes.cv_max = np.array(cv_max)\n        fes.cv_fes_range = np.array(cv_max) - np.array(cv_min)\n        fes.periodic = np.array(periodic, dtype=bool)\n        fes.cv_name = cv_name\n        fes.res = resolution\n        fes.cvs = len(cv_name)\n        return fes\n\n    def name_cv(self):\n        if self.cv_name is None:\n            self.cv_name = []\n            for i in range(self.cvs):\n                self.cv_name.append(f\"CV{i+1}\")\n\n    def get_e_beta_c(\n        self,\n        resolution: Optional[int] = None,\n        time_min: Optional[int] = None,\n        time_max: Optional[int] = None,\n        kb: float = 8.314e-3,\n        temp: float = 300.0,\n        bias_factor: float = 15.0,\n        return_fes: bool = False\n    ):\n        \"\"\"Function used internally for summing hills in Hills object with the fast Bias Sum Algorithm. \n        From which could also be quick to get e_beta_c for reweighting.\n\n        Args:\n            resolution (int, optional): \\\n                The resolution of the free energy surface. Defaults to 256.\n            time_min (int): The starting time step of simulation. Defaults to 0.\n            time_max (int, optional): The ending time step of simulation. Defaults to None.\n            reweighting (bool, optional): \\\n                If True, the function of c(t) will be calculated and stored in `self.e_beta_c`.\n                Defaults to False.\n            kb (float, optional): The Boltzmann Constant in the energy unit. Defaults to 8.314e-3.\n            temp (float, optional): The temperature of the simulation in Kelvins. Defaults to 300.0.\n            bias_factor (float, optional): The bias factor used in the simulation. Defaults to 15.0.\n        \"\"\"\n\n        if resolution is None:\n            resolution = self.res\n\n        if self.hills is None:\n            raise ValueError(\"Hills not loaded yet.\")\n\n        if time_min is None:\n            time_min = 0\n\n        if time_max is None:\n            time_max = len(self.hills.cv[:, 0])\n\n        cvs = self.cvs\n\n        cv_min = self.cv_min\n        cv_max = self.cv_max\n        if self.cv_fes_range is None:\n            self.cv_fes_range = cv_max - cv_min\n        cv_fes_range = self.cv_fes_range\n\n        cv_bins = np.ceil(\n            (self.hills.cv[time_min:time_max, :cvs] -\n             cv_min) * resolution / cv_fes_range\n        ).T.astype(int)\n\n        sigma = self.hills.sigma[:cvs, 0]\n        sigma_res = (sigma * resolution) / (cv_max - cv_min)\n\n        gauss_res = (8 * sigma_res).astype(int)\n        for i, _ in enumerate(gauss_res):\n            if _ % 2 == 0:\n                gauss_res[i] += 1\n\n        gauss = self._gauss_kernel(gauss_res, sigma_res)\n        gauss_center = np.array(gauss.shape) // 2\n\n        fes = np.zeros([resolution] * cvs)\n        e_beta_c = np.zeros(len(cv_bins[0]))\n\n        for line in range(len(cv_bins[0])):\n            fes_index_to_edit, delta_fes = \\\n                self._sum_bias(\n                    gauss_center, gauss, cv_bins, line, cvs, resolution\n                )\n            fes[fes_index_to_edit] += delta_fes\n\n            local_fes = fes - np.min(fes)\n            exp_local_fes = np.exp(-local_fes / (kb * temp))\n\n            numerator = np.sum(exp_local_fes)\n            denominator = np.sum(exp_local_fes / bias_factor)\n            e_beta_c[line] = numerator / denominator\n        if return_fes:\n            fes -= np.min(fes)\n            return e_beta_c, fes\n        else:\n            return e_beta_c\n\n    def _gauss_kernel(self, gauss_res, sigma_res):\n\n        gauss_center = gauss_res // 2\n        grids = np.indices(gauss_res)\n\n        grids_flatten = grids.reshape(gauss_res.shape[0], -1).T\n        exponent = np.sum(\n            -(grids_flatten - gauss_center)**2 / (2 * sigma_res**2), \n            axis=1\n        )\n        gauss = -np.exp(exponent.T.reshape(gauss_res))\n        return gauss\n\n    def _sum_bias(\n        self, gauss_center, gauss, cv_bins, line, cvs, resolution\n    ):\n        if self.hills is None:\n            raise ValueError(\"Hills not loaded yet.\")\n\n        # create a meshgrid of the indexes of the fes that need to be edited\n        fes_index_to_edit = np.indices(gauss.shape)\n\n        # create a mask to avoid editing indexes outside the fes\n        local_mask = np.ones_like(gauss, dtype=int)\n        for d in range(cvs):\n            fes_index_to_edit[d] += cv_bins[d][line] - gauss_center[d]\n            if not self.periodic[d]:\n                mask = np.where(\n                    (fes_index_to_edit[d] &lt; 0) + (\n                        fes_index_to_edit[d] &gt; resolution - 1)\n                )[0]\n                # if the cv is not periodic, remove the indexes outside the fes\n                local_mask[mask] = 0\n            # make sure the indexes are inside the fes\n            fes_index_to_edit[d] = np.mod(fes_index_to_edit[d], resolution)\n        delta_fes = gauss * local_mask * self.hills.heights[line]\n        fes_index_to_edit = tuple(fes_index_to_edit)\n        return fes_index_to_edit, delta_fes\n\n    def reweighting(\n        self,\n        colvar_file: str,\n        e_beta_c: ArrayLike,\n        cv_indexes: Optional[List[int]] = None,\n        resolution: int = 64,\n        kb: float = 8.314e-3,\n        temp: float = 300.0\n    ):\n        \"\"\"\n        Reweights the free energy surface based on the given collective variables.\n\n        Args:\n            colvar_file (str): The path to the file containing the collective variables.\n            e_beta_c (ArrayLike): The array of e^(-beta*C(t)) values.\n            cv_indexes (Optional[List[int]], optional): The indexes of the collective variables to use. Defaults to None.\n            resolution (int, optional): The resolution of the free energy surface. Defaults to 64.\n            kb (float, optional): The Boltzmann constant. Defaults to 8.314e-3.\n            temp (float, optional): The temperature in Kelvin. Defaults to 300.0.\n\n        Returns:\n            np.ndarray: The reweighted free energy surface.\n        \"\"\"\n        colvar = np.loadtxt(colvar_file)\n\n        if cv_indexes is None:\n            cvs = self.cvs\n            colvar_value = colvar[:, 1:cvs+1]\n        else:\n            cvs = len(cv_indexes)\n            colvar_value = np.vstack(\n                [colvar[:, i + 1] for i in cv_indexes]\n            ).T\n        cv_array = colvar_value - np.min(colvar_value, axis=0)\n        cv_range = np.max(cv_array)\n        cv_array = np.floor((resolution - 1) * cv_array / cv_range).astype(int)\n\n        bias = colvar[:, 9]\n        probs = np.zeros([resolution] * cvs)\n\n        e_beta_c = np.array(e_beta_c)\n        reweighted_fes = np.zeros([len(e_beta_c)] + [resolution] * cvs)\n\n        for i in np.arange(len(e_beta_c)):\n            index = tuple(cv_array[i])\n            probs[index] += np.exp(bias[i]/(kb * temp)) / e_beta_c[i]\n            reweighted_fes[i] = -kb * temp * np.log(probs)\n\n        return reweighted_fes\n\n    def _calculate_dp2(self, index, time_min, time_max):\n        if self.hills is None:\n            raise ValueError(\"Hills not loaded yet.\")\n\n        cv_min = self.cv_min\n        if self.cv_fes_range is None:\n            self.cv_fes_range = self.cv_max - self.cv_min\n        cv_fes_range = self.cv_fes_range\n        cvs = self.cvs\n\n        dp2 = np.zeros(time_max - time_min)\n        for i, cv_idx in enumerate(range(cvs)):\n            dist_cv = \\\n                self.hills.cv[time_min:time_max, cv_idx] - \\\n                (cv_min[i] + index[i] * cv_fes_range[i] / self.res)\n            if self.periodic[cv_idx]:\n                dist_cv[dist_cv &lt; -0.5*cv_fes_range[i]] += cv_fes_range[i]\n                dist_cv[dist_cv &gt; +0.5*cv_fes_range[i]] -= cv_fes_range[i]\n            dp2_local = dist_cv ** 2 / \\\n                (2 * self.hills.sigma[cv_idx][0] ** 2)\n            dp2 += dp2_local\n\n        return dp2\n\n    def make_fes_original(\n        self,\n        resolution: Optional[int],\n        time_min: Optional[int] = None,\n        time_max: Optional[int] = None,\n        n_workers: int = 2\n    ):\n        \"\"\"\n        Function internally used to sum Hills in the same way as Plumed `sum_hills`. \n\n        Args:\n            resolution (int, optional): \\\n                The resolution of the free energy surface. Defaults to 256.\n            time_min (int): The starting time step of simulation. Defaults to 0.\n            time_max (int, optional): The ending time step of simulation. Defaults to None.\n            n_workers (int, optional): Number of workers for parallelization. Defaults to 2.\n        \"\"\"\n        if self.hills is None:\n            raise ValueError(\"Hills not loaded yet.\")\n\n        if resolution is None:\n            resolution = self.res\n\n        cvs = self.cvs\n        fes = np.zeros([resolution] * cvs)\n\n        if time_min is None:\n            time_min = 0\n        if time_max is None:\n            time_max = len(self.hills.cv[:, 0])\n        time_limit = time_max - time_min\n\n        def calculate_fes(index):\n            dp2 = self._calculate_dp2(index, time_min, time_max)\n\n            tmp = np.zeros(time_limit)\n            tmp[dp2 &lt; 6.25] = self.hills.heights[dp2 &lt; 6.25] * \\\n                (np.exp(-dp2[dp2 &lt; 6.25]) *\n                 1.00193418799744762399 - 0.00193418799744762399)\n            return index, -tmp.sum()\n\n        indices = list(np.ndindex(fes.shape))\n        results = Parallel(n_jobs=n_workers)(\n            delayed(calculate_fes)(index) for index in indices\n        )\n        if results is not None:\n            for index, value in results:\n                fes[index] = value\n            fes -= np.min(fes)\n        self.fes = fes\n        return fes\n\n    def remove_cv(\n        self,\n        CV: int,\n        kb: Optional[float] = None,\n        energy_unit: str = \"kJ/mol\",\n        temp: float = 300.0\n    ):\n        \"\"\"Remove a CV from an existing FES. \n        The function first recalculates the FES to an array of probabilities. \n        The probabilities are summed along the CV to be removed, \n        and resulting probability distribution with 1 less dimension \n        is converted back to FES. \n\n        Interactivity was working in jupyter notebook/lab with \"%matplotlib widget\".\n\n        Args:\n            CV (int): the index of CV to be removed. \n            energy_unit (str): has to be either \"kJ/mol\" or \"kcal/mol\". Defaults to be \"kJ/mol\".\n            kb (float, optional): the Boltzmann Constant in the energy unit. \\\n                Defaults to be None, which will be set according to energy_unit.\n            temp (float) = temperature of the simulation in Kelvins.\n\n        Return:\n            New `FES` instance without the CV to be removed.\n        \"\"\"\n\n        logger.info(f\"Removing CV {CV}.\")\n\n        if self.fes is None:\n            raise ValueError(\n                \"FES not calculated yet. Use makefes() or makefes2() first.\")\n\n        if CV &gt; self.hills.cvs:\n            raise ValueError(\n                \"Error: The CV to remove is not available in this FES object.\")\n\n        if kb == None:\n            if energy_unit == \"kJ/mol\":\n                kb = 8.314e-3\n            elif energy_unit == \"kcal/mol\":\n                kb = 8.314e-3 / 4.184\n            else:\n                raise ValueError(\n                    \"Please give the Boltzmann Constant in the energy unit.\")\n\n        if self.cvs == 1:\n            raise ValueError(\"Error: You can not remove the only CV. \")\n        else:\n            probabilities = np.exp(-self.fes / (kb * temp))\n            new_prob = np.sum(probabilities, axis=CV)\n\n            new_fes = FreeEnergySurface.from_hills(hills=self.hills)\n            new_fes.fes = - kb * temp * np.log(new_prob)\n            new_fes.fes = new_fes.fes - np.min(new_fes.fes)\n            new_fes.res = self.res\n\n            mask = np.ones(self.cvs, dtype=bool)\n            mask[CV] = False\n            new_fes.cv_min = self.cv_min[mask]\n            new_fes.cv_max = self.cv_max[mask]\n            new_fes.cv_fes_range = self.cv_fes_range[mask]\n            new_fes.cv_name = [\n                j for i, j in enumerate(self.cv_name) if mask[i]]\n            new_fes.cvs = self.cvs - 1\n            return new_fes\n\n    def remove_cvs(\n        self,\n        CVs: List[int],\n        kb: Optional[float] = None,\n        energy_unit: str = \"kJ/mol\",\n        temp: float = 300.0\n    ):\n        \"\"\"\n        Remove multiple collective variables (CVs) from the free energy surface (FES).\n\n        Args:\n            CVs (List[int]): The list of CVs to be removed.\n            kb (Optional[float], optional): The Boltzmann constant. Defaults to None.\n            energy_unit (str, optional): The unit of energy. Defaults to \"kJ/mol\".\n            temp (float, optional): The temperature in Kelvin. Defaults to 300.0.\n\n        Returns:\n            Fes: The new FES object with the specified CVs removed.\n        \"\"\"\n        fes = self.remove_cv(CVs[0], kb, energy_unit, temp)\n        if len(CVs) &gt; 1:\n            for CV in CVs[1:]:\n                if fes is not None:\n                    fes = fes.remove_cv(CV, kb, energy_unit, temp)\n        return fes\n\n    def set_fes(self, fes: np.ndarray):\n        self.fes = fes\n\n    def find_minima(self, nbins=8):\n        \"\"\"Method for finding local minima on FES.\n\n        Args:\n            fes (Fes): The Fes object to find the minima on.\n            nbins (int, default=8): The number of bins used to divide the FES.\n        \"\"\"\n        if self.fes is None:\n            raise ValueError(\n                \"FES not calculated yet. Use make_fes_original() first.\"\n            )\n\n        if self.minima is not None:\n            logger.warning(\"Minima already found.\")\n            return None\n\n        import pandas as pd\n\n        cv_min = self.cv_min\n        cv_max = self.cv_max\n\n        if int(nbins) != nbins:\n            nbins = int(nbins)\n            logger.info(\n                f\"Number of bins must be an integer, it will be set to {nbins}.\")\n        if self.res % nbins != 0:\n            raise ValueError(\"Resolution of FES must be divisible by number of bins.\")\n        if nbins &gt; self.res/2:\n            raise ValueError(\"Number of bins is too high.\")\n\n        bin_size = int(self.res/nbins)\n\n        for index in np.ndindex(tuple([nbins] * self.cvs)):\n            # index serve as bin number\n            _fes_slice = tuple(\n                slice(\n                    index[i] * bin_size, (index[i] + 1) * bin_size\n                ) for i in range(self.cvs)\n            )\n            fes_slice = self.fes[_fes_slice]\n            bin_min = np.min(fes_slice)\n\n            # indexes of global minimum of a bin\n            bin_min_arg = np.unravel_index(\n                np.argmin(fes_slice), fes_slice.shape\n            )\n            # indexes of that minima in the original fes (indexes +1)\n            min_cv_b = np.array([\n                bin_min_arg[i] + index[i] * bin_size for i in range(self.cvs)\n            ], dtype=int)\n\n            if (np.array(bin_min_arg, dtype=int) &gt; 0).all() and \\\n                    (np.array(bin_min_arg, dtype=int) &lt; bin_size - 1).all():\n                # if the minima is not on the edge of the bin\n                min_cv = (((min_cv_b+0.5)/self.res) * (cv_max-cv_min))+cv_min\n                local_minima = np.concatenate([\n                    [np.round(bin_min, 6)], min_cv_b, np.round(min_cv, 6)\n                ])\n                if self.minima is None:\n                    self.minima = local_minima\n                else:\n                    self.minima = np.vstack((self.minima, local_minima))\n            else:\n                # if the minima is on the edge of the bin\n                around = np.zeros(tuple([3] * self.cvs))\n\n                for product_index in product(*[range(3)] * self.cvs):\n                    converted_index = np.array(product_index, dtype=int) + \\\n                        np.array(min_cv_b, dtype=int) - 1\n                    converted_index[self.periodic] = \\\n                        converted_index[self.periodic] % self.res\n\n                    mask = np.where(\n                        (converted_index &lt; 0) + (converted_index &gt; self.res - 1)\n                    )[0]\n\n                    if len(mask) &gt; 0:\n                        around[product_index] = np.inf\n\n                    elif product_index == tuple([1] * self.cvs):\n                        around[product_index] = np.inf\n\n                    else:\n                        around[product_index] = self.fes[tuple(\n                            converted_index)]\n\n                if (around &gt; bin_min).all():\n                    min_cv = (((min_cv_b+0.5)/self.res) * (cv_max-cv_min))+cv_min\n                    local_minima = np.concatenate([\n                        [np.round(bin_min, 6)], min_cv_b, np.round(min_cv, 6)\n                    ])\n                    if self.minima is None:\n                        self.minima = local_minima\n                    else:\n                        self.minima = np.vstack((self.minima, local_minima))\n\n        if self.minima is None:\n            logger.warning(\"No minima found.\")\n            return None\n\n        if len(self.minima.shape) &gt; 1:\n            self.minima = self.minima[self.minima[:, 0].argsort()]\n\n        if self.minima.shape[0] == 1:\n            self.minima = np.concatenate((\n                np.arange(0, self.minima.shape[0], dtype=int), self.minima\n            ))\n        else:\n            self.minima = np.column_stack((\n                np.arange(0, self.minima.shape[0], dtype=int), self.minima\n            ))\n\n        if self.cv_name is None:\n            self.cv_name = [f\"CV{i+1}\" for i in range(self.cvs)]\n\n        minima_df = pd.DataFrame(\n            np.array(self.minima),\n            columns=[\"Minimum\", \"free energy\"] +\n            [f\"CV{i+1}bin\" for i in range(self.cvs)] +\n            [f\"CV{i+1} - {self.cv_name[i]}\" for i in range(self.cvs)]\n        )\n        minima_df[\"Minimum\"] = minima_df[\"Minimum\"].astype(int)\n        self.minima = minima_df\n\n    def plot(\n        self,\n        png_name: Optional[str] = None,\n        cmap: Union[str, Colormap] = \"RdYlBu_r\",\n        energy_unit: str = \"kJ/mol\",\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        image_size: List[int] = [10, 7],\n        levels: int = 20,\n        dpi: int = 96,\n        surface: bool = False,\n        surface_params: dict = {},\n        **kwargs\n    ):\n        \"\"\"\n        Visualizes the free energy surface (FES) using Matplotlib and PyVista.\n\n        Usage:\n        ```python\n        fes.plot()\n        ```\n\n        Args:\n            png_name (str, optional): If provided, the picture of FES will be saved under this name in the current working directory.\n            cmap (str, default=\"RdYlBu_r\"): The Matplotlib colormap used to color the 2D or 3D FES.\n            energy_unit (str, default=\"kJ/mol\"): The unit used in the description of the colorbar.\n            xlabel, ylabel (str, optional): If provided, they will be used as labels for the graphs.\n            image_size (List[int], default=[10,7]): The width and height of the picture.\n            levels (int, optional): A list of free energy values for isosurfaces in FES. Defaults to be 20.\n            dpi (int, default=96): The resolution of the picture.\n            surface (bool, default=False): Whether to plot the 3D surface of the FES.\n            surface_params (dict, optional): A dictionary of parameters to be passed to the PyVista plotter when plotting the 3D surface.\n            **kwargs: Additional keyword arguments to be passed to the Matplotlib plotter.\n\n        Returns:\n            fig, ax: The Matplotlib figure and axis objects.\n        \"\"\"\n\n        import matplotlib.cm as cm\n        import matplotlib.pyplot as plt\n\n        if self.fes is None:\n            raise ValueError(\n                \"FES not calculated yet. Use makefes() or makefes2() first.\")\n\n        if type(cmap) is str:\n            cmap = cm.get_cmap(cmap)\n\n        cvs = self.cvs\n\n        if cvs == 1:\n            fig, ax = PlottingFES._plot1d(\n                self, image_size=image_size, dpi=dpi,\n                energy_unit=energy_unit, xlabel=xlabel, **kwargs\n            )\n\n        elif cvs == 2:\n            if surface:\n                fig, ax = PlottingFES._surface_plot(\n                    self,\n                    cmap=cmap, image_size=image_size, dpi=dpi,\n                    xlabel=xlabel, ylabel=ylabel,\n                    energy_unit=energy_unit,\n                    **surface_params, **kwargs\n                )\n            fig, ax = PlottingFES._plot2d(\n                self,\n                levels=levels, cmap=cmap, image_size=image_size, dpi=dpi,\n                xlabel=xlabel, ylabel=ylabel, **kwargs\n            )\n\n        else:\n            raise ValueError(\"Only 1D and 2D FES are supported.\")\n\n        if png_name != None:\n            fig.savefig(png_name)\n\n        return fig, ax\n\n    def plot_minima(self, mark_color=\"white\", png_name=None, **kwargs):\n        fig, ax = PlottingFES.plot_minima(self, mark_color, **kwargs)\n        if png_name is not None:\n            fig.savefig(png_name)\n        return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.find_minima","title":"<code>find_minima(nbins=8)</code>","text":"<p>Method for finding local minima on FES.</p> <p>Parameters:</p> Name Type Description Default <code>fes</code> <code>Fes</code> <p>The Fes object to find the minima on.</p> required <code>nbins</code> <code>int, default=8</code> <p>The number of bins used to divide the FES.</p> <code>8</code> Source code in <code>catflow/metad/fes.py</code> <pre><code>def find_minima(self, nbins=8):\n    \"\"\"Method for finding local minima on FES.\n\n    Args:\n        fes (Fes): The Fes object to find the minima on.\n        nbins (int, default=8): The number of bins used to divide the FES.\n    \"\"\"\n    if self.fes is None:\n        raise ValueError(\n            \"FES not calculated yet. Use make_fes_original() first.\"\n        )\n\n    if self.minima is not None:\n        logger.warning(\"Minima already found.\")\n        return None\n\n    import pandas as pd\n\n    cv_min = self.cv_min\n    cv_max = self.cv_max\n\n    if int(nbins) != nbins:\n        nbins = int(nbins)\n        logger.info(\n            f\"Number of bins must be an integer, it will be set to {nbins}.\")\n    if self.res % nbins != 0:\n        raise ValueError(\"Resolution of FES must be divisible by number of bins.\")\n    if nbins &gt; self.res/2:\n        raise ValueError(\"Number of bins is too high.\")\n\n    bin_size = int(self.res/nbins)\n\n    for index in np.ndindex(tuple([nbins] * self.cvs)):\n        # index serve as bin number\n        _fes_slice = tuple(\n            slice(\n                index[i] * bin_size, (index[i] + 1) * bin_size\n            ) for i in range(self.cvs)\n        )\n        fes_slice = self.fes[_fes_slice]\n        bin_min = np.min(fes_slice)\n\n        # indexes of global minimum of a bin\n        bin_min_arg = np.unravel_index(\n            np.argmin(fes_slice), fes_slice.shape\n        )\n        # indexes of that minima in the original fes (indexes +1)\n        min_cv_b = np.array([\n            bin_min_arg[i] + index[i] * bin_size for i in range(self.cvs)\n        ], dtype=int)\n\n        if (np.array(bin_min_arg, dtype=int) &gt; 0).all() and \\\n                (np.array(bin_min_arg, dtype=int) &lt; bin_size - 1).all():\n            # if the minima is not on the edge of the bin\n            min_cv = (((min_cv_b+0.5)/self.res) * (cv_max-cv_min))+cv_min\n            local_minima = np.concatenate([\n                [np.round(bin_min, 6)], min_cv_b, np.round(min_cv, 6)\n            ])\n            if self.minima is None:\n                self.minima = local_minima\n            else:\n                self.minima = np.vstack((self.minima, local_minima))\n        else:\n            # if the minima is on the edge of the bin\n            around = np.zeros(tuple([3] * self.cvs))\n\n            for product_index in product(*[range(3)] * self.cvs):\n                converted_index = np.array(product_index, dtype=int) + \\\n                    np.array(min_cv_b, dtype=int) - 1\n                converted_index[self.periodic] = \\\n                    converted_index[self.periodic] % self.res\n\n                mask = np.where(\n                    (converted_index &lt; 0) + (converted_index &gt; self.res - 1)\n                )[0]\n\n                if len(mask) &gt; 0:\n                    around[product_index] = np.inf\n\n                elif product_index == tuple([1] * self.cvs):\n                    around[product_index] = np.inf\n\n                else:\n                    around[product_index] = self.fes[tuple(\n                        converted_index)]\n\n            if (around &gt; bin_min).all():\n                min_cv = (((min_cv_b+0.5)/self.res) * (cv_max-cv_min))+cv_min\n                local_minima = np.concatenate([\n                    [np.round(bin_min, 6)], min_cv_b, np.round(min_cv, 6)\n                ])\n                if self.minima is None:\n                    self.minima = local_minima\n                else:\n                    self.minima = np.vstack((self.minima, local_minima))\n\n    if self.minima is None:\n        logger.warning(\"No minima found.\")\n        return None\n\n    if len(self.minima.shape) &gt; 1:\n        self.minima = self.minima[self.minima[:, 0].argsort()]\n\n    if self.minima.shape[0] == 1:\n        self.minima = np.concatenate((\n            np.arange(0, self.minima.shape[0], dtype=int), self.minima\n        ))\n    else:\n        self.minima = np.column_stack((\n            np.arange(0, self.minima.shape[0], dtype=int), self.minima\n        ))\n\n    if self.cv_name is None:\n        self.cv_name = [f\"CV{i+1}\" for i in range(self.cvs)]\n\n    minima_df = pd.DataFrame(\n        np.array(self.minima),\n        columns=[\"Minimum\", \"free energy\"] +\n        [f\"CV{i+1}bin\" for i in range(self.cvs)] +\n        [f\"CV{i+1} - {self.cv_name[i]}\" for i in range(self.cvs)]\n    )\n    minima_df[\"Minimum\"] = minima_df[\"Minimum\"].astype(int)\n    self.minima = minima_df\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.from_hills","title":"<code>from_hills(hills, resolution=256)</code>  <code>classmethod</code>","text":"<p>Generate a FES object from a Hills object.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>@classmethod\ndef from_hills(\n    cls, \n    hills: Hills,\n    resolution: int = 256\n):\n    \"\"\"Generate a FES object from a Hills object.\"\"\"\n    fes = cls(resolution=resolution)\n\n    fes.cvs = hills.cvs\n\n    fes.hills = hills\n    fes.periodic = hills.periodic\n    fes.cv_name = hills.cv_name\n\n    fes.generate_cv_map()\n\n    return fes\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.generate_cv_map","title":"<code>generate_cv_map()</code>","text":"<p>generate CV map</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>def generate_cv_map(self):\n    \"\"\"generate CV map\"\"\"\n    if self.hills is not None:\n        cv_min = deepcopy(self.hills.cv_min)\n        cv_max = deepcopy(self.hills.cv_max)\n        cv_range = cv_max - cv_min\n        self.cv_range = cv_range\n\n        cv_min[~self.periodic] -= cv_range[~self.periodic] * 0.15\n        cv_max[~self.periodic] += cv_range[~self.periodic] * 0.15\n        cv_fes_range = np.abs(cv_max - cv_min)\n\n        # generate remapped cv_min and cv_max\n        self.cv_min = cv_min\n        self.cv_max = cv_max\n        self.cv_fes_range = cv_fes_range\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.get_e_beta_c","title":"<code>get_e_beta_c(resolution=None, time_min=None, time_max=None, kb=0.008314, temp=300.0, bias_factor=15.0, return_fes=False)</code>","text":"<p>Function used internally for summing hills in Hills object with the fast Bias Sum Algorithm.  From which could also be quick to get e_beta_c for reweighting.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>int</code> <p>The resolution of the free energy surface. Defaults to 256.</p> <code>None</code> <code>time_min</code> <code>int</code> <p>The starting time step of simulation. Defaults to 0.</p> <code>None</code> <code>time_max</code> <code>int</code> <p>The ending time step of simulation. Defaults to None.</p> <code>None</code> <code>reweighting</code> <code>bool</code> <p>If True, the function of c(t) will be calculated and stored in <code>self.e_beta_c</code>. Defaults to False.</p> required <code>kb</code> <code>float</code> <p>The Boltzmann Constant in the energy unit. Defaults to 8.314e-3.</p> <code>0.008314</code> <code>temp</code> <code>float</code> <p>The temperature of the simulation in Kelvins. Defaults to 300.0.</p> <code>300.0</code> <code>bias_factor</code> <code>float</code> <p>The bias factor used in the simulation. Defaults to 15.0.</p> <code>15.0</code> Source code in <code>catflow/metad/fes.py</code> <pre><code>def get_e_beta_c(\n    self,\n    resolution: Optional[int] = None,\n    time_min: Optional[int] = None,\n    time_max: Optional[int] = None,\n    kb: float = 8.314e-3,\n    temp: float = 300.0,\n    bias_factor: float = 15.0,\n    return_fes: bool = False\n):\n    \"\"\"Function used internally for summing hills in Hills object with the fast Bias Sum Algorithm. \n    From which could also be quick to get e_beta_c for reweighting.\n\n    Args:\n        resolution (int, optional): \\\n            The resolution of the free energy surface. Defaults to 256.\n        time_min (int): The starting time step of simulation. Defaults to 0.\n        time_max (int, optional): The ending time step of simulation. Defaults to None.\n        reweighting (bool, optional): \\\n            If True, the function of c(t) will be calculated and stored in `self.e_beta_c`.\n            Defaults to False.\n        kb (float, optional): The Boltzmann Constant in the energy unit. Defaults to 8.314e-3.\n        temp (float, optional): The temperature of the simulation in Kelvins. Defaults to 300.0.\n        bias_factor (float, optional): The bias factor used in the simulation. Defaults to 15.0.\n    \"\"\"\n\n    if resolution is None:\n        resolution = self.res\n\n    if self.hills is None:\n        raise ValueError(\"Hills not loaded yet.\")\n\n    if time_min is None:\n        time_min = 0\n\n    if time_max is None:\n        time_max = len(self.hills.cv[:, 0])\n\n    cvs = self.cvs\n\n    cv_min = self.cv_min\n    cv_max = self.cv_max\n    if self.cv_fes_range is None:\n        self.cv_fes_range = cv_max - cv_min\n    cv_fes_range = self.cv_fes_range\n\n    cv_bins = np.ceil(\n        (self.hills.cv[time_min:time_max, :cvs] -\n         cv_min) * resolution / cv_fes_range\n    ).T.astype(int)\n\n    sigma = self.hills.sigma[:cvs, 0]\n    sigma_res = (sigma * resolution) / (cv_max - cv_min)\n\n    gauss_res = (8 * sigma_res).astype(int)\n    for i, _ in enumerate(gauss_res):\n        if _ % 2 == 0:\n            gauss_res[i] += 1\n\n    gauss = self._gauss_kernel(gauss_res, sigma_res)\n    gauss_center = np.array(gauss.shape) // 2\n\n    fes = np.zeros([resolution] * cvs)\n    e_beta_c = np.zeros(len(cv_bins[0]))\n\n    for line in range(len(cv_bins[0])):\n        fes_index_to_edit, delta_fes = \\\n            self._sum_bias(\n                gauss_center, gauss, cv_bins, line, cvs, resolution\n            )\n        fes[fes_index_to_edit] += delta_fes\n\n        local_fes = fes - np.min(fes)\n        exp_local_fes = np.exp(-local_fes / (kb * temp))\n\n        numerator = np.sum(exp_local_fes)\n        denominator = np.sum(exp_local_fes / bias_factor)\n        e_beta_c[line] = numerator / denominator\n    if return_fes:\n        fes -= np.min(fes)\n        return e_beta_c, fes\n    else:\n        return e_beta_c\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.make_fes_original","title":"<code>make_fes_original(resolution, time_min=None, time_max=None, n_workers=2)</code>","text":"<p>Function internally used to sum Hills in the same way as Plumed <code>sum_hills</code>. </p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>int</code> <p>The resolution of the free energy surface. Defaults to 256.</p> required <code>time_min</code> <code>int</code> <p>The starting time step of simulation. Defaults to 0.</p> <code>None</code> <code>time_max</code> <code>int</code> <p>The ending time step of simulation. Defaults to None.</p> <code>None</code> <code>n_workers</code> <code>int</code> <p>Number of workers for parallelization. Defaults to 2.</p> <code>2</code> Source code in <code>catflow/metad/fes.py</code> <pre><code>def make_fes_original(\n    self,\n    resolution: Optional[int],\n    time_min: Optional[int] = None,\n    time_max: Optional[int] = None,\n    n_workers: int = 2\n):\n    \"\"\"\n    Function internally used to sum Hills in the same way as Plumed `sum_hills`. \n\n    Args:\n        resolution (int, optional): \\\n            The resolution of the free energy surface. Defaults to 256.\n        time_min (int): The starting time step of simulation. Defaults to 0.\n        time_max (int, optional): The ending time step of simulation. Defaults to None.\n        n_workers (int, optional): Number of workers for parallelization. Defaults to 2.\n    \"\"\"\n    if self.hills is None:\n        raise ValueError(\"Hills not loaded yet.\")\n\n    if resolution is None:\n        resolution = self.res\n\n    cvs = self.cvs\n    fes = np.zeros([resolution] * cvs)\n\n    if time_min is None:\n        time_min = 0\n    if time_max is None:\n        time_max = len(self.hills.cv[:, 0])\n    time_limit = time_max - time_min\n\n    def calculate_fes(index):\n        dp2 = self._calculate_dp2(index, time_min, time_max)\n\n        tmp = np.zeros(time_limit)\n        tmp[dp2 &lt; 6.25] = self.hills.heights[dp2 &lt; 6.25] * \\\n            (np.exp(-dp2[dp2 &lt; 6.25]) *\n             1.00193418799744762399 - 0.00193418799744762399)\n        return index, -tmp.sum()\n\n    indices = list(np.ndindex(fes.shape))\n    results = Parallel(n_jobs=n_workers)(\n        delayed(calculate_fes)(index) for index in indices\n    )\n    if results is not None:\n        for index, value in results:\n            fes[index] = value\n        fes -= np.min(fes)\n    self.fes = fes\n    return fes\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.plot","title":"<code>plot(png_name=None, cmap='RdYlBu_r', energy_unit='kJ/mol', xlabel=None, ylabel=None, image_size=[10, 7], levels=20, dpi=96, surface=False, surface_params={}, **kwargs)</code>","text":"<p>Visualizes the free energy surface (FES) using Matplotlib and PyVista.</p> <p>Usage: <pre><code>fes.plot()\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>png_name</code> <code>str</code> <p>If provided, the picture of FES will be saved under this name in the current working directory.</p> <code>None</code> <code>cmap</code> <code>str, default=\"RdYlBu_r\"</code> <p>The Matplotlib colormap used to color the 2D or 3D FES.</p> <code>'RdYlBu_r'</code> <code>energy_unit</code> <code>str, default=\"kJ/mol\"</code> <p>The unit used in the description of the colorbar.</p> <code>'kJ/mol'</code> <code>xlabel,</code> <code>ylabel (str</code> <p>If provided, they will be used as labels for the graphs.</p> required <code>image_size</code> <code>List[int], default=[10,7]</code> <p>The width and height of the picture.</p> <code>[10, 7]</code> <code>levels</code> <code>int</code> <p>A list of free energy values for isosurfaces in FES. Defaults to be 20.</p> <code>20</code> <code>dpi</code> <code>int, default=96</code> <p>The resolution of the picture.</p> <code>96</code> <code>surface</code> <code>bool, default=False</code> <p>Whether to plot the 3D surface of the FES.</p> <code>False</code> <code>surface_params</code> <code>dict</code> <p>A dictionary of parameters to be passed to the PyVista plotter when plotting the 3D surface.</p> <code>{}</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the Matplotlib plotter.</p> <code>{}</code> <p>Returns:</p> Type Description <p>fig, ax: The Matplotlib figure and axis objects.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>def plot(\n    self,\n    png_name: Optional[str] = None,\n    cmap: Union[str, Colormap] = \"RdYlBu_r\",\n    energy_unit: str = \"kJ/mol\",\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n    image_size: List[int] = [10, 7],\n    levels: int = 20,\n    dpi: int = 96,\n    surface: bool = False,\n    surface_params: dict = {},\n    **kwargs\n):\n    \"\"\"\n    Visualizes the free energy surface (FES) using Matplotlib and PyVista.\n\n    Usage:\n    ```python\n    fes.plot()\n    ```\n\n    Args:\n        png_name (str, optional): If provided, the picture of FES will be saved under this name in the current working directory.\n        cmap (str, default=\"RdYlBu_r\"): The Matplotlib colormap used to color the 2D or 3D FES.\n        energy_unit (str, default=\"kJ/mol\"): The unit used in the description of the colorbar.\n        xlabel, ylabel (str, optional): If provided, they will be used as labels for the graphs.\n        image_size (List[int], default=[10,7]): The width and height of the picture.\n        levels (int, optional): A list of free energy values for isosurfaces in FES. Defaults to be 20.\n        dpi (int, default=96): The resolution of the picture.\n        surface (bool, default=False): Whether to plot the 3D surface of the FES.\n        surface_params (dict, optional): A dictionary of parameters to be passed to the PyVista plotter when plotting the 3D surface.\n        **kwargs: Additional keyword arguments to be passed to the Matplotlib plotter.\n\n    Returns:\n        fig, ax: The Matplotlib figure and axis objects.\n    \"\"\"\n\n    import matplotlib.cm as cm\n    import matplotlib.pyplot as plt\n\n    if self.fes is None:\n        raise ValueError(\n            \"FES not calculated yet. Use makefes() or makefes2() first.\")\n\n    if type(cmap) is str:\n        cmap = cm.get_cmap(cmap)\n\n    cvs = self.cvs\n\n    if cvs == 1:\n        fig, ax = PlottingFES._plot1d(\n            self, image_size=image_size, dpi=dpi,\n            energy_unit=energy_unit, xlabel=xlabel, **kwargs\n        )\n\n    elif cvs == 2:\n        if surface:\n            fig, ax = PlottingFES._surface_plot(\n                self,\n                cmap=cmap, image_size=image_size, dpi=dpi,\n                xlabel=xlabel, ylabel=ylabel,\n                energy_unit=energy_unit,\n                **surface_params, **kwargs\n            )\n        fig, ax = PlottingFES._plot2d(\n            self,\n            levels=levels, cmap=cmap, image_size=image_size, dpi=dpi,\n            xlabel=xlabel, ylabel=ylabel, **kwargs\n        )\n\n    else:\n        raise ValueError(\"Only 1D and 2D FES are supported.\")\n\n    if png_name != None:\n        fig.savefig(png_name)\n\n    return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.remove_cv","title":"<code>remove_cv(CV, kb=None, energy_unit='kJ/mol', temp=300.0)</code>","text":"<p>Remove a CV from an existing FES.  The function first recalculates the FES to an array of probabilities.  The probabilities are summed along the CV to be removed,  and resulting probability distribution with 1 less dimension  is converted back to FES. </p> <p>Interactivity was working in jupyter notebook/lab with \"%matplotlib widget\".</p> <p>Parameters:</p> Name Type Description Default <code>CV</code> <code>int</code> <p>the index of CV to be removed. </p> required <code>energy_unit</code> <code>str</code> <p>has to be either \"kJ/mol\" or \"kcal/mol\". Defaults to be \"kJ/mol\".</p> <code>'kJ/mol'</code> <code>kb</code> <code>float</code> <p>the Boltzmann Constant in the energy unit.                 Defaults to be None, which will be set according to energy_unit.</p> <code>None</code> Return <p>New <code>FES</code> instance without the CV to be removed.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>def remove_cv(\n    self,\n    CV: int,\n    kb: Optional[float] = None,\n    energy_unit: str = \"kJ/mol\",\n    temp: float = 300.0\n):\n    \"\"\"Remove a CV from an existing FES. \n    The function first recalculates the FES to an array of probabilities. \n    The probabilities are summed along the CV to be removed, \n    and resulting probability distribution with 1 less dimension \n    is converted back to FES. \n\n    Interactivity was working in jupyter notebook/lab with \"%matplotlib widget\".\n\n    Args:\n        CV (int): the index of CV to be removed. \n        energy_unit (str): has to be either \"kJ/mol\" or \"kcal/mol\". Defaults to be \"kJ/mol\".\n        kb (float, optional): the Boltzmann Constant in the energy unit. \\\n            Defaults to be None, which will be set according to energy_unit.\n        temp (float) = temperature of the simulation in Kelvins.\n\n    Return:\n        New `FES` instance without the CV to be removed.\n    \"\"\"\n\n    logger.info(f\"Removing CV {CV}.\")\n\n    if self.fes is None:\n        raise ValueError(\n            \"FES not calculated yet. Use makefes() or makefes2() first.\")\n\n    if CV &gt; self.hills.cvs:\n        raise ValueError(\n            \"Error: The CV to remove is not available in this FES object.\")\n\n    if kb == None:\n        if energy_unit == \"kJ/mol\":\n            kb = 8.314e-3\n        elif energy_unit == \"kcal/mol\":\n            kb = 8.314e-3 / 4.184\n        else:\n            raise ValueError(\n                \"Please give the Boltzmann Constant in the energy unit.\")\n\n    if self.cvs == 1:\n        raise ValueError(\"Error: You can not remove the only CV. \")\n    else:\n        probabilities = np.exp(-self.fes / (kb * temp))\n        new_prob = np.sum(probabilities, axis=CV)\n\n        new_fes = FreeEnergySurface.from_hills(hills=self.hills)\n        new_fes.fes = - kb * temp * np.log(new_prob)\n        new_fes.fes = new_fes.fes - np.min(new_fes.fes)\n        new_fes.res = self.res\n\n        mask = np.ones(self.cvs, dtype=bool)\n        mask[CV] = False\n        new_fes.cv_min = self.cv_min[mask]\n        new_fes.cv_max = self.cv_max[mask]\n        new_fes.cv_fes_range = self.cv_fes_range[mask]\n        new_fes.cv_name = [\n            j for i, j in enumerate(self.cv_name) if mask[i]]\n        new_fes.cvs = self.cvs - 1\n        return new_fes\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.remove_cvs","title":"<code>remove_cvs(CVs, kb=None, energy_unit='kJ/mol', temp=300.0)</code>","text":"<p>Remove multiple collective variables (CVs) from the free energy surface (FES).</p> <p>Parameters:</p> Name Type Description Default <code>CVs</code> <code>List[int]</code> <p>The list of CVs to be removed.</p> required <code>kb</code> <code>Optional[float]</code> <p>The Boltzmann constant. Defaults to None.</p> <code>None</code> <code>energy_unit</code> <code>str</code> <p>The unit of energy. Defaults to \"kJ/mol\".</p> <code>'kJ/mol'</code> <code>temp</code> <code>float</code> <p>The temperature in Kelvin. Defaults to 300.0.</p> <code>300.0</code> <p>Returns:</p> Name Type Description <code>Fes</code> <p>The new FES object with the specified CVs removed.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>def remove_cvs(\n    self,\n    CVs: List[int],\n    kb: Optional[float] = None,\n    energy_unit: str = \"kJ/mol\",\n    temp: float = 300.0\n):\n    \"\"\"\n    Remove multiple collective variables (CVs) from the free energy surface (FES).\n\n    Args:\n        CVs (List[int]): The list of CVs to be removed.\n        kb (Optional[float], optional): The Boltzmann constant. Defaults to None.\n        energy_unit (str, optional): The unit of energy. Defaults to \"kJ/mol\".\n        temp (float, optional): The temperature in Kelvin. Defaults to 300.0.\n\n    Returns:\n        Fes: The new FES object with the specified CVs removed.\n    \"\"\"\n    fes = self.remove_cv(CVs[0], kb, energy_unit, temp)\n    if len(CVs) &gt; 1:\n        for CV in CVs[1:]:\n            if fes is not None:\n                fes = fes.remove_cv(CV, kb, energy_unit, temp)\n    return fes\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.FreeEnergySurface.reweighting","title":"<code>reweighting(colvar_file, e_beta_c, cv_indexes=None, resolution=64, kb=0.008314, temp=300.0)</code>","text":"<p>Reweights the free energy surface based on the given collective variables.</p> <p>Parameters:</p> Name Type Description Default <code>colvar_file</code> <code>str</code> <p>The path to the file containing the collective variables.</p> required <code>e_beta_c</code> <code>ArrayLike</code> <p>The array of e^(-beta*C(t)) values.</p> required <code>cv_indexes</code> <code>Optional[List[int]]</code> <p>The indexes of the collective variables to use. Defaults to None.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>The resolution of the free energy surface. Defaults to 64.</p> <code>64</code> <code>kb</code> <code>float</code> <p>The Boltzmann constant. Defaults to 8.314e-3.</p> <code>0.008314</code> <code>temp</code> <code>float</code> <p>The temperature in Kelvin. Defaults to 300.0.</p> <code>300.0</code> <p>Returns:</p> Type Description <p>np.ndarray: The reweighted free energy surface.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>def reweighting(\n    self,\n    colvar_file: str,\n    e_beta_c: ArrayLike,\n    cv_indexes: Optional[List[int]] = None,\n    resolution: int = 64,\n    kb: float = 8.314e-3,\n    temp: float = 300.0\n):\n    \"\"\"\n    Reweights the free energy surface based on the given collective variables.\n\n    Args:\n        colvar_file (str): The path to the file containing the collective variables.\n        e_beta_c (ArrayLike): The array of e^(-beta*C(t)) values.\n        cv_indexes (Optional[List[int]], optional): The indexes of the collective variables to use. Defaults to None.\n        resolution (int, optional): The resolution of the free energy surface. Defaults to 64.\n        kb (float, optional): The Boltzmann constant. Defaults to 8.314e-3.\n        temp (float, optional): The temperature in Kelvin. Defaults to 300.0.\n\n    Returns:\n        np.ndarray: The reweighted free energy surface.\n    \"\"\"\n    colvar = np.loadtxt(colvar_file)\n\n    if cv_indexes is None:\n        cvs = self.cvs\n        colvar_value = colvar[:, 1:cvs+1]\n    else:\n        cvs = len(cv_indexes)\n        colvar_value = np.vstack(\n            [colvar[:, i + 1] for i in cv_indexes]\n        ).T\n    cv_array = colvar_value - np.min(colvar_value, axis=0)\n    cv_range = np.max(cv_array)\n    cv_array = np.floor((resolution - 1) * cv_array / cv_range).astype(int)\n\n    bias = colvar[:, 9]\n    probs = np.zeros([resolution] * cvs)\n\n    e_beta_c = np.array(e_beta_c)\n    reweighted_fes = np.zeros([len(e_beta_c)] + [resolution] * cvs)\n\n    for i in np.arange(len(e_beta_c)):\n        index = tuple(cv_array[i])\n        probs[index] += np.exp(bias[i]/(kb * temp)) / e_beta_c[i]\n        reweighted_fes[i] = -kb * temp * np.log(probs)\n\n    return reweighted_fes\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.PlottingFES","title":"<code>PlottingFES</code>","text":"<p>A class that provides methods for plotting free energy surfaces (FES) from a FES object.</p> Source code in <code>catflow/metad/fes.py</code> <pre><code>class PlottingFES:\n    \"\"\"\n    A class that provides methods for plotting free energy surfaces (FES) from a FES object.\n    \"\"\"\n\n    @staticmethod\n    def _surface_plot(\n        fes: FreeEnergySurface,\n        cmap: Union[str, Colormap] = \"RdYlBu\",\n        energy_unit: str = \"kJ/mol\",\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        zlabel: Optional[str] = None,\n        label_size: int = 12,\n        image_size: List[int] = [10, 7],\n        rstride: int = 1,\n        cstride: int = 1,\n        dpi: int = 96,\n        **kwargs\n    ):\n        \"\"\"\n        Visualizes the 2D free energy surface (FES) as a 3D surface plot using Matplotlib.\n\n        Note: Interactivity is currently limited to jupyter notebook or jupyter lab in `%matplotlib widget` mode. Otherwise, it is a static image of the 3D surface plot.\n\n        Usage:\n        ```python\n        %matplotlib widget\n        fes.surface_plot()\n        ```\n\n        Future plans include implementing this function using PyVista. However, in the current version of PyVista (0.38.5), there is an issue with labels on the 3rd axis for free energy showing wrong values.\n        \"\"\"\n\n        if fes.cv_name is None:\n            fes.name_cv()\n\n        if fes.cvs == 2:\n            cv_min = fes.cv_min\n            cv_max = fes.cv_max\n\n            x = np.linspace(cv_min[0], cv_max[0], fes.res)\n            y = np.linspace(cv_min[1], cv_max[1], fes.res)\n\n            X, Y = np.meshgrid(x, y)\n            Z = fes.fes\n\n            canvas_style(**kwargs)\n\n            fig, ax = plt.subplots(\n                figsize=image_size, dpi=dpi,\n                subplot_kw={\"projection\": \"3d\"}\n            )\n            ax.plot_surface(X, Y, Z, cmap=cmap,  # type: ignore\n                            rstride=rstride, cstride=cstride)\n\n            if xlabel == None:\n                ax.set_xlabel(\n                    f'CV1 - {fes.cv_name[0]}', size=label_size) # type: ignore\n            else:\n                ax.set_xlabel(xlabel, size=label_size)\n            if ylabel == None:\n                ax.set_ylabel(\n                    f'CV2 - {fes.cv_name[1]}', size=label_size) # type: ignore\n            else:\n                ax.set_ylabel(ylabel, size=label_size)\n            if zlabel == None:\n                ax.set_zlabel(f'Free energy ({energy_unit})', size=label_size) # type: ignore\n            else:\n                ax.set_zlabel(zlabel, size=label_size)  # type: ignore\n        else:\n            raise ValueError(\n                f\"Surface plot only works for FES with exactly two CVs, and this FES has {fes.cvs}.\"\n            )\n        return fig, ax\n\n    @staticmethod\n    def _plot1d(\n        fes: FreeEnergySurface,\n        image_size: List[int] = [10, 7],\n        dpi: int = 96,\n        energy_unit: str = 'kJ/mol',\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        **kwargs\n    ):\n        canvas_style(**kwargs)\n        fig, ax = plt.subplots(\n            figsize=(image_size[0], image_size[1]),\n            dpi=dpi\n        )\n        X = np.linspace(fes.cv_min[0], fes.cv_max[0], fes.res)\n        ax.plot(X, fes.fes)\n        if xlabel == None:\n            ax.set_xlabel(\n                f'CV1 - {fes.cv_name[0]}') # type: ignore\n        else:\n            ax.set_xlabel(xlabel)\n        if ylabel == None:\n            ax.set_ylabel(f'Free Energy ({energy_unit})')\n        else:\n            ax.set_ylabel(ylabel)\n        return fig, ax\n\n    @staticmethod\n    def _plot2d(\n        fes_obj: FreeEnergySurface,\n        levels: int = 20,\n        cmap: Union[str, Colormap] = \"RdYlBu\",\n        image_size: List[int] = [10, 7],\n        dpi: int = 96,\n        energy_unit: str = 'kJ/mol',\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        zlabel: Optional[str] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Generates a filled contour plot of the energy landscape $V$.\n\n        Args:\n            cmap: Colormap for plot.\n            levels: Levels to plot contours at (see matplotlib contour/contourf docs for details).\n            dpi: DPI.\n        \"\"\"\n        import seaborn as sns\n        import matplotlib.pyplot as plt\n\n        canvas_style(**kwargs)\n        fig, ax = plt.subplots(\n            figsize=(image_size[0], image_size[1]),\n            dpi=dpi\n        )\n\n        if fes_obj.fes is None:\n            raise ValueError(\n                \"FES not calculated yet. Use fes.makefes() or fes.makefes2() first.\")\n        X = np.linspace(fes_obj.cv_min[0], fes_obj.cv_max[0], fes_obj.res)\n        Y = np.linspace(fes_obj.cv_min[1], fes_obj.cv_max[1], fes_obj.res)\n        fes = fes_obj.fes.T\n        cs = ax.contourf(X, Y, fes, levels=levels, cmap=cmap)\n        ax.contour(X, Y, fes, levels=levels, colors=\"black\", alpha=0.2)\n\n        if xlabel == None:\n            ax.set_xlabel(\n                f'CV1 - {fes_obj.cv_name[0]}')\n        else:\n            ax.set_xlabel(xlabel)\n        if ylabel == None:\n            ax.set_ylabel(\n                f'CV2 - {fes_obj.cv_name[1]}')\n        else:\n            ax.set_ylabel(ylabel)\n        cbar = fig.colorbar(cs)\n        if zlabel == None:\n            cbar.set_label(f'Free Energy ({energy_unit})')\n        else:\n            cbar.set_label(zlabel)\n        return fig, ax\n\n    @staticmethod\n    def plot_minima(\n        fes_obj: FreeEnergySurface,\n        mark_color: str = \"white\",\n        **kwargs\n    ):\n        \"\"\"\n        Function used to visualize the FES objects with the positions of local minima shown as letters on the graph.\n\n        Usage:\n        ```python\n        minima.plot()\n        ```\n        \"\"\"\n        if fes_obj.minima is None:\n            raise ValueError(\"No minima found.\")\n\n        fig, ax = fes_obj.plot(**kwargs)\n\n        free_energy_range = fes_obj.fes.max() - fes_obj.fes.min()\n\n        if fes_obj.cvs == 1:\n            for m in range(len(fes_obj.minima.index)):\n                ax.text(\n                    float(fes_obj.minima.iloc[m, 3]), \n                    float(fes_obj.minima.iloc[m, 1])+free_energy_range*0.05, \n                    fes_obj.minima.iloc[m, 0],\n                    horizontalalignment='center', \n                    c=mark_color,\n                    verticalalignment='bottom'\n                )\n\n        elif fes_obj.cvs == 2:\n            for m in range(len(fes_obj.minima.index)):\n                ax.text(\n                    float(fes_obj.minima.iloc[m, 4]), \n                    float(fes_obj.minima.iloc[m, 5]), \n                    fes_obj.minima.iloc[m, 0],\n                    horizontalalignment='center',\n                    verticalalignment='center', \n                    c=mark_color\n                )\n        return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/fes/#catflow.metad.fes.PlottingFES.plot_minima","title":"<code>plot_minima(fes_obj, mark_color='white', **kwargs)</code>  <code>staticmethod</code>","text":"<p>Function used to visualize the FES objects with the positions of local minima shown as letters on the graph.</p> <p>Usage: <pre><code>minima.plot()\n</code></pre></p> Source code in <code>catflow/metad/fes.py</code> <pre><code>@staticmethod\ndef plot_minima(\n    fes_obj: FreeEnergySurface,\n    mark_color: str = \"white\",\n    **kwargs\n):\n    \"\"\"\n    Function used to visualize the FES objects with the positions of local minima shown as letters on the graph.\n\n    Usage:\n    ```python\n    minima.plot()\n    ```\n    \"\"\"\n    if fes_obj.minima is None:\n        raise ValueError(\"No minima found.\")\n\n    fig, ax = fes_obj.plot(**kwargs)\n\n    free_energy_range = fes_obj.fes.max() - fes_obj.fes.min()\n\n    if fes_obj.cvs == 1:\n        for m in range(len(fes_obj.minima.index)):\n            ax.text(\n                float(fes_obj.minima.iloc[m, 3]), \n                float(fes_obj.minima.iloc[m, 1])+free_energy_range*0.05, \n                fes_obj.minima.iloc[m, 0],\n                horizontalalignment='center', \n                c=mark_color,\n                verticalalignment='bottom'\n            )\n\n    elif fes_obj.cvs == 2:\n        for m in range(len(fes_obj.minima.index)):\n            ax.text(\n                float(fes_obj.minima.iloc[m, 4]), \n                float(fes_obj.minima.iloc[m, 5]), \n                fes_obj.minima.iloc[m, 0],\n                horizontalalignment='center',\n                verticalalignment='center', \n                c=mark_color\n            )\n    return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/hills/","title":"hills","text":""},{"location":"reference/catflow/metad/hills/#catflow.metad.hills.Hills","title":"<code>Hills</code>","text":"<p>Loads and extracts information from HILLS files.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the HILLS file. Defaults to \"HILLS\".</p> <code>'HILLS'</code> <code>encoding</code> <code>str</code> <p>Encoding of the HILLS file. Defaults to \"utf8\".</p> <code>'utf8'</code> <code>ignoretime</code> <code>bool</code> <p>If True, the time values in the HILLS file are ignored.  If False, the time values are saved. Defaults to True.</p> required <code>periodic</code> <code>List[bool]</code> <p>List of boolean values indicating which CV is periodic.  Defaults to [False, False].</p> <code>None</code> <code>cv_per</code> <code>List[List[float]]</code> <p>List of lists containing two numeric values defining  the periodicity of each periodic CV. Defaults to [[-numpy.pi, numpy.pi]].</p> <code>None</code> <code>timestep</code> <code>float</code> <p>Time difference between hills, in picoseconds.</p> required <p>Attributes:</p> Name Type Description <code>hills_filename</code> <code>str</code> <p>Name of the HILLS file.</p> <code>cvs</code> <code>int</code> <p>Number of collective variables (CVs) in the HILLS file.</p> <code>cv_name</code> <code>List[str]</code> <p>Names of the CVs.</p> <code>periodic</code> <code>ndarray</code> <p>Array of boolean values indicating which CV is periodic.</p> <code>cv_per</code> <code>List[List[float]]</code> <p>List of lists containing two numeric values defining  the periodicity of each periodic CV.</p> <code>cv</code> <code>ndarray</code> <p>Array of CV values.</p> <code>cv_min</code> <code>ndarray</code> <p>Array of minimum CV values.</p> <code>cv_max</code> <code>ndarray</code> <p>Array of maximum CV values.</p> <code>sigma</code> <code>ndarray</code> <p>Array of sigma values.</p> <code>heights</code> <code>ndarray</code> <p>Array of hill heights.</p> <code>biasf</code> <code>ndarray</code> <p>Array of bias factors.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If cv_per is not provided for each periodic CV.</p> <p>Examples:</p> <p>Load a HILLS file and extract its information:</p> <pre><code>&gt;&gt;&gt; hills = Hills(name=\"my_hills_file\")\n&gt;&gt;&gt; print(hills.get_cv_name())\n['cv1', 'cv2']\n&gt;&gt;&gt; print(hills.get_periodic())\n[False, True]\n&gt;&gt;&gt; print(hills.get_cv_per())\n[[-3.141592653589793, 3.141592653589793], [-numpy.pi, numpy.pi]]\n</code></pre> Source code in <code>catflow/metad/hills.py</code> <pre><code>class Hills:\n    \"\"\"\n    Loads and extracts information from HILLS files.\n\n    Args:\n        name (str, optional): Name of the HILLS file. Defaults to \"HILLS\".\n        encoding (str, optional): Encoding of the HILLS file. Defaults to \"utf8\".\n        ignoretime (bool, optional): If True, the time values in the HILLS file are ignored. \n            If False, the time values are saved. Defaults to True.\n        periodic (List[bool], optional): List of boolean values indicating which CV is periodic. \n            Defaults to [False, False].\n        cv_per (List[List[float]], optional): List of lists containing two numeric values defining \n            the periodicity of each periodic CV. Defaults to [[-numpy.pi, numpy.pi]].\n        timestep (float, optional): Time difference between hills, in picoseconds.\n\n    Attributes:\n        hills_filename (str): Name of the HILLS file.\n        cvs (int): Number of collective variables (CVs) in the HILLS file.\n        cv_name (List[str]): Names of the CVs.\n        periodic (ndarray): Array of boolean values indicating which CV is periodic.\n        cv_per (List[List[float]]): List of lists containing two numeric values defining \n            the periodicity of each periodic CV.\n        cv (ndarray): Array of CV values.\n        cv_min (ndarray): Array of minimum CV values.\n        cv_max (ndarray): Array of maximum CV values.\n        sigma (ndarray): Array of sigma values.\n        heights (ndarray): Array of hill heights.\n        biasf (ndarray): Array of bias factors.\n\n    Raises:\n        ValueError: If cv_per is not provided for each periodic CV.\n\n    Examples:\n        Load a HILLS file and extract its information:\n\n        &gt;&gt;&gt; hills = Hills(name=\"my_hills_file\")\n        &gt;&gt;&gt; print(hills.get_cv_name())\n        ['cv1', 'cv2']\n        &gt;&gt;&gt; print(hills.get_periodic())\n        [False, True]\n        &gt;&gt;&gt; print(hills.get_cv_per())\n        [[-3.141592653589793, 3.141592653589793], [-numpy.pi, numpy.pi]]\n\n    \"\"\"\n\n    def __init__(\n            self, \n            name=\"HILLS\", \n            encoding=\"utf8\", \n            ignore_time=True, \n            periodic=None, \n            cv_per: Optional[List[List[float]]] = None,\n            time_step=None\n    ):\n        self.read(\n            name, encoding, ignore_time, periodic, cv_per, time_step\n        )\n        self.hills_filename = name\n\n    def read(\n            self, \n            name=\"HILLS\", \n            encoding=\"utf8\", \n            ignore_time=True, \n            periodic=None, \n            cv_per: Optional[List[List[float]]] = None,\n            time_step=None\n    ):\n        with open(name, 'r', encoding=encoding) as hills_file:\n            first_line = hills_file.readline()\n        columns = first_line.split() \n        number_of_columns_head = len(columns) - 2\n        self.cvs = (number_of_columns_head - 3) // 2\n        self.cv_name = columns[3:3+self.cvs]\n\n        if periodic == None:\n            periodic = [False for i in range(self.cvs)]\n        self.periodic = np.array(periodic[:self.cvs], dtype=bool)\n\n        self.cv_per = cv_per\n\n        t = 0\n        self.hills = np.loadtxt(name, dtype=np.double)\n        self.cv = self.hills[:, 1:1+self.cvs]\n        self.cv_min = np.min(self.cv, axis=0) - 1e-8\n        self.cv_max = np.max(self.cv, axis=0) + 1e-8\n        for i in range(self.cvs):\n            flag = 0\n            if self.periodic[i]:\n                if self.cv_per == None:\n                    raise ValueError(\n                        \"cv_per has to be provided for each periodic CV\"\n                    )\n                try:\n                    if self.cv_per[flag][0] &lt;= self.cv_per[flag][1]:\n                        self.cv_min[i] = self.cv_per[flag][0]\n                        self.cv_max[i] = self.cv_per[flag][1]\n                        flag += 1\n                except IndexError:\n                    raise ValueError(\n                        \"cv_per has to be provided for each periodic CV\"\n                    )\n\n        self.sigma = self.hills[:, 1+self.cvs:-2]\n        self.heights = self.hills[:, -2]\n        self.biasf = self.hills[:, -1]\n        if ignore_time:\n            if time_step == None:\n                time_step = self.hills[0][0]\n            self.hills[:, 0] = np.arange(\n                time_step, time_step*(len(self.hills)+1), time_step\n            )\n</code></pre>"},{"location":"reference/catflow/metad/profile/","title":"profile","text":""},{"location":"reference/catflow/metad/profile/#catflow.metad.profile.FreeEnergyProfile","title":"<code>FreeEnergyProfile</code>","text":"<p>A class to calculate and visualize the free energy profile of a metadynamics simulation.</p> Source code in <code>catflow/metad/profile.py</code> <pre><code>class FreeEnergyProfile:\n    \"\"\"\n    A class to calculate and visualize the free energy profile of a metadynamics simulation.\n    \"\"\"\n\n    def __init__(\n        self, \n        fes: FreeEnergySurface, \n        hills: Hills, \n        profile_length: Optional[int] = None\n    ):\n        \"\"\"\n        Initializes a FreeEnergyProfile object with the given FES and Hills objects.\n\n        Args:\n            fes (FES): A FES object containing the collective variables (CVs) and the free energy surface.\n            hills (Hills): A Hills object containing the collective variables (CVs), the Gaussian hills, and the sigma values.\n            profile_length (int, optional): The length of the free energy profile. Defaults to None, for which the length is the same as the number of hills.\n\n        Raises:\n            ValueError: If there is only one local minimum on the free energy surface.\n        \"\"\"\n\n        self.cvs = fes.cvs\n        self.res = fes.res\n\n        if type(fes.minima) != pd.DataFrame:\n            raise ValueError(\n                \"There is only one local minimum on the free energy surface.\"\n            )\n        self.minima = fes.minima\n\n        self.periodic = fes.periodic\n        self.heights = hills.heights\n\n        self.cv_name = fes.cv_name\n        self.cv_min = fes.cv_min\n        self.cv_max = fes.cv_max\n        self.sigma = hills.sigma\n        self.cv = hills.cv\n\n        self.make_free_energy_profile(profile_length)\n\n    def make_free_energy_profile(\n        self, \n        profile_length: Optional[int] = None\n    ):\n        \"\"\"Internal method to calculate free energy profile.\n\n        Raises:\n            ValueError: If there is only one local minimum on the free energy surface.\n        \"\"\"\n        hills_length = len(self.cv[:, 0])\n\n        if profile_length == None:\n            profile_length = hills_length\n            scan_times = np.arange(hills_length, dtype=int)\n        else:\n            scan_times = np.linspace(0, hills_length-1, profile_length, dtype=int)\n\n        number_of_minima = self.minima.shape[0]\n        self.free_profile = np.zeros((self.minima[\"Minimum\"].shape[0]+1))\n\n        cvs = self.cvs\n        cv_min, cv_max = self.cv_min, self.cv_max\n        cv_fes_range = self.cv_max - self.cv_min\n\n        fes = np.zeros((self.res, self.res))\n\n        last_time = 0\n\n        for time in scan_times:\n            minima_cv_matrix = np.array(\n                self.minima.iloc[:, cvs+2:2*cvs+2], dtype=float\n            )\n            for coords in product(*minima_cv_matrix.T):\n                dist_cvs = []\n                for i in range(cvs):\n                    dist_cv = self.cv[:, i][last_time:time] - coords[i]\n                    if self.periodic[i]:\n                        dist_cv[dist_cv &lt; -0.5*cv_fes_range[i]\n                                ] += cv_fes_range[i]\n                        dist_cv[dist_cv &gt; +0.5*cv_fes_range[i]\n                                ] -= cv_fes_range[i]\n                    dist_cvs.append(dist_cv)\n                dp2 = np.sum(np.array(dist_cvs)**2, axis=0) / \\\n                    (2*self.sigma[:, 0][last_time:time]**2)\n                tmp = np.zeros(self.cv[:, 0][last_time:time].shape)\n                tmp[dp2 &lt; 2.5] = self.heights[last_time:time][dp2 &lt; 2.5] * \\\n                    (np.exp(-dp2[dp2 &lt; 2.5]) *\n                     1.00193418799744762399 - 0.00193418799744762399)\n                fes[tuple([\n                    int((float(coords[i])-cv_min[i])*self.res/cv_fes_range[i]) for i in range(cvs)\n                ])] -= tmp.sum()\n\n            # save profile\n            profile_line = [time]\n            for m in range(number_of_minima):\n                profile = fes[tuple([\n                    int(float(self.minima.iloc[m, i+2])) for i in range(cvs)\n                ])] - fes[tuple([\n                    int(float(self.minima.iloc[0, i+2])) for i in range(cvs)\n                ])]\n                profile_line.append(profile)\n            self.free_profile = np.vstack([self.free_profile, profile_line])\n\n            last_time = time\n\n    def plot(\n        self,\n        image_size: List[int] = [10, 7],\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        time_unit: str = \"ps\",\n        energy_unit: str = \"kJ/mol\",\n        label_size: int = 12,\n        cmap: Union[str, Colormap] = \"RdYlBu\",\n        png_name: Optional[str] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Visualization function for Free Energy Profile (FEP).\n\n        Usage:\n        ```python\n        fep.plot()\n        ```\n\n        Args:\n            name (str): Name for the .png file to save the plot to. Defaults to be \"FEProfile.png\".\n            image_size (List[int]): List of two dimensions of the picture. Defaults to be [10, 7].\n            xlabel (str, optional): X-axis label. Defaults to be None.\n            ylabel (str, optional): Y-axis label. Defaults to be None.\n            label_size (int): Size of labels. Defaults to be 12.\n            cmap (str): Matplotlib colormap used for coloring the line of the minima. Defaults to be \"jet\".\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n        import matplotlib.cm as cm\n\n        canvas_style(**kwargs)\n\n        fig, ax = plt.subplots(figsize=(image_size[0], image_size[1]))\n\n        if type(cmap) == str:\n            cmap = cm.get_cmap(cmap)\n\n        # colors = cm.jet((self.minima.iloc[:,1].to_numpy()).astype(float)/\\\n        #                (np.max(self.minima.iloc[:,1].to_numpy().astype(float))))\n        colors = cmap(np.linspace(0.15, 0.85, self.minima.shape[0]))\n        for m in range(self.minima.shape[0]):\n            ax.plot(\n                self.free_profile[:, 0],\n                self.free_profile[:, m+1],\n                color=colors[m],\n                label=f\"Minima {self.minima.iloc[m, 0]}\",\n            )\n\n        ax.legend()\n\n        if xlabel == None:\n            ax.set_xlabel(f'Time ({time_unit})')\n        else:\n            ax.set_xlabel(xlabel)\n        if ylabel == None:\n            ax.set_ylabel(f'Free energy difference ({energy_unit})')\n        else:\n            ax.set_ylabel(ylabel)\n\n        if png_name != None:\n            fig.savefig(png_name)\n</code></pre>"},{"location":"reference/catflow/metad/profile/#catflow.metad.profile.FreeEnergyProfile.__init__","title":"<code>__init__(fes, hills, profile_length=None)</code>","text":"<p>Initializes a FreeEnergyProfile object with the given FES and Hills objects.</p> <p>Parameters:</p> Name Type Description Default <code>fes</code> <code>FES</code> <p>A FES object containing the collective variables (CVs) and the free energy surface.</p> required <code>hills</code> <code>Hills</code> <p>A Hills object containing the collective variables (CVs), the Gaussian hills, and the sigma values.</p> required <code>profile_length</code> <code>int</code> <p>The length of the free energy profile. Defaults to None, for which the length is the same as the number of hills.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is only one local minimum on the free energy surface.</p> Source code in <code>catflow/metad/profile.py</code> <pre><code>def __init__(\n    self, \n    fes: FreeEnergySurface, \n    hills: Hills, \n    profile_length: Optional[int] = None\n):\n    \"\"\"\n    Initializes a FreeEnergyProfile object with the given FES and Hills objects.\n\n    Args:\n        fes (FES): A FES object containing the collective variables (CVs) and the free energy surface.\n        hills (Hills): A Hills object containing the collective variables (CVs), the Gaussian hills, and the sigma values.\n        profile_length (int, optional): The length of the free energy profile. Defaults to None, for which the length is the same as the number of hills.\n\n    Raises:\n        ValueError: If there is only one local minimum on the free energy surface.\n    \"\"\"\n\n    self.cvs = fes.cvs\n    self.res = fes.res\n\n    if type(fes.minima) != pd.DataFrame:\n        raise ValueError(\n            \"There is only one local minimum on the free energy surface.\"\n        )\n    self.minima = fes.minima\n\n    self.periodic = fes.periodic\n    self.heights = hills.heights\n\n    self.cv_name = fes.cv_name\n    self.cv_min = fes.cv_min\n    self.cv_max = fes.cv_max\n    self.sigma = hills.sigma\n    self.cv = hills.cv\n\n    self.make_free_energy_profile(profile_length)\n</code></pre>"},{"location":"reference/catflow/metad/profile/#catflow.metad.profile.FreeEnergyProfile.make_free_energy_profile","title":"<code>make_free_energy_profile(profile_length=None)</code>","text":"<p>Internal method to calculate free energy profile.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is only one local minimum on the free energy surface.</p> Source code in <code>catflow/metad/profile.py</code> <pre><code>def make_free_energy_profile(\n    self, \n    profile_length: Optional[int] = None\n):\n    \"\"\"Internal method to calculate free energy profile.\n\n    Raises:\n        ValueError: If there is only one local minimum on the free energy surface.\n    \"\"\"\n    hills_length = len(self.cv[:, 0])\n\n    if profile_length == None:\n        profile_length = hills_length\n        scan_times = np.arange(hills_length, dtype=int)\n    else:\n        scan_times = np.linspace(0, hills_length-1, profile_length, dtype=int)\n\n    number_of_minima = self.minima.shape[0]\n    self.free_profile = np.zeros((self.minima[\"Minimum\"].shape[0]+1))\n\n    cvs = self.cvs\n    cv_min, cv_max = self.cv_min, self.cv_max\n    cv_fes_range = self.cv_max - self.cv_min\n\n    fes = np.zeros((self.res, self.res))\n\n    last_time = 0\n\n    for time in scan_times:\n        minima_cv_matrix = np.array(\n            self.minima.iloc[:, cvs+2:2*cvs+2], dtype=float\n        )\n        for coords in product(*minima_cv_matrix.T):\n            dist_cvs = []\n            for i in range(cvs):\n                dist_cv = self.cv[:, i][last_time:time] - coords[i]\n                if self.periodic[i]:\n                    dist_cv[dist_cv &lt; -0.5*cv_fes_range[i]\n                            ] += cv_fes_range[i]\n                    dist_cv[dist_cv &gt; +0.5*cv_fes_range[i]\n                            ] -= cv_fes_range[i]\n                dist_cvs.append(dist_cv)\n            dp2 = np.sum(np.array(dist_cvs)**2, axis=0) / \\\n                (2*self.sigma[:, 0][last_time:time]**2)\n            tmp = np.zeros(self.cv[:, 0][last_time:time].shape)\n            tmp[dp2 &lt; 2.5] = self.heights[last_time:time][dp2 &lt; 2.5] * \\\n                (np.exp(-dp2[dp2 &lt; 2.5]) *\n                 1.00193418799744762399 - 0.00193418799744762399)\n            fes[tuple([\n                int((float(coords[i])-cv_min[i])*self.res/cv_fes_range[i]) for i in range(cvs)\n            ])] -= tmp.sum()\n\n        # save profile\n        profile_line = [time]\n        for m in range(number_of_minima):\n            profile = fes[tuple([\n                int(float(self.minima.iloc[m, i+2])) for i in range(cvs)\n            ])] - fes[tuple([\n                int(float(self.minima.iloc[0, i+2])) for i in range(cvs)\n            ])]\n            profile_line.append(profile)\n        self.free_profile = np.vstack([self.free_profile, profile_line])\n\n        last_time = time\n</code></pre>"},{"location":"reference/catflow/metad/profile/#catflow.metad.profile.FreeEnergyProfile.plot","title":"<code>plot(image_size=[10, 7], xlabel=None, ylabel=None, time_unit='ps', energy_unit='kJ/mol', label_size=12, cmap='RdYlBu', png_name=None, **kwargs)</code>","text":"<p>Visualization function for Free Energy Profile (FEP).</p> <p>Usage: <pre><code>fep.plot()\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the .png file to save the plot to. Defaults to be \"FEProfile.png\".</p> required <code>image_size</code> <code>List[int]</code> <p>List of two dimensions of the picture. Defaults to be [10, 7].</p> <code>[10, 7]</code> <code>xlabel</code> <code>str</code> <p>X-axis label. Defaults to be None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label. Defaults to be None.</p> <code>None</code> <code>label_size</code> <code>int</code> <p>Size of labels. Defaults to be 12.</p> <code>12</code> <code>cmap</code> <code>str</code> <p>Matplotlib colormap used for coloring the line of the minima. Defaults to be \"jet\".</p> <code>'RdYlBu'</code> Source code in <code>catflow/metad/profile.py</code> <pre><code>def plot(\n    self,\n    image_size: List[int] = [10, 7],\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n    time_unit: str = \"ps\",\n    energy_unit: str = \"kJ/mol\",\n    label_size: int = 12,\n    cmap: Union[str, Colormap] = \"RdYlBu\",\n    png_name: Optional[str] = None,\n    **kwargs\n):\n    \"\"\"\n    Visualization function for Free Energy Profile (FEP).\n\n    Usage:\n    ```python\n    fep.plot()\n    ```\n\n    Args:\n        name (str): Name for the .png file to save the plot to. Defaults to be \"FEProfile.png\".\n        image_size (List[int]): List of two dimensions of the picture. Defaults to be [10, 7].\n        xlabel (str, optional): X-axis label. Defaults to be None.\n        ylabel (str, optional): Y-axis label. Defaults to be None.\n        label_size (int): Size of labels. Defaults to be 12.\n        cmap (str): Matplotlib colormap used for coloring the line of the minima. Defaults to be \"jet\".\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    import matplotlib.cm as cm\n\n    canvas_style(**kwargs)\n\n    fig, ax = plt.subplots(figsize=(image_size[0], image_size[1]))\n\n    if type(cmap) == str:\n        cmap = cm.get_cmap(cmap)\n\n    # colors = cm.jet((self.minima.iloc[:,1].to_numpy()).astype(float)/\\\n    #                (np.max(self.minima.iloc[:,1].to_numpy().astype(float))))\n    colors = cmap(np.linspace(0.15, 0.85, self.minima.shape[0]))\n    for m in range(self.minima.shape[0]):\n        ax.plot(\n            self.free_profile[:, 0],\n            self.free_profile[:, m+1],\n            color=colors[m],\n            label=f\"Minima {self.minima.iloc[m, 0]}\",\n        )\n\n    ax.legend()\n\n    if xlabel == None:\n        ax.set_xlabel(f'Time ({time_unit})')\n    else:\n        ax.set_xlabel(xlabel)\n    if ylabel == None:\n        ax.set_ylabel(f'Free energy difference ({energy_unit})')\n    else:\n        ax.set_ylabel(ylabel)\n\n    if png_name != None:\n        fig.savefig(png_name)\n</code></pre>"},{"location":"reference/catflow/metad/string/","title":"string","text":"<p>Inspired by GitHub Repository: https://github.com/apallath/stringmethod @author Akash Pallath Licensed under the MIT license, see LICENSE for details.</p> <p>Reference: Weinan E, \"Simplified and improved string method for computing the minimum energy paths in barrier-crossing events\", J. Chem. Phys. 126, 164103 (2007), https://doi.org/10.1063/1.2720838</p>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod","title":"<code>StringMethod</code>","text":"<p>Class containing methods to compute the minimum energy path between two points on an energy landscape \\(V\\).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Array of shape (nx,) specifying x-axis coordinates of grid.</p> required <code>y</code> <p>Array of shape (ny,) specifying y-axis coordinates of grid.</p> required <code>V</code> <p>Array of shape (ny, nx) or (nx, ny) specifying energy values at each point on the grid. Missing values should be set to np.inf.</p> required <code>indexing</code> <code>Literal['xy', 'ij']</code> <p>Indexing of V array ('xy' specifies (ny, nx), 'ij' specifies (nx, ny); default = 'xy').</p> <code>'xy'</code> <p>Attributes:</p> Name Type Description <code>x</code> <p>Array of shape (nx,) specifying x-axis coordinates of grid.</p> <code>y</code> <p>Array of shape (ny,) specifying y-axis coordinates of grid.</p> <code>V</code> <p>Array of shape (ny, nx) or (nx, ny) specifying energy values at each point on the grid.</p> <code>X</code> <p>Grid of shape (ny, nx) or (nx, ny) containing x-coordinates of each point on the grid.</p> <code>Y</code> <p>Grid of shape (ny, nx) or (nx, ny) containing y-coordinates of each point on the grid.</p> <code>indexing</code> <p>Indexing of V, X, and Y arrays ('xy' specifies (ny, nx), 'ij' specifies (nx, ny); default = 'xy').</p> <code>gradX</code> <p>Gradient in x.</p> <code>gradY</code> <p>Gradient in y.</p> <code>string_traj</code> <p>Trajectory showing the evolution of the string (default=[]).</p> <code>mep</code> <p>Converged minimum energy path (default=None, if not converged).</p> Source code in <code>catflow/metad/string.py</code> <pre><code>class StringMethod:\n    \"\"\"\n    Class containing methods to compute the minimum energy path between two\n    points on an energy landscape $V$.\n\n    Args:\n        x: Array of shape (nx,) specifying x-axis coordinates of grid.\n        y: Array of shape (ny,) specifying y-axis coordinates of grid.\n        V: Array of shape (ny, nx) or (nx, ny) specifying energy values at each point on the grid.\n            Missing values should be set to np.inf.\n        indexing: Indexing of V array ('xy' specifies (ny, nx), 'ij' specifies (nx, ny); default = 'xy').\n\n    Attributes:\n        x: Array of shape (nx,) specifying x-axis coordinates of grid.\n        y: Array of shape (ny,) specifying y-axis coordinates of grid.\n        V: Array of shape (ny, nx) or (nx, ny) specifying energy values at each point on the grid.\n        X: Grid of shape (ny, nx) or (nx, ny) containing x-coordinates of each point on the grid.\n        Y: Grid of shape (ny, nx) or (nx, ny) containing y-coordinates of each point on the grid.\n        indexing: Indexing of V, X, and Y arrays ('xy' specifies (ny, nx), 'ij' specifies (nx, ny); default = 'xy').\n        gradX: Gradient in x.\n        gradY: Gradient in y.\n        string_traj: Trajectory showing the evolution of the string (default=[]).\n        mep: Converged minimum energy path (default=None, if not converged).\n    \"\"\"\n\n    def __init__(self, fes: FreeEnergySurface, indexing: Literal['xy', 'ij'] = 'xy'):\n        self.fes = fes\n        try:\n            self.x = np.linspace(fes.cv_min[0], fes.cv_max[0], fes.res)\n            self.y = np.linspace(fes.cv_min[1], fes.cv_max[1], fes.res)\n        except IndexError:\n            raise ValueError(\n                \"FES should contain at least 2 CVs.\"\n            )\n        if fes.fes is None:\n            raise ValueError(\n                \"FES not calculated yet. Use makefes() or makefes2() first.\"\n            )\n        else:\n            self.V = fes.fes.T\n\n        # Generate grids\n        self.X, self.Y = np.meshgrid(self.x, self.y, indexing=indexing)\n        self.grid = np.vstack([self.X.ravel(), self.Y.ravel()]).T\n\n        # Compute gradients\n        self.indexing = indexing\n\n        if self.indexing == 'xy':\n            self.gradY, self.gradX = np.gradient(self.V, self.x, self.y)\n        elif self.indexing == 'ij':\n            self.gradX, self.gradY = np.gradient(self.V, self.x, self.y)\n        else:\n            raise ValueError(\"Indexing method not recognized.\")\n\n        # String method variables\n        self.string_traj = []\n        self.mep = None\n\n    def compute_mep(\n        self,\n        begin: Union[np.ndarray, List[int], Tuple[int, int]],\n        end: Union[np.ndarray, List[int], Tuple[int, int]],\n        mid: List[Union[np.ndarray, List[int], Tuple[int, int]]] = [],\n        function: str = 'linear',\n        n_points: int = 100,\n        integrator: Literal[\"forward_euler\", \"rk4\"] = \"forward_euler\",\n        dt: float = 0.1,\n        tol: Optional[float] = None,\n        max_steps: int = 100,\n        traj_each: int = 10,\n        flexible: bool = True,\n        grid_method: Literal[\"cubic\", \"linear\"] = \"linear\"\n    ):\n        \"\"\"\n        Computes the minimum free energy path. The points `begin`\n        and `end` and the midpoints passed through `mid` are used to generate\n        an initial guess (a k-order spline which interpolates through all the points).\n        If no midpoints are defined, then the initial guess is a line connecting `begin`\n        and `end`. If `flexible` is set to False, the ends of the string are fixed to `begin`\n        and `end`, otherwise the ends of the string are free to move.\n\n        Args:\n            begin: Array of shape (2,) specifying starting point of the string.\n            end: Array of shape (2,) specifying end point of the string.\n            mid: List of arrays of shape (2,) specifying points between `begin` and `end`\n                to use for generating an initial guess of the minimum energy path (default=[]).\n            function: The radial basis function used for interpolation. (default='linear').\n            n_points: Number of points between any two valuesalong the string (default=100).\n            integrator: Integration scheme to use (default='forward_euler'). Options=['forward_euler'].\n            dt: Integration timestep (default=0.1).\n            tol: Convergence criterion; stop stepping if string has an RMSD &lt; tol between\n                consecutive steps (default = max{npts^-4, 10^-10}).\n            max_steps: Maximum number of steps to take (default=100).\n            traj_each: Interval to store string trajectory (default=10).\n            flexible: If False, the ends of the string are fixed (default=True).\n\n        Returns:\n            mep: Array of shape (npts, 2) specifying string images along the minimum energy path between `begin` and `end`.\n        \"\"\"\n        # Calculate params\n        if tol is None:\n            tol = max([n_points**-4, 1e-10])\n\n        # Generate initial guess\n        if len(mid) &gt; 0:\n            string_x = np.linspace(begin[0], end[0], n_points)\n            xpts = [begin[0]] + [mpt[0] for mpt in mid] + [end[0]]\n            ypts = [begin[1]] + [mpt[1] for mpt in mid] + [end[1]]\n            spline = Rbf(xpts, ypts, function=function)\n            string_y = spline(string_x)\n        else:\n            string_x = np.linspace(begin[0], end[0], n_points)\n            string_y = np.linspace(begin[1], end[1], n_points)\n\n        string = np.vstack([string_x, string_y]).T\n\n        # Store initial guess\n        self.string_traj = []\n        self.string_traj.append(string)\n\n        # Loop\n        old_string = np.zeros_like(string)\n\n        for t_step in range(1, max_steps + 1):\n            # Integrator step\n            if integrator == \"forward_euler\":\n                old_string[:] = string\n                string = self.step_euler(\n                    string, dt, flexible=flexible, grid_method=grid_method\n                )\n            elif integrator == \"rk4\":\n                old_string[:] = string\n                string = self.step_rk4(\n                    string, dt, flexible=flexible, grid_method=grid_method\n                )\n            else:\n                raise ValueError(\"Invalid integrator\")\n\n            # Reparameterize string (equal arc length reparameterization)\n            arc_length = np.hstack(\n                [0, np.cumsum(np.linalg.norm(string[1:] - string[:-1], axis=1))])\n            arc_length /= arc_length[-1]\n            reparam_x = interp1d(arc_length, string[:, 0], kind=\"cubic\")\n            reparam_y = interp1d(arc_length, string[:, 1], kind=\"cubic\")\n            gamma = np.linspace(0, 1, n_points)\n            string = np.vstack([reparam_x(gamma), reparam_y(gamma)]).T\n\n            # Store\n            string_change = np.sqrt(np.mean((string - old_string) ** 2))\n            if t_step % traj_each == 0:\n                self.string_traj.append(string)\n                # Print convergence\n                logger.info(\n                    \"Change in string: {:.10f}\".format(string_change)\n                )\n\n            # Test for convergence\n            if string_change &lt; tol:\n                logger.info(\"Change in string lower than tolerance.\")\n                logger.info(f\"Converged in {t_step + 1} steps.\")\n                break\n\n        # Store minimum energy path\n        self.mep = string\n\n    def load_minima(\n        self,\n        nbins: int = 8\n    ):\n        if self.fes.minima is None:\n            self.fes.find_minima(nbins)\n        self.minima = self.fes.minima\n        logger.info(self.minima)\n\n    def mep_from_minima(\n        self,\n        begin_index: int,\n        end_index: int,\n        mid_indices: Optional[List[int]] = None,\n        *,\n        nbins: int = 8,\n        **kwargs\n    ):\n        \"\"\"Calculate MEP from given reaction path through index of local minima.\n\n        Args:\n            begin_index (int): The index of starting local minima.\n            end_index (int): The index of ending local minima.\n            mid_indices (List[int], optional): The index of path in the middle of reaction path. Defaults to [].\n            minima (Optional[Minima], optional): If minima not loaded, please select here. Defaults to None.\n            nbins (int, optional): Refer to minima.Minima. Defaults to 8.\n\n        Raises:\n            ValueError: `self.minima` should not be None, or please provide one into `minima` to load it.\n        \"\"\"\n        if self.minima is None:\n            self.load_minima(nbins)\n\n        minima_x = self.minima.filter(regex=r\"^CV1\\s+-\\s+\")  # type: ignore\n        minima_y = self.minima.filter(regex=r\"^CV2\\s+-\\s+\")  # type: ignore\n        begin_x = minima_x.iloc[begin_index].values[0]\n        begin_y = minima_y.iloc[begin_index].values[0]\n        end_x = minima_x.iloc[end_index].values[0]\n        end_y = minima_y.iloc[end_index].values[0]\n        if mid_indices is not None:\n            mid = [[minima_x.iloc[i].values[0], minima_y.iloc[i].values[0]]\n                   for i in mid_indices]\n        else:\n            mid = []\n        self.compute_mep(\n            begin=[begin_x, begin_y],\n            mid=mid,  # type: ignore\n            end=[end_x, end_y],\n            **kwargs\n        )\n\n    def step_euler(self, string, dt, flexible=True, grid_method=\"linear\"):\n        \"\"\"\n        Evolves string images in time in response to forces calculated from the energy landscape using the forward Euler method.\n\n        Args:\n            string: Array of shape (npts, 2) specifying string images at the previous timestep.\n            dt: Timestep.\n            flexible: If False, the ends of the string are fixed (default=True).\n            grid_method: Method used to interpolate the gradient (default=\"linear\").\n\n        Returns:\n            newstring: Array of shape (npts, 2) specifying string images after a timestep.\n        \"\"\"\n        # Compute gradients at string points\n        string_grad_x = griddata(\n            self.grid, self.gradX.ravel(), string, method=grid_method)\n        string_grad_y = griddata(\n            self.grid, self.gradY.ravel(), string, method=grid_method)\n        h = np.max(np.sqrt(string_grad_x**2 + string_grad_y**2))\n\n        # Euler step\n        if flexible:\n            string = string - dt * \\\n                np.vstack([string_grad_x, string_grad_y]).T / h\n        else:\n            string[1:-1] = (\n                string[1:-1] - dt *\n                np.vstack([string_grad_x, string_grad_y]).T[1:-1] / h\n            )\n\n        return string\n\n    def step_rk4(self, string, dt, flexible=True, grid_method=\"linear\"):\n        \"\"\"\n        Evolves string images in time in response to forces calculated from the energy landscape using the fourth-order Runge-Kutta method.\n\n        Args:\n            string: Array of shape (npts, 2) specifying string images at the previous timestep.\n            dt: Timestep.\n            flexible: If False, the ends of the string are fixed (default=True).\n            grid_method: Method used to interpolate the gradient (default=\"linear\").\n\n        Returns:\n            string: Array of shape (npts, 2) specifying string images after a timestep.\n        \"\"\"\n\n        string_grad_x = griddata(\n            self.grid, self.gradX.ravel(), string, method=grid_method)\n        string_grad_y = griddata(\n            self.grid, self.gradY.ravel(), string, method=grid_method)\n        h = np.max(np.sqrt(string_grad_x**2 + string_grad_y**2))\n\n        k1 = dt * np.vstack([string_grad_x, string_grad_y]).T / h\n\n        string_grad_x_1 = griddata(\n            self.grid, self.gradX.ravel(), string + k1/2, method=grid_method)\n        string_grad_y_1 = griddata(\n            self.grid, self.gradY.ravel(), string + k1/2, method=grid_method)\n        h1 = np.max(np.sqrt(string_grad_x_1**2 + string_grad_y_1**2))\n        k2 = dt * np.vstack([string_grad_x_1, string_grad_y_1]).T / h1\n\n        string_grad_x_2 = griddata(\n            self.grid, self.gradX.ravel(), string + k2/2, method=grid_method)\n        string_grad_y_2 = griddata(\n            self.grid, self.gradY.ravel(), string + k2/2, method=grid_method)\n        h2 = np.max(np.sqrt(string_grad_x_2**2 + string_grad_y_2**2))\n        k3 = dt * np.vstack([string_grad_x_2, string_grad_y_2]).T / h2\n\n        string_grad_x_3 = griddata(\n            self.grid, self.gradX.ravel(), string + k3, method=grid_method)\n        string_grad_y_3 = griddata(\n            self.grid, self.gradY.ravel(), string + k3, method=grid_method)\n        h3 = np.max(np.sqrt(string_grad_x_3**2 + string_grad_y_3**2))\n        k4 = dt * np.vstack([string_grad_x_3, string_grad_y_3]).T / h3\n\n        if flexible:\n            string = string - (k1 + 2*k2 + 2*k3 + k4) / 6\n        else:\n            string[1:-1] = \\\n                string[1:-1] - (k1[1:-1] + 2*k2[1:-1] +\n                                2*k3[1:-1] + k4[1:-1]) / 6\n        return string\n\n    def get_mep_energy_profile(self):\n        energy_mep = griddata(self.grid, self.V.ravel(),\n                              self.mep, method=\"linear\")\n        return self.mep, energy_mep\n\n    def plot_mep(self, path_color=\"white\", **kwargs):\n        \"\"\"\n        Plots the minimum energy path on the energy landscape $V$.\n\n        Args:\n            **plot_V_kwargs: Keyword arguments for plotting the energy landscape V.\n        \"\"\"\n        fes = self.fes\n        fig, ax = fes.plot(**kwargs)\n\n        if self.mep is None:\n            raise ValueError(\"No MEP found. Please run `compute_mep` first.\")\n\n        ax.scatter(self.mep[0, 0], self.mep[0, 1], color=path_color)\n        ax.scatter(self.mep[-1, 0], self.mep[-1, 1], color=path_color)\n        ax.plot(self.mep[:, 0], self.mep[:, 1], color=path_color)\n        return fig, ax\n\n    def plot_mep_energy_profile(self, energy_unit=\"kJ/mol\", dpi=96):\n        \"\"\"\n        Plots the energy profile along the minimum energy path in $V$.\n        \"\"\"\n        energy_mep = griddata(self.grid, self.V.ravel(),\n                              self.mep, method=\"linear\")\n        fig, ax = plt.subplots(dpi=dpi)\n        ax.plot(np.linspace(0, 1, len(energy_mep)), energy_mep)\n        ax.set_xlabel(\"Reaction coordinate\")\n        ax.set_ylabel(f\"Free Energy ({energy_unit})\")\n        return fig, ax\n\n    def plot_string_evolution(self, string_cmap=cm.gray, **kwargs):\n        \"\"\"\n        Plots the evolution of the string on the energy landscape $V$.\n\n        Args:\n            string_cmap: Colormap to use for plotting the evolution of the string.\n            **plot_V_kwargs: Keyword arguments for plotting the energy landscape V.\n        \"\"\"\n        fig, ax = self.fes.plot(**kwargs)\n        if self.mep is None:\n            raise ValueError(\"No MEP found. Please run `compute_mep` first.\")\n\n        colors = string_cmap(np.linspace(0, 1, len(self.string_traj)))\n        for sidx, string in enumerate(self.string_traj):\n            ax.plot(string[:, 0], string[:, 1], \"--\", color=colors[sidx])\n\n        return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.compute_mep","title":"<code>compute_mep(begin, end, mid=[], function='linear', n_points=100, integrator='forward_euler', dt=0.1, tol=None, max_steps=100, traj_each=10, flexible=True, grid_method='linear')</code>","text":"<p>Computes the minimum free energy path. The points <code>begin</code> and <code>end</code> and the midpoints passed through <code>mid</code> are used to generate an initial guess (a k-order spline which interpolates through all the points). If no midpoints are defined, then the initial guess is a line connecting <code>begin</code> and <code>end</code>. If <code>flexible</code> is set to False, the ends of the string are fixed to <code>begin</code> and <code>end</code>, otherwise the ends of the string are free to move.</p> <p>Parameters:</p> Name Type Description Default <code>begin</code> <code>Union[ndarray, List[int], Tuple[int, int]]</code> <p>Array of shape (2,) specifying starting point of the string.</p> required <code>end</code> <code>Union[ndarray, List[int], Tuple[int, int]]</code> <p>Array of shape (2,) specifying end point of the string.</p> required <code>mid</code> <code>List[Union[ndarray, List[int], Tuple[int, int]]]</code> <p>List of arrays of shape (2,) specifying points between <code>begin</code> and <code>end</code> to use for generating an initial guess of the minimum energy path (default=[]).</p> <code>[]</code> <code>function</code> <code>str</code> <p>The radial basis function used for interpolation. (default='linear').</p> <code>'linear'</code> <code>n_points</code> <code>int</code> <p>Number of points between any two valuesalong the string (default=100).</p> <code>100</code> <code>integrator</code> <code>Literal['forward_euler', 'rk4']</code> <p>Integration scheme to use (default='forward_euler'). Options=['forward_euler'].</p> <code>'forward_euler'</code> <code>dt</code> <code>float</code> <p>Integration timestep (default=0.1).</p> <code>0.1</code> <code>tol</code> <code>Optional[float]</code> <p>Convergence criterion; stop stepping if string has an RMSD &lt; tol between consecutive steps (default = max{npts^-4, 10^-10}).</p> <code>None</code> <code>max_steps</code> <code>int</code> <p>Maximum number of steps to take (default=100).</p> <code>100</code> <code>traj_each</code> <code>int</code> <p>Interval to store string trajectory (default=10).</p> <code>10</code> <code>flexible</code> <code>bool</code> <p>If False, the ends of the string are fixed (default=True).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>mep</code> <p>Array of shape (npts, 2) specifying string images along the minimum energy path between <code>begin</code> and <code>end</code>.</p> Source code in <code>catflow/metad/string.py</code> <pre><code>def compute_mep(\n    self,\n    begin: Union[np.ndarray, List[int], Tuple[int, int]],\n    end: Union[np.ndarray, List[int], Tuple[int, int]],\n    mid: List[Union[np.ndarray, List[int], Tuple[int, int]]] = [],\n    function: str = 'linear',\n    n_points: int = 100,\n    integrator: Literal[\"forward_euler\", \"rk4\"] = \"forward_euler\",\n    dt: float = 0.1,\n    tol: Optional[float] = None,\n    max_steps: int = 100,\n    traj_each: int = 10,\n    flexible: bool = True,\n    grid_method: Literal[\"cubic\", \"linear\"] = \"linear\"\n):\n    \"\"\"\n    Computes the minimum free energy path. The points `begin`\n    and `end` and the midpoints passed through `mid` are used to generate\n    an initial guess (a k-order spline which interpolates through all the points).\n    If no midpoints are defined, then the initial guess is a line connecting `begin`\n    and `end`. If `flexible` is set to False, the ends of the string are fixed to `begin`\n    and `end`, otherwise the ends of the string are free to move.\n\n    Args:\n        begin: Array of shape (2,) specifying starting point of the string.\n        end: Array of shape (2,) specifying end point of the string.\n        mid: List of arrays of shape (2,) specifying points between `begin` and `end`\n            to use for generating an initial guess of the minimum energy path (default=[]).\n        function: The radial basis function used for interpolation. (default='linear').\n        n_points: Number of points between any two valuesalong the string (default=100).\n        integrator: Integration scheme to use (default='forward_euler'). Options=['forward_euler'].\n        dt: Integration timestep (default=0.1).\n        tol: Convergence criterion; stop stepping if string has an RMSD &lt; tol between\n            consecutive steps (default = max{npts^-4, 10^-10}).\n        max_steps: Maximum number of steps to take (default=100).\n        traj_each: Interval to store string trajectory (default=10).\n        flexible: If False, the ends of the string are fixed (default=True).\n\n    Returns:\n        mep: Array of shape (npts, 2) specifying string images along the minimum energy path between `begin` and `end`.\n    \"\"\"\n    # Calculate params\n    if tol is None:\n        tol = max([n_points**-4, 1e-10])\n\n    # Generate initial guess\n    if len(mid) &gt; 0:\n        string_x = np.linspace(begin[0], end[0], n_points)\n        xpts = [begin[0]] + [mpt[0] for mpt in mid] + [end[0]]\n        ypts = [begin[1]] + [mpt[1] for mpt in mid] + [end[1]]\n        spline = Rbf(xpts, ypts, function=function)\n        string_y = spline(string_x)\n    else:\n        string_x = np.linspace(begin[0], end[0], n_points)\n        string_y = np.linspace(begin[1], end[1], n_points)\n\n    string = np.vstack([string_x, string_y]).T\n\n    # Store initial guess\n    self.string_traj = []\n    self.string_traj.append(string)\n\n    # Loop\n    old_string = np.zeros_like(string)\n\n    for t_step in range(1, max_steps + 1):\n        # Integrator step\n        if integrator == \"forward_euler\":\n            old_string[:] = string\n            string = self.step_euler(\n                string, dt, flexible=flexible, grid_method=grid_method\n            )\n        elif integrator == \"rk4\":\n            old_string[:] = string\n            string = self.step_rk4(\n                string, dt, flexible=flexible, grid_method=grid_method\n            )\n        else:\n            raise ValueError(\"Invalid integrator\")\n\n        # Reparameterize string (equal arc length reparameterization)\n        arc_length = np.hstack(\n            [0, np.cumsum(np.linalg.norm(string[1:] - string[:-1], axis=1))])\n        arc_length /= arc_length[-1]\n        reparam_x = interp1d(arc_length, string[:, 0], kind=\"cubic\")\n        reparam_y = interp1d(arc_length, string[:, 1], kind=\"cubic\")\n        gamma = np.linspace(0, 1, n_points)\n        string = np.vstack([reparam_x(gamma), reparam_y(gamma)]).T\n\n        # Store\n        string_change = np.sqrt(np.mean((string - old_string) ** 2))\n        if t_step % traj_each == 0:\n            self.string_traj.append(string)\n            # Print convergence\n            logger.info(\n                \"Change in string: {:.10f}\".format(string_change)\n            )\n\n        # Test for convergence\n        if string_change &lt; tol:\n            logger.info(\"Change in string lower than tolerance.\")\n            logger.info(f\"Converged in {t_step + 1} steps.\")\n            break\n\n    # Store minimum energy path\n    self.mep = string\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.mep_from_minima","title":"<code>mep_from_minima(begin_index, end_index, mid_indices=None, *, nbins=8, **kwargs)</code>","text":"<p>Calculate MEP from given reaction path through index of local minima.</p> <p>Parameters:</p> Name Type Description Default <code>begin_index</code> <code>int</code> <p>The index of starting local minima.</p> required <code>end_index</code> <code>int</code> <p>The index of ending local minima.</p> required <code>mid_indices</code> <code>List[int]</code> <p>The index of path in the middle of reaction path. Defaults to [].</p> <code>None</code> <code>minima</code> <code>Optional[Minima]</code> <p>If minima not loaded, please select here. Defaults to None.</p> required <code>nbins</code> <code>int</code> <p>Refer to minima.Minima. Defaults to 8.</p> <code>8</code> <p>Raises:</p> Type Description <code>ValueError</code> <p><code>self.minima</code> should not be None, or please provide one into <code>minima</code> to load it.</p> Source code in <code>catflow/metad/string.py</code> <pre><code>def mep_from_minima(\n    self,\n    begin_index: int,\n    end_index: int,\n    mid_indices: Optional[List[int]] = None,\n    *,\n    nbins: int = 8,\n    **kwargs\n):\n    \"\"\"Calculate MEP from given reaction path through index of local minima.\n\n    Args:\n        begin_index (int): The index of starting local minima.\n        end_index (int): The index of ending local minima.\n        mid_indices (List[int], optional): The index of path in the middle of reaction path. Defaults to [].\n        minima (Optional[Minima], optional): If minima not loaded, please select here. Defaults to None.\n        nbins (int, optional): Refer to minima.Minima. Defaults to 8.\n\n    Raises:\n        ValueError: `self.minima` should not be None, or please provide one into `minima` to load it.\n    \"\"\"\n    if self.minima is None:\n        self.load_minima(nbins)\n\n    minima_x = self.minima.filter(regex=r\"^CV1\\s+-\\s+\")  # type: ignore\n    minima_y = self.minima.filter(regex=r\"^CV2\\s+-\\s+\")  # type: ignore\n    begin_x = minima_x.iloc[begin_index].values[0]\n    begin_y = minima_y.iloc[begin_index].values[0]\n    end_x = minima_x.iloc[end_index].values[0]\n    end_y = minima_y.iloc[end_index].values[0]\n    if mid_indices is not None:\n        mid = [[minima_x.iloc[i].values[0], minima_y.iloc[i].values[0]]\n               for i in mid_indices]\n    else:\n        mid = []\n    self.compute_mep(\n        begin=[begin_x, begin_y],\n        mid=mid,  # type: ignore\n        end=[end_x, end_y],\n        **kwargs\n    )\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.plot_mep","title":"<code>plot_mep(path_color='white', **kwargs)</code>","text":"<p>Plots the minimum energy path on the energy landscape \\(V\\).</p> <p>Parameters:</p> Name Type Description Default <code>**plot_V_kwargs</code> <p>Keyword arguments for plotting the energy landscape V.</p> required Source code in <code>catflow/metad/string.py</code> <pre><code>def plot_mep(self, path_color=\"white\", **kwargs):\n    \"\"\"\n    Plots the minimum energy path on the energy landscape $V$.\n\n    Args:\n        **plot_V_kwargs: Keyword arguments for plotting the energy landscape V.\n    \"\"\"\n    fes = self.fes\n    fig, ax = fes.plot(**kwargs)\n\n    if self.mep is None:\n        raise ValueError(\"No MEP found. Please run `compute_mep` first.\")\n\n    ax.scatter(self.mep[0, 0], self.mep[0, 1], color=path_color)\n    ax.scatter(self.mep[-1, 0], self.mep[-1, 1], color=path_color)\n    ax.plot(self.mep[:, 0], self.mep[:, 1], color=path_color)\n    return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.plot_mep_energy_profile","title":"<code>plot_mep_energy_profile(energy_unit='kJ/mol', dpi=96)</code>","text":"<p>Plots the energy profile along the minimum energy path in \\(V\\).</p> Source code in <code>catflow/metad/string.py</code> <pre><code>def plot_mep_energy_profile(self, energy_unit=\"kJ/mol\", dpi=96):\n    \"\"\"\n    Plots the energy profile along the minimum energy path in $V$.\n    \"\"\"\n    energy_mep = griddata(self.grid, self.V.ravel(),\n                          self.mep, method=\"linear\")\n    fig, ax = plt.subplots(dpi=dpi)\n    ax.plot(np.linspace(0, 1, len(energy_mep)), energy_mep)\n    ax.set_xlabel(\"Reaction coordinate\")\n    ax.set_ylabel(f\"Free Energy ({energy_unit})\")\n    return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.plot_string_evolution","title":"<code>plot_string_evolution(string_cmap=cm.gray, **kwargs)</code>","text":"<p>Plots the evolution of the string on the energy landscape \\(V\\).</p> <p>Parameters:</p> Name Type Description Default <code>string_cmap</code> <p>Colormap to use for plotting the evolution of the string.</p> <code>gray</code> <code>**plot_V_kwargs</code> <p>Keyword arguments for plotting the energy landscape V.</p> required Source code in <code>catflow/metad/string.py</code> <pre><code>def plot_string_evolution(self, string_cmap=cm.gray, **kwargs):\n    \"\"\"\n    Plots the evolution of the string on the energy landscape $V$.\n\n    Args:\n        string_cmap: Colormap to use for plotting the evolution of the string.\n        **plot_V_kwargs: Keyword arguments for plotting the energy landscape V.\n    \"\"\"\n    fig, ax = self.fes.plot(**kwargs)\n    if self.mep is None:\n        raise ValueError(\"No MEP found. Please run `compute_mep` first.\")\n\n    colors = string_cmap(np.linspace(0, 1, len(self.string_traj)))\n    for sidx, string in enumerate(self.string_traj):\n        ax.plot(string[:, 0], string[:, 1], \"--\", color=colors[sidx])\n\n    return fig, ax\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.step_euler","title":"<code>step_euler(string, dt, flexible=True, grid_method='linear')</code>","text":"<p>Evolves string images in time in response to forces calculated from the energy landscape using the forward Euler method.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <p>Array of shape (npts, 2) specifying string images at the previous timestep.</p> required <code>dt</code> <p>Timestep.</p> required <code>flexible</code> <p>If False, the ends of the string are fixed (default=True).</p> <code>True</code> <code>grid_method</code> <p>Method used to interpolate the gradient (default=\"linear\").</p> <code>'linear'</code> <p>Returns:</p> Name Type Description <code>newstring</code> <p>Array of shape (npts, 2) specifying string images after a timestep.</p> Source code in <code>catflow/metad/string.py</code> <pre><code>def step_euler(self, string, dt, flexible=True, grid_method=\"linear\"):\n    \"\"\"\n    Evolves string images in time in response to forces calculated from the energy landscape using the forward Euler method.\n\n    Args:\n        string: Array of shape (npts, 2) specifying string images at the previous timestep.\n        dt: Timestep.\n        flexible: If False, the ends of the string are fixed (default=True).\n        grid_method: Method used to interpolate the gradient (default=\"linear\").\n\n    Returns:\n        newstring: Array of shape (npts, 2) specifying string images after a timestep.\n    \"\"\"\n    # Compute gradients at string points\n    string_grad_x = griddata(\n        self.grid, self.gradX.ravel(), string, method=grid_method)\n    string_grad_y = griddata(\n        self.grid, self.gradY.ravel(), string, method=grid_method)\n    h = np.max(np.sqrt(string_grad_x**2 + string_grad_y**2))\n\n    # Euler step\n    if flexible:\n        string = string - dt * \\\n            np.vstack([string_grad_x, string_grad_y]).T / h\n    else:\n        string[1:-1] = (\n            string[1:-1] - dt *\n            np.vstack([string_grad_x, string_grad_y]).T[1:-1] / h\n        )\n\n    return string\n</code></pre>"},{"location":"reference/catflow/metad/string/#catflow.metad.string.StringMethod.step_rk4","title":"<code>step_rk4(string, dt, flexible=True, grid_method='linear')</code>","text":"<p>Evolves string images in time in response to forces calculated from the energy landscape using the fourth-order Runge-Kutta method.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <p>Array of shape (npts, 2) specifying string images at the previous timestep.</p> required <code>dt</code> <p>Timestep.</p> required <code>flexible</code> <p>If False, the ends of the string are fixed (default=True).</p> <code>True</code> <code>grid_method</code> <p>Method used to interpolate the gradient (default=\"linear\").</p> <code>'linear'</code> <p>Returns:</p> Name Type Description <code>string</code> <p>Array of shape (npts, 2) specifying string images after a timestep.</p> Source code in <code>catflow/metad/string.py</code> <pre><code>def step_rk4(self, string, dt, flexible=True, grid_method=\"linear\"):\n    \"\"\"\n    Evolves string images in time in response to forces calculated from the energy landscape using the fourth-order Runge-Kutta method.\n\n    Args:\n        string: Array of shape (npts, 2) specifying string images at the previous timestep.\n        dt: Timestep.\n        flexible: If False, the ends of the string are fixed (default=True).\n        grid_method: Method used to interpolate the gradient (default=\"linear\").\n\n    Returns:\n        string: Array of shape (npts, 2) specifying string images after a timestep.\n    \"\"\"\n\n    string_grad_x = griddata(\n        self.grid, self.gradX.ravel(), string, method=grid_method)\n    string_grad_y = griddata(\n        self.grid, self.gradY.ravel(), string, method=grid_method)\n    h = np.max(np.sqrt(string_grad_x**2 + string_grad_y**2))\n\n    k1 = dt * np.vstack([string_grad_x, string_grad_y]).T / h\n\n    string_grad_x_1 = griddata(\n        self.grid, self.gradX.ravel(), string + k1/2, method=grid_method)\n    string_grad_y_1 = griddata(\n        self.grid, self.gradY.ravel(), string + k1/2, method=grid_method)\n    h1 = np.max(np.sqrt(string_grad_x_1**2 + string_grad_y_1**2))\n    k2 = dt * np.vstack([string_grad_x_1, string_grad_y_1]).T / h1\n\n    string_grad_x_2 = griddata(\n        self.grid, self.gradX.ravel(), string + k2/2, method=grid_method)\n    string_grad_y_2 = griddata(\n        self.grid, self.gradY.ravel(), string + k2/2, method=grid_method)\n    h2 = np.max(np.sqrt(string_grad_x_2**2 + string_grad_y_2**2))\n    k3 = dt * np.vstack([string_grad_x_2, string_grad_y_2]).T / h2\n\n    string_grad_x_3 = griddata(\n        self.grid, self.gradX.ravel(), string + k3, method=grid_method)\n    string_grad_y_3 = griddata(\n        self.grid, self.gradY.ravel(), string + k3, method=grid_method)\n    h3 = np.max(np.sqrt(string_grad_x_3**2 + string_grad_y_3**2))\n    k4 = dt * np.vstack([string_grad_x_3, string_grad_y_3]).T / h3\n\n    if flexible:\n        string = string - (k1 + 2*k2 + 2*k3 + k4) / 6\n    else:\n        string[1:-1] = \\\n            string[1:-1] - (k1[1:-1] + 2*k2[1:-1] +\n                            2*k3[1:-1] + k4[1:-1]) / 6\n    return string\n</code></pre>"},{"location":"reference/catflow/structure/","title":"structure","text":""},{"location":"reference/catflow/structure/cluster/","title":"cluster","text":""},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.Cluster","title":"<code>Cluster</code>","text":"<p>             Bases: <code>object</code></p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>class Cluster(object):\n    def __init__(self, path=None, **kwargs):\n        self.path = path\n        self.kwargs = kwargs\n        if self.path is not None:\n            self.universe = self.load_mda_trajectory(**self.kwargs)\n\n    @classmethod\n    def convert_universe(cls, u: Universe, **kwargs):\n        \"\"\"Convert mda.Universe instaince to a Cluster instance\n\n        Args:\n            u (Universe): Trajectory instance.\n\n        Returns:\n            Cluster: Cluster instance.\n        \"\"\"\n        cluster = cls(**kwargs)\n        cluster.universe = u\n        return cluster\n\n    def load_mda_trajectory(self, **kwargs) -&gt; Universe:\n        \"\"\"Load trajectory as mda.Universe from file.\n\n        Returns:\n            Universe: Trajectory instance.\n        \"\"\"\n        if kwargs.get(\"topology_format\", None) is None:\n            kwargs[\"topology_format\"] = \"XYZ\"\n        return Universe(self.path, **kwargs)\n\n    def distance_to_com(self, selection_cluster: str):\n        \"\"\"Analyze cluster atoms by calculating distance to center of mass.\n\n        Args:\n            u (Universe): MDA trajectory instance.\n            selection_cluster (str): Selection language to select atoms in cluster.\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        u = self.universe\n        cluster = u.select_atoms(selection_cluster, updating=True)\n        distances = np.zeros((len(u.trajectory), len(cluster)))\n        cg = cluster.center_of_geometry()\n        for q, ts in enumerate(u.trajectory):\n            for p, t in enumerate(cluster.positions):\n                dis = distance.euclidean(t, cg)\n                distances[q, p] = dis\n        return distances\n\n    def lindemann_per_frames(self,\n                             selection_cluster: str,\n                             box: Optional[npt.NDArray] = None,\n                             **run_parameters) -&gt; np.ndarray:\n        u = self.universe\n        ag = u.select_atoms(selection_cluster)\n        li = LindemannIndex(ag, box=box)\n        li.run(**run_parameters)\n\n        lindex_array = np.array(li.results.lindemann_index)\n        return lindex_array\n</code></pre>"},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.Cluster.convert_universe","title":"<code>convert_universe(u, **kwargs)</code>  <code>classmethod</code>","text":"<p>Convert mda.Universe instaince to a Cluster instance</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>Universe</code> <p>Trajectory instance.</p> required <p>Returns:</p> Name Type Description <code>Cluster</code> <p>Cluster instance.</p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>@classmethod\ndef convert_universe(cls, u: Universe, **kwargs):\n    \"\"\"Convert mda.Universe instaince to a Cluster instance\n\n    Args:\n        u (Universe): Trajectory instance.\n\n    Returns:\n        Cluster: Cluster instance.\n    \"\"\"\n    cluster = cls(**kwargs)\n    cluster.universe = u\n    return cluster\n</code></pre>"},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.Cluster.distance_to_com","title":"<code>distance_to_com(selection_cluster)</code>","text":"<p>Analyze cluster atoms by calculating distance to center of mass.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>Universe</code> <p>MDA trajectory instance.</p> required <code>selection_cluster</code> <code>str</code> <p>Selection language to select atoms in cluster.</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>def distance_to_com(self, selection_cluster: str):\n    \"\"\"Analyze cluster atoms by calculating distance to center of mass.\n\n    Args:\n        u (Universe): MDA trajectory instance.\n        selection_cluster (str): Selection language to select atoms in cluster.\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    u = self.universe\n    cluster = u.select_atoms(selection_cluster, updating=True)\n    distances = np.zeros((len(u.trajectory), len(cluster)))\n    cg = cluster.center_of_geometry()\n    for q, ts in enumerate(u.trajectory):\n        for p, t in enumerate(cluster.positions):\n            dis = distance.euclidean(t, cg)\n            distances[q, p] = dis\n    return distances\n</code></pre>"},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.Cluster.load_mda_trajectory","title":"<code>load_mda_trajectory(**kwargs)</code>","text":"<p>Load trajectory as mda.Universe from file.</p> <p>Returns:</p> Name Type Description <code>Universe</code> <code>Universe</code> <p>Trajectory instance.</p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>def load_mda_trajectory(self, **kwargs) -&gt; Universe:\n    \"\"\"Load trajectory as mda.Universe from file.\n\n    Returns:\n        Universe: Trajectory instance.\n    \"\"\"\n    if kwargs.get(\"topology_format\", None) is None:\n        kwargs[\"topology_format\"] = \"XYZ\"\n    return Universe(self.path, **kwargs)\n</code></pre>"},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.distance_to_cnt","title":"<code>distance_to_cnt(u, selection_cluster, cnt_direction)</code>","text":"<p>For carbon nanotube included trajectories, analyze cluster atoms.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>Universe</code> <p>MDA trajectory instance.</p> required <code>selection_cluster</code> <code>str</code> <p>Selection language to select atoms in cluster.</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>def distance_to_cnt(u: Universe, selection_cluster: str, cnt_direction: str):\n    \"\"\"For carbon nanotube included trajectories, analyze cluster atoms.\n\n    Args:\n        u (Universe): MDA trajectory instance.\n        selection_cluster (str): Selection language to select atoms in cluster.\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    cnt = u.select_atoms('name C', updating=True)  # C for carbon\n    cluster = u.select_atoms(selection_cluster, updating=True)\n    distances = np.zeros((len(u.trajectory), len(cluster)))\n    for q, ts in enumerate(u.trajectory):\n        cg = cnt.center_of_geometry()\n        for p, t in enumerate(cluster.positions):\n            if cnt_direction == \"z\":\n                dis = distance.euclidean(t, [cg[0], cg[1], t[2]])\n            elif cnt_direction == \"y\":\n                dis = distance.euclidean(t, [cg[0], t[1], cg[2]])\n            elif cnt_direction == \"x\":\n                dis = distance.euclidean(t, [t[0], cg[1], cg[2]])\n            else:\n                raise ValueError(\"cnt_direction must be x, y or z\")\n            distances[q, p] = dis\n    return distances\n</code></pre>"},{"location":"reference/catflow/structure/cluster/#catflow.structure.cluster.fitting_lindemann_curve","title":"<code>fitting_lindemann_curve(temperature, lindemann, bounds, function='func2')</code>","text":"<p>fit smooth curve from given lindemann index or free energy of each temperature.</p> <p>Parameters:</p> Name Type Description Default <code>temperature</code> <code>_type_</code> <p>list of temperatures.  e.g.: [200, 300, 400, 500, 600, 700, 800]</p> required <code>lindemann</code> <code>_type_</code> <p>list of lindemann index calculated from  trajectories at each temperature</p> required <code>bounds</code> <code>_type_</code> <p>upper and lower bounds of each param in functions. e.g. ([-np.inf, -np.inf, -np.inf, -np.inf, 400, 15.],        [np.inf, np.inf, np.inf, np.inf, 700., 100.])</p> required <code>function</code> <code>str</code> <p>function used to fit the curve. Defaults to 'func2'.</p> <code>'func2'</code> <p>Returns:</p> Type Description <p>pd.DataFrame: description</p> Source code in <code>catflow/structure/cluster.py</code> <pre><code>def fitting_lindemann_curve(\n        temperature,\n        lindemann,\n        bounds,\n        function='func2'\n):\n    \"\"\"fit smooth curve from given lindemann index or free energy of each temperature.\n\n    Args:\n        temperature (_type_): list of temperatures. \n            e.g.: [200, 300, 400, 500, 600, 700, 800]\n        lindemann (_type_): list of lindemann index calculated from \n            trajectories at each temperature\n        bounds (_type_): upper and lower bounds of each param in functions.\n            e.g. ([-np.inf, -np.inf, -np.inf, -np.inf, 400, 15.], \n                  [np.inf, np.inf, np.inf, np.inf, 700., 100.])\n        function (str, optional): function used to fit the curve. Defaults to 'func2'.\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n\n    def func(x, a, b, c, d, x0, dx):\n        return b + (a - b) * x + d / (1 + np.exp((x - x0) / dx)) + c * x\n\n    def func2(x, a, b, c, d, x0, dx):\n        return (a * x + b) / (1 + np.exp((x - x0) / dx)) + \\\n               (c * x + d) / (1 + np.exp((x0 - x) / dx))\n\n    if function == 'func2':\n        fit_func = func2\n    else:\n        fit_func = func\n\n    popt, pcov = curve_fit(\n        fit_func, temperature, lindemann,\n        bounds=bounds\n    )\n    x_pred = np.linspace(min(temperature), max(temperature), 100)\n\n    df = pd.DataFrame({\n        'temperature': x_pred,\n        'fitting_curve': fit_func(x_pred, *popt)\n    })\n    return df\n</code></pre>"},{"location":"reference/catflow/structure/coordination_number/","title":"coordination_number","text":""},{"location":"reference/catflow/structure/dynamic_selection/","title":"dynamic_selection","text":""},{"location":"reference/catflow/structure/dynamic_selection/#catflow.structure.dynamic_selection.AxisMaxDistance","title":"<code>AxisMaxDistance</code>","text":"<p>             Bases: <code>AnalysisBase</code></p> <p>Calculates the maximum distance between two groups of atoms along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>ag1</code> <code>AtomGroup</code> <p>The first group of atoms.</p> required <code>ag2</code> <code>AtomGroup</code> <p>The second group of atoms.</p> required <code>universe</code> <code>Universe</code> <p>The MDAnalysis universe containing the atoms.</p> required <code>axis</code> <code>str</code> <p>The axis along which to calculate the maximum distance.</p> <code>'z'</code> <code>box</code> <code>ndarray or None</code> <p>The dimensions of the simulation box,  or None if periodic boundary conditions are not used.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent class.</p> <code>{}</code> Return <p>results (MDAnalysis.analysis.base.AnalysisResults): The results of the analysis.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>axis</code> is not \"x\", \"y\", or \"z\".</p> Notes <p>This class is a subclass of <code>MDAnalysis.analysis.base.AnalysisBase</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import MDAnalysis as mda\n&gt;&gt;&gt; from catflow.structure.dynamic_selection import AxisMaxDistance\n&gt;&gt;&gt; u = mda.Universe(\"system.gro\", \"system.trr\")\n&gt;&gt;&gt; ag1 = u.select_atoms(\"protein\")\n&gt;&gt;&gt; ag2 = u.select_atoms(\"resname LIG\")\n&gt;&gt;&gt; analysis = AxisMaxDistance(ag1, ag2, axis=\"x\", box=u.dimensions)\n&gt;&gt;&gt; analysis.run()\n&gt;&gt;&gt; max_distances = analysis.results.distances\n</code></pre> Source code in <code>catflow/structure/dynamic_selection.py</code> <pre><code>class AxisMaxDistance(AnalysisBase):\n    \"\"\"Calculates the maximum distance between two groups of atoms along a given axis.\n\n    Args:\n        ag1 (mda.AtomGroup): The first group of atoms.\n        ag2 (mda.AtomGroup): The second group of atoms.\n        universe (MDAnalysis.core.universe.Universe): The MDAnalysis universe containing the atoms.\n        axis (str): The axis along which to calculate the maximum distance.\n        box (numpy.ndarray or None): The dimensions of the simulation box, \n            or None if periodic boundary conditions are not used.\n        **kwargs: Additional keyword arguments to be passed to the parent class.\n\n    Return:\n        results (MDAnalysis.analysis.base.AnalysisResults): The results of the analysis.\n\n    Raises:\n        ValueError: If `axis` is not \"x\", \"y\", or \"z\".\n\n    Notes:\n        This class is a subclass of `MDAnalysis.analysis.base.AnalysisBase`.\n\n    Examples:\n        &gt;&gt;&gt; import MDAnalysis as mda\n        &gt;&gt;&gt; from catflow.structure.dynamic_selection import AxisMaxDistance\n        &gt;&gt;&gt; u = mda.Universe(\"system.gro\", \"system.trr\")\n        &gt;&gt;&gt; ag1 = u.select_atoms(\"protein\")\n        &gt;&gt;&gt; ag2 = u.select_atoms(\"resname LIG\")\n        &gt;&gt;&gt; analysis = AxisMaxDistance(ag1, ag2, axis=\"x\", box=u.dimensions)\n        &gt;&gt;&gt; analysis.run()\n        &gt;&gt;&gt; max_distances = analysis.results.distances\n    \"\"\"\n\n    def __init__(self,\n                 ag1: mda.AtomGroup,\n                 ag2: mda.AtomGroup,\n                 axis: str = \"z\",\n                 box=None,\n                 **kwargs):\n        self.ag1 = ag1\n        self.ag2 = ag2\n        self.universe = ag1.universe\n        self.axis = axis\n        self.box = box\n        if box and self.universe.dimensions is None:\n            self.universe.dimensions = box\n        super(AxisMaxDistance, self).__init__(\n            ag1.universe.trajectory,\n            **kwargs\n        )\n\n    def _prepare(self):\n        self.results.distances = []\n\n    def _single_frame(self):\n        reference = self.ag1.center_of_geometry()\n        temp_distances = self.ag2.positions[:]\n        axis_indices = {\"x\": (1, 2), \"y\": (0, 2), \"z\": (0, 1)}\n        if self.axis not in axis_indices:\n            raise ValueError(\"axis must be x, y or z\")\n        reference[axis_indices[self.axis]] = 0.\n        temp_distances[:, axis_indices[self.axis][0]] = 0.\n        temp_distances[:, axis_indices[self.axis][1]] = 0.\n        self_distances = distance_array(\n            temp_distances, reference, box=self.box)\n        max_distances = np.max(self_distances, axis=1)\n        self.results.distances.append(max_distances)\n</code></pre>"},{"location":"reference/catflow/structure/dynamic_selection/#catflow.structure.dynamic_selection.EqualAroundIndex","title":"<code>EqualAroundIndex</code>","text":"<p>             Bases: <code>AnalysisBase</code></p> <p>Get indices of atoms from <code>AtomGroup</code> closest to given <code>AtomGroup</code>.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>AtomGroup</code> <p>AtomGroup. Reference group, should be static.</p> required <code>environment</code> <code>AtomGroup</code> <p>AtomGroup. Environment group. <code>updating</code> should be <code>True</code> for dynamic selection.</p> required <code>box</code> <code>ndarray</code> <p>The box dimensions. Defaults to None.</p> <code>None</code> <code>size</code> <code>int</code> <p>The number of atoms to select. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the parent class.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>ag1</code> <code>AtomGroup</code> <p>The first AtomGroup.</p> <code>ag2</code> <code>AtomGroup</code> <p>The second AtomGroup.</p> <code>universe</code> <code>Universe</code> <p>The universe containing the AtomGroups.</p> <code>size</code> <code>int</code> <p>The number of atoms to select.</p> <code>size_initial</code> <code>bool</code> <p>Whether the size was initially None.</p> <code>box</code> <code>ndarray</code> <p>The box dimensions.</p> <code>results</code> <code>AnalysisResults</code> <p>The results of the analysis.</p> <p>Methods:</p> Name Description <code>_prepare</code> <p>Prepare the analysis.</p> <code>_single_frame</code> <p>Perform the analysis on a single frame.</p> Source code in <code>catflow/structure/dynamic_selection.py</code> <pre><code>class EqualAroundIndex(AnalysisBase):\n    \"\"\"Get indices of atoms from `AtomGroup` closest to given `AtomGroup`.\n\n    Args:\n        reference (mda.AtomGroup): AtomGroup. Reference group, should be static.\n        environment (mda.AtomGroup): AtomGroup. Environment group. `updating` should be `True` for dynamic selection.\n        box (np.ndarray, optional): The box dimensions. Defaults to None.\n        size (int, optional): The number of atoms to select. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the parent class.\n\n    Attributes:\n        ag1 (mda.AtomGroup): The first AtomGroup.\n        ag2 (mda.AtomGroup): The second AtomGroup.\n        universe (mda.Universe): The universe containing the AtomGroups.\n        size (int): The number of atoms to select.\n        size_initial (bool): Whether the size was initially None.\n        box (np.ndarray): The box dimensions.\n        results (AnalysisResults): The results of the analysis.\n\n    Methods:\n        _prepare(): Prepare the analysis.\n        _single_frame(): Perform the analysis on a single frame.\n    \"\"\"\n\n    def __init__(self,\n                 reference: mda.AtomGroup,\n                 environment: mda.AtomGroup,\n                 box=None,\n                 size=None,\n                 **kwargs):\n        self.reference = reference\n        self.environment = environment\n        self.universe = reference.universe\n        self.atom_groups = []\n\n        if size:\n            self.size = size\n        else:\n            self.size = None\n        if box:\n            self.universe.dimensions = box\n            self.box = self.universe.dimensions\n        elif not box and self.universe.dimensions:\n            self.box = self.universe.dimensions\n        super(EqualAroundIndex, self).__init__(\n            reference.universe.trajectory,\n            **kwargs\n        )\n\n    def _prepare(self):\n        self.results.atom_groups = []\n        self.results.indices = []\n        ref_size = len(self.reference)\n\n        if not self.size:\n            # loop to find minimum size\n            for _ in self.universe.trajectory:\n                if len(self.environment) == 0:\n                    raise ValueError(\n                        \"Environment should not be empty through the trajectory.\")\n                if not self.size:\n                    self.size = len(self.environment) + ref_size\n                elif len(self.environment) + ref_size &lt; self.size:\n                    self.size = len(self.environment) + ref_size\n\n    def _single_frame(self):\n        array_distance = distance_array(\n            self.reference, self.environment, box=self.box)\n        min_distances = np.min(array_distance, axis=0)\n        if self.size is not None:\n            clip = self.size - len(self.reference)\n        else:\n            clip = None\n        new_ag = self.reference | self.environment[np.argsort(min_distances)[\n            :clip]]\n        self.atom_groups.append(new_ag)\n        self.results.atom_groups.append(new_ag)\n        self.results.indices.append(new_ag.indices)\n</code></pre>"},{"location":"reference/catflow/structure/dynamic_selection/#catflow.structure.dynamic_selection.EqualAxisIndex","title":"<code>EqualAxisIndex</code>","text":"<p>             Bases: <code>AnalysisBase</code></p> <p>Selects atoms from a given AtomGroup based on their distance along a specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>ag1</code> <code>AtomGroup</code> <p>The reference AtomGroup.</p> required <code>ag2</code> <code>AtomGroup</code> <p>The AtomGroup to select atoms from.</p> required <code>axis</code> <code>str</code> <p>The axis along which to measure distances. Must be \"x\", \"y\", or \"z\".</p> <code>'z'</code> <code>box</code> <code>Box</code> <p>The simulation box. Required if periodic boundary conditions are used.</p> <code>None</code> <code>size</code> <code>int</code> <p>The number of atoms to select. If None, selects all atoms in ag2.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to AnalysisBase.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If axis is not \"x\", \"y\", or \"z\".</p> <p>Attributes:</p> Name Type Description <code>ag1</code> <code>AtomGroup</code> <p>The reference AtomGroup.</p> <code>ag2</code> <code>AtomGroup</code> <p>The AtomGroup to select atoms from.</p> <code>universe</code> <code>Universe</code> <p>The simulation universe.</p> <code>axis</code> <code>str</code> <p>The axis along which to measure distances.</p> <code>size</code> <code>int</code> <p>The number of atoms to select.</p> <code>box</code> <code>Box</code> <p>The simulation box.</p> <code>results</code> <code>AnalysisResults</code> <p>The results of the analysis.</p> Source code in <code>catflow/structure/dynamic_selection.py</code> <pre><code>class EqualAxisIndex(AnalysisBase):\n    \"\"\"Selects atoms from a given AtomGroup based on their distance along a specified axis.\n\n    Args:\n        ag1 (mda.AtomGroup): The reference AtomGroup.\n        ag2 (mda.AtomGroup): The AtomGroup to select atoms from.\n        axis (str): The axis along which to measure distances. Must be \"x\", \"y\", or \"z\".\n        box (mda.Box): The simulation box. Required if periodic boundary conditions are used.\n        size (int): The number of atoms to select. If None, selects all atoms in ag2.\n        **kwargs: Additional keyword arguments to pass to AnalysisBase.\n\n    Raises:\n        ValueError: If axis is not \"x\", \"y\", or \"z\".\n\n    Attributes:\n        ag1 (mda.AtomGroup): The reference AtomGroup.\n        ag2 (mda.AtomGroup): The AtomGroup to select atoms from.\n        universe (mda.Universe): The simulation universe.\n        axis (str): The axis along which to measure distances.\n        size (int): The number of atoms to select.\n        box (mda.Box): The simulation box.\n        results (AnalysisResults): The results of the analysis.\n\n    \"\"\"\n\n    def __init__(self,\n                 ag1: mda.AtomGroup,\n                 ag2: mda.AtomGroup,\n                 axis: str = \"z\",\n                 box=None,\n                 size=None,\n                 **kwargs):\n        self.ag1 = ag1\n        self.ag2 = ag2\n        self.universe = ag1.universe\n        self.axis = axis\n        if size:\n            self.size = size\n        else:\n            self.size = None\n        self.box = box\n        if box and self.universe.dimensions is None:\n            self.universe.dimensions = box\n        super(EqualAxisIndex, self).__init__(\n            ag1.universe.trajectory,\n            **kwargs\n        )\n\n    def _prepare(self):\n        \"\"\"Prepares the analysis.\"\"\"\n        self.results.atom_groups = []\n        self.results.indices = []\n        if self.size is None:\n            for _ in self.universe.trajectory:\n                if self.size is None:\n                    self.size = len(self.ag2)\n                if len(self.ag2) &lt; self.size:\n                    self.size = len(self.ag2)\n\n    def _single_frame(self):\n        \"\"\"Performs the analysis on a single frame.\"\"\"\n        reference = self.ag1.center_of_geometry()\n        temp_distances = self.ag2.positions[:]\n        axis_indices = {\"x\": (1, 2), \"y\": (0, 2), \"z\": (0, 1)}\n        if self.axis not in axis_indices:\n            raise ValueError(\"axis must be x, y or z\")\n        reference[axis_indices[self.axis]] = 0.\n        temp_distances[:, axis_indices[self.axis][0]] = 0.\n        temp_distances[:, axis_indices[self.axis][1]] = 0.\n        self_distances = distance_array(\n            temp_distances, reference, box=self.box)\n        new_ag = self.ag1 | self.ag2[np.argsort(\n            self_distances.flatten())[:self.size]]\n        self.results.atom_groups.append(new_ag)\n        self.results.indices.append(new_ag.indices)\n</code></pre>"},{"location":"reference/catflow/structure/lindemann_index/","title":"lindemann_index","text":""},{"location":"reference/catflow/tesla/","title":"tesla","text":""},{"location":"reference/catflow/tesla/ai2_kit/","title":"ai2_kit","text":""},{"location":"reference/catflow/tesla/ai2_kit/exploration/","title":"exploration","text":""},{"location":"reference/catflow/tesla/ai2_kit/exploration/#catflow.tesla.ai2_kit.exploration.CllExplorationAnalyzer","title":"<code>CllExplorationAnalyzer</code>","text":"<p>             Bases: <code>ExplorationAnalyzer</code>, <code>CllAnalyzer</code></p> <p>Analyzer for exploration tasks.</p> Source code in <code>catflow/tesla/ai2_kit/exploration.py</code> <pre><code>class CllExplorationAnalyzer(ExplorationAnalyzer, CllAnalyzer):\n    \"\"\"Analyzer for exploration tasks.\n    \"\"\"\n\n    def _iteration_tasks(self, iteration) -&gt; List[Path]:\n        n_iter = self._iteration_dir(iteration=iteration)\n        stage_path = self.dp_task.path / n_iter / 'explore-lammps/tasks'\n        task_files = [\n            item for item in stage_path.iterdir() if re.search(r'^\\d+$', str(item.name))\n        ]\n        return task_files\n\n    def load_task_job_dict(self, task: Path):\n        try:\n            job_dict = lammps_variable_parser(task / 'lammps.input')\n        except Exception as err:\n            logger.error(err)\n            job_dict = {}\n        return job_dict\n</code></pre>"},{"location":"reference/catflow/tesla/ai2_kit/labeling/","title":"labeling","text":""},{"location":"reference/catflow/tesla/ai2_kit/task/","title":"task","text":""},{"location":"reference/catflow/tesla/ai2_kit/task/#catflow.tesla.ai2_kit.task.CllAnalyzer","title":"<code>CllAnalyzer</code>","text":"<p>             Bases: <code>BaseAnalyzer</code></p> <p>Base class to be implemented as analyzer for <code>DPTask</code></p> Source code in <code>catflow/tesla/ai2_kit/task.py</code> <pre><code>class CllAnalyzer(BaseAnalyzer):\n    \"\"\"Base class to be implemented as analyzer for `DPTask`\n    \"\"\"\n    def __init__(\n        self, \n        dp_task: CllTask,\n        iteration: int = 0,\n        **kwargs\n    ) -&gt; None:\n        self.dp_task = dp_task\n        self.iteration = iteration\n        if type(self.dp_task) is not CllTask:\n            self.dp_task = CllTask.from_dict(**self.dp_task.__dict__, **kwargs)\n\n    def _iteration_dir(self, iteration: Optional[int] = None, **kwargs) -&gt; str:\n        if iteration is None:\n            iteration = self.iteration\n        return 'iters-' + str(iteration).zfill(3)\n\n    @classmethod\n    def setup_task(cls, **kwargs):\n        task = CllTask(**kwargs)\n        return cls(task, kwargs.get('iteration', 0))\n</code></pre>"},{"location":"reference/catflow/tesla/ai2_kit/task/#catflow.tesla.ai2_kit.task.CllTask","title":"<code>CllTask</code>","text":"<p>             Bases: <code>BaseTask</code></p> <p>CllTask is a class reading a ai2-kit directory, where the Cll-Workflow run.</p> Source code in <code>catflow/tesla/ai2_kit/task.py</code> <pre><code>class CllTask(BaseTask):\n    \"\"\"CllTask is a class reading a ai2-kit directory, where the Cll-Workflow run.\n    \"\"\"\n\n    def __init__(\n        self,\n        *config_files,\n        path: str\n    ):\n        \"\"\"Generate a class of tesla task.\n\n        Args:\n            path (str): The path of the tesla task.\n            deepmd_version (str): DeepMD-kit version used. Default: 2.0.\n        \"\"\"\n        super().__init__(path)\n        config_data = load_yaml_files(*config_files)\n        self.config = CllWorkflowConfig.parse_obj(config_data)   \n\n    @classmethod\n    def from_dict(cls, dp_task_dict: dict):\n        return cls(**dp_task_dict)\n</code></pre>"},{"location":"reference/catflow/tesla/ai2_kit/task/#catflow.tesla.ai2_kit.task.CllTask.__init__","title":"<code>__init__(*config_files, path)</code>","text":"<p>Generate a class of tesla task.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path of the tesla task.</p> required <code>deepmd_version</code> <code>str</code> <p>DeepMD-kit version used. Default: 2.0.</p> required Source code in <code>catflow/tesla/ai2_kit/task.py</code> <pre><code>def __init__(\n    self,\n    *config_files,\n    path: str\n):\n    \"\"\"Generate a class of tesla task.\n\n    Args:\n        path (str): The path of the tesla task.\n        deepmd_version (str): DeepMD-kit version used. Default: 2.0.\n    \"\"\"\n    super().__init__(path)\n    config_data = load_yaml_files(*config_files)\n    self.config = CllWorkflowConfig.parse_obj(config_data)   \n</code></pre>"},{"location":"reference/catflow/tesla/ai2_kit/training/","title":"training","text":""},{"location":"reference/catflow/tesla/ai2_kit/training/#catflow.tesla.ai2_kit.training.CllTrainingAnalyzer","title":"<code>CllTrainingAnalyzer</code>","text":"<p>             Bases: <code>TrainingAnalyzer</code>, <code>CllAnalyzer</code></p> <p>Analyzer for training tasks.</p> Source code in <code>catflow/tesla/ai2_kit/training.py</code> <pre><code>class CllTrainingAnalyzer(TrainingAnalyzer, CllAnalyzer):\n    \"\"\"Analyzer for training tasks.\n    \"\"\"\n\n    def get_lcurve_path(self, iteration: int, model=0) -&gt; Path:\n        _iteration_dir = self._iteration_dir(iteration=iteration)\n        lcurve_path = self.dp_task.path / _iteration_dir / \\\n            f'train-deepmd/tasks/{str(model).zfill(3)}/lcurve.out'\n        return lcurve_path\n\n    def load_lcurve(self, iteration=None, model=0):\n        lcurve_path = self.get_lcurve_path(iteration=iteration, model=model)\n\n        if self.validation is True:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=4),\n                'energy_test': np.loadtxt(lcurve_path, usecols=3),\n                'force_train': np.loadtxt(lcurve_path, usecols=6),\n                'force_test': np.loadtxt(lcurve_path, usecols=5),\n            }\n        else:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=2),\n                'force_train': np.loadtxt(lcurve_path, usecols=3)\n            }\n</code></pre>"},{"location":"reference/catflow/tesla/base/","title":"base","text":""},{"location":"reference/catflow/tesla/base/exploration/","title":"exploration","text":""},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer","title":"<code>ExplorationAnalyzer</code>","text":"<p>             Bases: <code>BaseAnalyzer</code></p> <p>Analyzer for exploration tasks.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>class ExplorationAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzer for exploration tasks.\n    \"\"\"\n\n    def _iteration_tasks(self, iteration: int) -&gt; List[Path]:\n        ...\n        return []\n\n    def load_task_job_dict(self, task: Path) -&gt; dict:\n        ...\n        return {}\n\n    def make_set(self, iteration: int, **kwargs) -&gt; List[dict]:\n        \"\"\"Dump dataset for easy analysis as list of dict\n\n        Args:\n            iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n        Returns:\n            List[dict]: all model deviation results\n        \"\"\"\n\n        all_data = []\n        for task in self._iteration_tasks(iteration):\n            # read model_devi.out\n            steps, max_devi_f, max_devi_v = \\\n                read_model_deviation(task / 'model_devi.out')\n\n            # load job config\n            job_dict = self.load_task_job_dict(task)\n\n            # gather result_dict\n            result_dict = {\n                'iteration': self._iteration_dir(iteration=iteration, **kwargs),\n                'max_devi_v': max_devi_v,\n                'max_devi_f': max_devi_f,\n                'task_path': task,\n                'steps': steps\n            }\n            all_dict = {**result_dict, **job_dict}\n            all_data.append(all_dict)\n        return all_data\n\n    def make_set_dataframe(self, iteration: int) -&gt; pd.DataFrame:\n        \"\"\"Dump dataset for easy analysis as `pandas.Dataframe`\n\n        Args:\n            iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n        Returns:\n            pd.DataFrame: Dataframe containing all model deviation logs.\n        \"\"\"\n        all_data = self.make_set(iteration=iteration)\n        df = pd.DataFrame(all_data)\n        df = df.explode([\"max_devi_v\", \"max_devi_f\", \"steps\"])\n        return df\n\n    def make_set_pickle(self, iteration: int) -&gt; pd.DataFrame:\n        \"\"\"Dump pickle from `self.make_set_dataframe` for quick load.\n           Default to `&lt;dpgen_task_path&gt;/model_devi_each_iter/data_&lt;iter&gt;.pkl`\n\n        Args:\n            iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n        Returns:\n            pd.DataFrame: DataFrame containing all model deviation logs.\n        \"\"\"\n        df = self.make_set_dataframe(iteration=iteration)\n        save_path = self.dp_task.path / 'model_devi_each_iter'\n        os.makedirs(name=save_path, exist_ok=True)\n        df.to_pickle(save_path / f'data_{str(iteration).zfill(6)}.pkl')\n        return df\n\n    def load_from_pickle(self, iteration: int) -&gt; pd.DataFrame:\n        \"\"\"Load DataFrame from pickle file.\n\n        Args:\n            iteration (int): the iteration to get\n\n        Returns:\n            pd.DataFrame: DataFrame containing all model deviation logs.\n        \"\"\"\n        pkl_path = self.dp_task.path / \\\n            f'model_devi_each_iter/data_{str(iteration).zfill(6)}.pkl'\n        df = pd.read_pickle(pkl_path)\n        return df\n\n    @staticmethod\n    def _convert_group_by(\n        group_by: Optional[str] = None,\n        **kwargs\n    ) -&gt; Tuple[int, Union[List, Collection]]:\n        if group_by is None:\n            num_item = 1\n            plot_items = [None]\n        else:\n            plot_items = kwargs.get(group_by)\n            if isinstance(plot_items, str):\n                num_item = 1\n                plot_items = [int(plot_items)]\n            elif isinstance(plot_items, (int, float)):\n                num_item = 1\n                plot_items = [plot_items]\n            elif isinstance(plot_items, Collection):\n                num_item = len(plot_items)\n            else:\n                num_item = 1\n                plot_items = [plot_items]\n        return num_item, plot_items\n\n    @staticmethod\n    def select_dataset(dataset, select, select_value=None):\n        try:\n            df = dataset[dataset[select] == select_value]\n        except KeyError as err:\n            logger.error(f'Please choose existing parameter for `select`')\n            raise err\n        return df\n\n    @staticmethod\n    def extract_group_dataset(dataset, group_item, group_by='temps'):\n        try:\n            part_data = dataset[dataset[group_by] == group_item]\n        except KeyError as err:\n            logger.error(\n                f'Please choose existing parameter for `group_by`')\n            raise err\n        return part_data\n\n    @staticmethod\n    def extract_iteration_dataset(dataset, iteration_dir=None):\n        try:\n            parts = dataset[dataset['iteration'] == iteration_dir]\n        except KeyError as err:\n            logger.error(f'Please choose existing iteration as input.')\n            raise err\n        return parts\n\n    def _load_model_devi_dataframe(\n            self,\n            plot_item,\n            iteration: int,\n            group_by=None,\n            select=None,\n            select_value=None,\n            **kwargs\n    ) -&gt; pd.DataFrame:\n        \"\"\"Load model deviation DataFrame from tasks.\"\"\"\n        try:\n            df = self.load_from_pickle(iteration=iteration)\n        except FileNotFoundError:\n            df = self.make_set_pickle(iteration=iteration)\n\n        # select data frame of given select\n        if all([select, select_value]):\n            df = self.select_dataset(df, select, select_value)\n\n        # extract data frame of given group\n        if group_by:\n            partdata = self.extract_group_dataset(df, plot_item, group_by)\n        else:\n            partdata = df\n\n        # export data frame of given iteration\n        parts = self.extract_iteration_dataset(\n            partdata, self._iteration_dir(iteration=iteration, **kwargs)\n        )\n        return parts\n\n    def _data_prepareation(\n            self,\n            plot_item,\n            iteration: int,\n            group_by=None,\n            select=None,\n            select_value=None,\n            **kwargs\n    ):\n        parts = self._load_model_devi_dataframe(\n            plot_item, iteration, group_by, select, select_value, **kwargs\n        )\n\n        steps = parts['steps']\n        mdf = parts['max_devi_f']\n        label_unit = kwargs.get('label_unit')\n        logger.info(\n            f\"f_max = {mdf.max()} ev/\u00c5 at {group_by}={plot_item} {label_unit} at iter {iteration}.\")\n        return steps, mdf\n\n    def _read_model_devi_trust_level(self, trust_level_key, iteration=None):\n        pass\n\n    def plot_single_iteration(\n            self,\n            iteration: int,\n            *,\n            x_limit: Optional[Union[float, List[float]]] = None,\n            y_limit: Optional[Union[float, List[float]]] = None,\n            use_log: bool = False,\n            group_by: Optional[str] = None,\n            f_trust_lo: float = 0.1,\n            f_trust_hi: float = 0.3,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            **kwargs\n    ) -&gt; Figure:\n        \"\"\"Generate a plot of model deviation in each iteration.\n\n        Args:\n            iteration (int, optional): The iteration. Defaults to current iteration.\n            x_limit (float, List[float], optional): Choose the limit of x axis. Defaults to None.\n            y_limit (float, List[float], optional): Choose the limit of y axis. Defaults to None.\n            use_log (bool, optional): Choose whether log scale used. Defaults to False.\n            group_by (str, optional): Choose which the plots are grouped by, which should be included. \n                Should be corresponding to keys in model_devi_job. Defaults to 'temps'.\n            f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n            f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n            select (str, optional): Choose which param selected as plot zone. Defaults to None.\n            select_value (str, optional): The dependence of `select`. \n                Different from `group_by`, please pass only one number. Defaults to None.\n            kwargs (_type_, optional): Additional keyword arguments. Include other params, such as:\n                `temps`: please use the value of `group_by`, whose default input is `\"temps\"`.\n                `label_unit`: the unit of `select_value`, such as '\u00c5'.\n                Parameters of `canvas_style`: please refer to `catflow.graph.plotting.canvas_style`.\n\n        Returns:\n            Figure: A plot for different desired values.\n        \"\"\"\n\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n\n        canvas_style(**kwargs)\n        fig = plt.figure(figsize=[12, 4 * num_item],\n                         constrained_layout=True)\n        gs = fig.add_gridspec(num_item, 3)\n\n        for i, plot_item in enumerate(plot_items):\n            steps, mdf = self._data_prepareation(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n\n            # left part\n            fig_left = fig.add_subplot(gs[i, :-1])  # type: ignore\n            fig_left_args = {\n                'x': steps,\n                'y': mdf,\n                'plot_item': plot_item,\n                'label_unit': kwargs.get('label_unit'),\n                'x_limit': x_limit,\n                'y_limit': y_limit,\n                'use_log': use_log,\n                'f_trust_lo': f_trust_lo,\n                'f_trust_hi': f_trust_hi,\n                'color': 'red',\n                'iteration': iteration,\n            }\n            PlottingExploartion.plot_mdf_time_curve(fig_left, fig_left_args)\n            global_ylim = fig_left.get_ylim()\n\n            # right part\n            fig_right = fig.add_subplot(gs[i, -1])  # type: ignore\n            fig_right_args = {\n                'data': mdf,\n                'plot_item': plot_item,\n                'label_unit': kwargs.get('label_unit'),\n                'y_limit': global_ylim,\n                'use_log': use_log,\n                'f_trust_lo': f_trust_lo,\n                'f_trust_hi': f_trust_hi,\n                'color': 'red',\n                'iteration': iteration,\n            }\n            PlottingExploartion.plot_mdf_distribution(\n                fig_right, fig_right_args, orientation='horizontal')\n            fig_right.set_xticklabels([])\n            fig_right.set_yticklabels([])\n        return fig\n\n    def plot_multiple_iterations(\n            self,\n            iterations: Iterable,\n            group_by: Optional[str] = None,\n            f_trust_lo: float = 0.1,\n            f_trust_hi: float = 0.3,\n            x_limit: Optional[Union[float, List[float]]] = None,\n            y_limit: Optional[Union[float, List[float]]] = None,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            **kwargs\n    ):\n        \"\"\"Analyse trajectories for different temperatures.\n\n        Args:\n            iterations (Iterabke): Iterations selected, which should be iterable.\n            group_by (str, optional): Choose which the plots are grouped by, which should be included.\n            For value of group_by, a list, int or str containing desired value(s) should be included as kwargs.\n            For example, if `group_by='temps'`, then `temps=[100., 200., 300.]` should also be passed to this function.\n            Default: \"temps\".\n            f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n            f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n            x_limit (_type_, optional): The limit of x scale. Defaults to None.\n            y_limit (_type_, optional): The limit of y scale. Defaults to None.\n            select (_type_, optional): Choose which param selected as plot zone.. Defaults to None.\n            select_value (_type_, optional): _description_. Defaults to None.\n\n        Returns:\n            _type_: A plot for different iterations.\n\n        \"\"\"\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n        label_unit = kwargs.get('label_unit', 'K')\n\n        canvas_style(**kwargs)\n        nrows = square_grid(num_item)\n        fig, axs = plt.subplots(nrows, nrows, figsize=[\n                                12, 12], constrained_layout=True)\n        for i, plot_item in enumerate(plot_items):\n            try:\n                ax = axs.flatten()[i]\n            except AttributeError:\n                ax = axs\n            for iteration in iterations:\n                step, mdf = self._data_prepareation(\n                    plot_item, iteration, group_by, select, select_value, **kwargs)\n                ax.scatter(step, mdf, s=80, alpha=0.3,  # type: ignore\n                           label=f'iter {int(iteration)}', marker='o')\n            ax.axhline(f_trust_lo, linestyle='dashed')  # type: ignore\n            ax.axhline(f_trust_hi, linestyle='dashed')  # type: ignore\n            ax.set_ylabel(r\"$\\sigma_{f}^{max}$ (ev/\u00c5)\")  # type: ignore\n            ax.set_xlabel('Simulation time (fs)')  # type: ignore\n            ax.legend()  # type: ignore\n            if x_limit is not None:\n                PlottingExploartion._plot_set_axis_limits(\n                    ax, x_limit, 'x_limit')  # type: ignore\n            if kwargs.get('use_log', False) == True:\n                ax.set_yscale('log')  # type: ignore\n            else:\n                if y_limit is not None:\n                    PlottingExploartion._plot_set_axis_limits(\n                        ax, y_limit, 'y_limit')  # type: ignore\n        for i in range(num_item, nrows * nrows):\n            try:\n                fig.delaxes(axs.flatten()[i])\n            except AttributeError:\n                pass\n        return fig\n\n    def plot_multi_iter_distribution(\n            self,\n            iterations: Iterable,\n            group_by: Optional[str] = None,\n            f_trust_lo: float = 0.1,\n            f_trust_hi: float = 0.3,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            x_limit: Optional[Union[float, List[float]]] = None,\n            y_limit: Optional[Union[float, List[float]]] = None,\n            **kwargs\n    ) -&gt; Figure:\n        \"\"\"Draw distribution in histogram of model deviation for multiple iterations.\n\n        Args:\n            iterations (Iterable): _description_\n            group_by (str, optional): _description_. Defaults to None.\n            select (str, optional): _description_. Defaults to None.\n            select_value (str, optional): _description_. Defaults to None.\n            f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n            f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n            x_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n            y_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n\n        Returns:\n            Figure: A figure containing distribution of model deviation for multiple iterations.\n        \"\"\"\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n        label_unit = kwargs.get('label_unit', 'K')\n\n        canvas_style(**kwargs)\n\n        nrows = square_grid(num_item)\n        fig, axs = plt.subplots(nrows, nrows, figsize=[\n                                12, 12], constrained_layout=True)\n\n        colors = plt.colormaps['viridis_r'](  # type: ignore\n            np.linspace(0.15, 0.85, len(iterations))  # type: ignore\n        )\n        for i, plot_item in enumerate(plot_items):\n            try:\n                ax = axs.flatten()[i]\n            except AttributeError:\n                ax = axs\n            for j, iteration in enumerate(iterations):\n                step, mdf = self._data_prepareation(\n                    plot_item, iteration, group_by, select, select_value, **kwargs)\n                ax_args = {\n                    'data': mdf,\n                    'plot_item': plot_item,\n                    'label_unit': kwargs.get('label_unit'),\n                    'f_trust_lo': f_trust_lo,\n                    'f_trust_hi': f_trust_hi,\n                    'iteration': iteration,\n                    'x_limit': x_limit,\n                    'y_limit': y_limit,\n                    'color': colors[j],\n                    'label': f'Iter {iteration}'\n                }\n                PlottingExploartion.plot_mdf_distribution(\n                    ax, ax_args, orientation='vertical')  # type: ignore\n            ax.set_ylabel('Distribution')  # type: ignore\n            ax.set_xlabel(r'$\\sigma_{f}^{max}$ (ev/\u00c5)')  # type: ignore\n            ax.legend()  # type: ignore\n        for i in range(num_item, nrows * nrows):\n            try:\n                fig.delaxes(axs.flatten()[i])\n            except AttributeError:\n                pass\n        return fig\n\n    def plot_ensemble_ratio_bar(\n            self,\n            iterations: Iterable,\n            group_by: Optional[str] = None,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            f_trust_lo: float = 0.1,\n            f_trust_hi: float = 0.3,\n            **kwargs\n    ) -&gt; Figure:\n        \"\"\"Draw ensemble ratio bar for multiple iterations.\n\n        Args:\n            iterations (Iterable): _description_\n            group_by (Optional[str], optional): _description_. Defaults to None.\n            select (Optional[str], optional): _description_. Defaults to None.\n            select_value (Optional[str], optional): _description_. Defaults to None.\n            f_trust_lo (float, optional): _description_. Defaults to 0.1.\n            f_trust_hi (float, optional): _description_. Defaults to 0.3.\n\n        Returns:\n            Figure: _description_\n        \"\"\"\n\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n        nrows = square_grid(num_item)\n\n        canvas_style(**kwargs)\n\n        fig, axs = plt.subplots(nrows, nrows)\n        for i, plot_item in enumerate(plot_items):\n            if type(axs) is plt.Axes:\n                ax = axs\n            else:\n                ax = axs.flatten()[i]  # type: ignore\n\n            ratios = np.zeros((len(iterations), 3))  # type: ignore\n\n            for j, iteration in enumerate(iterations):\n                df = self._load_model_devi_dataframe(\n                    plot_item, iteration, group_by, select, select_value, **kwargs)\n\n                accu_count = (df['max_devi_f'] &lt;= f_trust_lo).sum()\n                failed_count = (df['max_devi_f'] &gt; f_trust_hi).sum()\n                candidate_count = (\n                    (df['max_devi_f'] &gt; f_trust_lo) &amp;\n                    (df['max_devi_f'] &lt;= f_trust_hi)\n                ).sum()\n\n                all_count = accu_count + failed_count + candidate_count\n                count_array = np.array(\n                    [accu_count, candidate_count, failed_count])\n                ratios[j] = count_array / all_count\n\n            ax_args = {\n                'category_names': ['Accurate', 'Candidate', 'Failed'],\n                'ratios': ratios,\n                'iterations': iterations,\n            }\n            PlottingExploartion.plot_ensemble_ratio_bar(ax, ax_args)\n            handles, labels = ax.get_legend_handles_labels()\n        fig.supxlabel('Iteration')\n        fig.supylabel('Ratio')\n        fig.legend(handles, labels, loc='upper center',  # type: ignore\n                   ncol=3, bbox_to_anchor=(0.5, 1.0))\n        return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.load_from_pickle","title":"<code>load_from_pickle(iteration)</code>","text":"<p>Load DataFrame from pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>the iteration to get</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame containing all model deviation logs.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def load_from_pickle(self, iteration: int) -&gt; pd.DataFrame:\n    \"\"\"Load DataFrame from pickle file.\n\n    Args:\n        iteration (int): the iteration to get\n\n    Returns:\n        pd.DataFrame: DataFrame containing all model deviation logs.\n    \"\"\"\n    pkl_path = self.dp_task.path / \\\n        f'model_devi_each_iter/data_{str(iteration).zfill(6)}.pkl'\n    df = pd.read_pickle(pkl_path)\n    return df\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.make_set","title":"<code>make_set(iteration, **kwargs)</code>","text":"<p>Dump dataset for easy analysis as list of dict</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>iteration to be dumped. Defaults to None, dumping the latest iteration.</p> required <p>Returns:</p> Type Description <code>List[dict]</code> <p>List[dict]: all model deviation results</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def make_set(self, iteration: int, **kwargs) -&gt; List[dict]:\n    \"\"\"Dump dataset for easy analysis as list of dict\n\n    Args:\n        iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n    Returns:\n        List[dict]: all model deviation results\n    \"\"\"\n\n    all_data = []\n    for task in self._iteration_tasks(iteration):\n        # read model_devi.out\n        steps, max_devi_f, max_devi_v = \\\n            read_model_deviation(task / 'model_devi.out')\n\n        # load job config\n        job_dict = self.load_task_job_dict(task)\n\n        # gather result_dict\n        result_dict = {\n            'iteration': self._iteration_dir(iteration=iteration, **kwargs),\n            'max_devi_v': max_devi_v,\n            'max_devi_f': max_devi_f,\n            'task_path': task,\n            'steps': steps\n        }\n        all_dict = {**result_dict, **job_dict}\n        all_data.append(all_dict)\n    return all_data\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.make_set_dataframe","title":"<code>make_set_dataframe(iteration)</code>","text":"<p>Dump dataset for easy analysis as <code>pandas.Dataframe</code></p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>iteration to be dumped. Defaults to None, dumping the latest iteration.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Dataframe containing all model deviation logs.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def make_set_dataframe(self, iteration: int) -&gt; pd.DataFrame:\n    \"\"\"Dump dataset for easy analysis as `pandas.Dataframe`\n\n    Args:\n        iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n    Returns:\n        pd.DataFrame: Dataframe containing all model deviation logs.\n    \"\"\"\n    all_data = self.make_set(iteration=iteration)\n    df = pd.DataFrame(all_data)\n    df = df.explode([\"max_devi_v\", \"max_devi_f\", \"steps\"])\n    return df\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.make_set_pickle","title":"<code>make_set_pickle(iteration)</code>","text":"<p>Dump pickle from <code>self.make_set_dataframe</code> for quick load.    Default to <code>&lt;dpgen_task_path&gt;/model_devi_each_iter/data_&lt;iter&gt;.pkl</code></p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>iteration to be dumped. Defaults to None, dumping the latest iteration.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame containing all model deviation logs.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def make_set_pickle(self, iteration: int) -&gt; pd.DataFrame:\n    \"\"\"Dump pickle from `self.make_set_dataframe` for quick load.\n       Default to `&lt;dpgen_task_path&gt;/model_devi_each_iter/data_&lt;iter&gt;.pkl`\n\n    Args:\n        iteration (int, optional): iteration to be dumped. Defaults to None, dumping the latest iteration.\n\n    Returns:\n        pd.DataFrame: DataFrame containing all model deviation logs.\n    \"\"\"\n    df = self.make_set_dataframe(iteration=iteration)\n    save_path = self.dp_task.path / 'model_devi_each_iter'\n    os.makedirs(name=save_path, exist_ok=True)\n    df.to_pickle(save_path / f'data_{str(iteration).zfill(6)}.pkl')\n    return df\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.plot_ensemble_ratio_bar","title":"<code>plot_ensemble_ratio_bar(iterations, group_by=None, select=None, select_value=None, f_trust_lo=0.1, f_trust_hi=0.3, **kwargs)</code>","text":"<p>Draw ensemble ratio bar for multiple iterations.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>Iterable</code> <p>description</p> required <code>group_by</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>select</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>f_trust_lo</code> <code>float</code> <p>description. Defaults to 0.1.</p> <code>0.1</code> <code>f_trust_hi</code> <code>float</code> <p>description. Defaults to 0.3.</p> <code>0.3</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>description</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def plot_ensemble_ratio_bar(\n        self,\n        iterations: Iterable,\n        group_by: Optional[str] = None,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        f_trust_lo: float = 0.1,\n        f_trust_hi: float = 0.3,\n        **kwargs\n) -&gt; Figure:\n    \"\"\"Draw ensemble ratio bar for multiple iterations.\n\n    Args:\n        iterations (Iterable): _description_\n        group_by (Optional[str], optional): _description_. Defaults to None.\n        select (Optional[str], optional): _description_. Defaults to None.\n        select_value (Optional[str], optional): _description_. Defaults to None.\n        f_trust_lo (float, optional): _description_. Defaults to 0.1.\n        f_trust_hi (float, optional): _description_. Defaults to 0.3.\n\n    Returns:\n        Figure: _description_\n    \"\"\"\n\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n    nrows = square_grid(num_item)\n\n    canvas_style(**kwargs)\n\n    fig, axs = plt.subplots(nrows, nrows)\n    for i, plot_item in enumerate(plot_items):\n        if type(axs) is plt.Axes:\n            ax = axs\n        else:\n            ax = axs.flatten()[i]  # type: ignore\n\n        ratios = np.zeros((len(iterations), 3))  # type: ignore\n\n        for j, iteration in enumerate(iterations):\n            df = self._load_model_devi_dataframe(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n\n            accu_count = (df['max_devi_f'] &lt;= f_trust_lo).sum()\n            failed_count = (df['max_devi_f'] &gt; f_trust_hi).sum()\n            candidate_count = (\n                (df['max_devi_f'] &gt; f_trust_lo) &amp;\n                (df['max_devi_f'] &lt;= f_trust_hi)\n            ).sum()\n\n            all_count = accu_count + failed_count + candidate_count\n            count_array = np.array(\n                [accu_count, candidate_count, failed_count])\n            ratios[j] = count_array / all_count\n\n        ax_args = {\n            'category_names': ['Accurate', 'Candidate', 'Failed'],\n            'ratios': ratios,\n            'iterations': iterations,\n        }\n        PlottingExploartion.plot_ensemble_ratio_bar(ax, ax_args)\n        handles, labels = ax.get_legend_handles_labels()\n    fig.supxlabel('Iteration')\n    fig.supylabel('Ratio')\n    fig.legend(handles, labels, loc='upper center',  # type: ignore\n               ncol=3, bbox_to_anchor=(0.5, 1.0))\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.plot_multi_iter_distribution","title":"<code>plot_multi_iter_distribution(iterations, group_by=None, f_trust_lo=0.1, f_trust_hi=0.3, select=None, select_value=None, x_limit=None, y_limit=None, **kwargs)</code>","text":"<p>Draw distribution in histogram of model deviation for multiple iterations.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>Iterable</code> <p>description</p> required <code>group_by</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>select</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>f_trust_lo</code> <code>float</code> <p>The lower limit of max_deviation_force. Defaults to 0.1.</p> <code>0.1</code> <code>f_trust_hi</code> <code>float</code> <p>The higher limit of max_deviation_force. Defaults to 0.3.</p> <code>0.3</code> <code>x_limit</code> <code>Union[float, List[float]]</code> <p>description. Defaults to None.</p> <code>None</code> <code>y_limit</code> <code>Union[float, List[float]]</code> <p>description. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>A figure containing distribution of model deviation for multiple iterations.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def plot_multi_iter_distribution(\n        self,\n        iterations: Iterable,\n        group_by: Optional[str] = None,\n        f_trust_lo: float = 0.1,\n        f_trust_hi: float = 0.3,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        x_limit: Optional[Union[float, List[float]]] = None,\n        y_limit: Optional[Union[float, List[float]]] = None,\n        **kwargs\n) -&gt; Figure:\n    \"\"\"Draw distribution in histogram of model deviation for multiple iterations.\n\n    Args:\n        iterations (Iterable): _description_\n        group_by (str, optional): _description_. Defaults to None.\n        select (str, optional): _description_. Defaults to None.\n        select_value (str, optional): _description_. Defaults to None.\n        f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n        f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n        x_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n        y_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n\n    Returns:\n        Figure: A figure containing distribution of model deviation for multiple iterations.\n    \"\"\"\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n    label_unit = kwargs.get('label_unit', 'K')\n\n    canvas_style(**kwargs)\n\n    nrows = square_grid(num_item)\n    fig, axs = plt.subplots(nrows, nrows, figsize=[\n                            12, 12], constrained_layout=True)\n\n    colors = plt.colormaps['viridis_r'](  # type: ignore\n        np.linspace(0.15, 0.85, len(iterations))  # type: ignore\n    )\n    for i, plot_item in enumerate(plot_items):\n        try:\n            ax = axs.flatten()[i]\n        except AttributeError:\n            ax = axs\n        for j, iteration in enumerate(iterations):\n            step, mdf = self._data_prepareation(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n            ax_args = {\n                'data': mdf,\n                'plot_item': plot_item,\n                'label_unit': kwargs.get('label_unit'),\n                'f_trust_lo': f_trust_lo,\n                'f_trust_hi': f_trust_hi,\n                'iteration': iteration,\n                'x_limit': x_limit,\n                'y_limit': y_limit,\n                'color': colors[j],\n                'label': f'Iter {iteration}'\n            }\n            PlottingExploartion.plot_mdf_distribution(\n                ax, ax_args, orientation='vertical')  # type: ignore\n        ax.set_ylabel('Distribution')  # type: ignore\n        ax.set_xlabel(r'$\\sigma_{f}^{max}$ (ev/\u00c5)')  # type: ignore\n        ax.legend()  # type: ignore\n    for i in range(num_item, nrows * nrows):\n        try:\n            fig.delaxes(axs.flatten()[i])\n        except AttributeError:\n            pass\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.plot_multiple_iterations","title":"<code>plot_multiple_iterations(iterations, group_by=None, f_trust_lo=0.1, f_trust_hi=0.3, x_limit=None, y_limit=None, select=None, select_value=None, **kwargs)</code>","text":"<p>Analyse trajectories for different temperatures.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>Iterabke</code> <p>Iterations selected, which should be iterable.</p> required <code>group_by</code> <code>str</code> <p>Choose which the plots are grouped by, which should be included.</p> <code>None</code> <code>Default</code> <p>\"temps\".</p> required <code>f_trust_lo</code> <code>float</code> <p>The lower limit of max_deviation_force. Defaults to 0.1.</p> <code>0.1</code> <code>f_trust_hi</code> <code>float</code> <p>The higher limit of max_deviation_force. Defaults to 0.3.</p> <code>0.3</code> <code>x_limit</code> <code>_type_</code> <p>The limit of x scale. Defaults to None.</p> <code>None</code> <code>y_limit</code> <code>_type_</code> <p>The limit of y scale. Defaults to None.</p> <code>None</code> <code>select</code> <code>_type_</code> <p>Choose which param selected as plot zone.. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>_type_</code> <p>description. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>A plot for different iterations.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def plot_multiple_iterations(\n        self,\n        iterations: Iterable,\n        group_by: Optional[str] = None,\n        f_trust_lo: float = 0.1,\n        f_trust_hi: float = 0.3,\n        x_limit: Optional[Union[float, List[float]]] = None,\n        y_limit: Optional[Union[float, List[float]]] = None,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        **kwargs\n):\n    \"\"\"Analyse trajectories for different temperatures.\n\n    Args:\n        iterations (Iterabke): Iterations selected, which should be iterable.\n        group_by (str, optional): Choose which the plots are grouped by, which should be included.\n        For value of group_by, a list, int or str containing desired value(s) should be included as kwargs.\n        For example, if `group_by='temps'`, then `temps=[100., 200., 300.]` should also be passed to this function.\n        Default: \"temps\".\n        f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n        f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n        x_limit (_type_, optional): The limit of x scale. Defaults to None.\n        y_limit (_type_, optional): The limit of y scale. Defaults to None.\n        select (_type_, optional): Choose which param selected as plot zone.. Defaults to None.\n        select_value (_type_, optional): _description_. Defaults to None.\n\n    Returns:\n        _type_: A plot for different iterations.\n\n    \"\"\"\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n    label_unit = kwargs.get('label_unit', 'K')\n\n    canvas_style(**kwargs)\n    nrows = square_grid(num_item)\n    fig, axs = plt.subplots(nrows, nrows, figsize=[\n                            12, 12], constrained_layout=True)\n    for i, plot_item in enumerate(plot_items):\n        try:\n            ax = axs.flatten()[i]\n        except AttributeError:\n            ax = axs\n        for iteration in iterations:\n            step, mdf = self._data_prepareation(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n            ax.scatter(step, mdf, s=80, alpha=0.3,  # type: ignore\n                       label=f'iter {int(iteration)}', marker='o')\n        ax.axhline(f_trust_lo, linestyle='dashed')  # type: ignore\n        ax.axhline(f_trust_hi, linestyle='dashed')  # type: ignore\n        ax.set_ylabel(r\"$\\sigma_{f}^{max}$ (ev/\u00c5)\")  # type: ignore\n        ax.set_xlabel('Simulation time (fs)')  # type: ignore\n        ax.legend()  # type: ignore\n        if x_limit is not None:\n            PlottingExploartion._plot_set_axis_limits(\n                ax, x_limit, 'x_limit')  # type: ignore\n        if kwargs.get('use_log', False) == True:\n            ax.set_yscale('log')  # type: ignore\n        else:\n            if y_limit is not None:\n                PlottingExploartion._plot_set_axis_limits(\n                    ax, y_limit, 'y_limit')  # type: ignore\n    for i in range(num_item, nrows * nrows):\n        try:\n            fig.delaxes(axs.flatten()[i])\n        except AttributeError:\n            pass\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/exploration/#catflow.tesla.base.exploration.ExplorationAnalyzer.plot_single_iteration","title":"<code>plot_single_iteration(iteration, *, x_limit=None, y_limit=None, use_log=False, group_by=None, f_trust_lo=0.1, f_trust_hi=0.3, select=None, select_value=None, **kwargs)</code>","text":"<p>Generate a plot of model deviation in each iteration.</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>The iteration. Defaults to current iteration.</p> required <code>x_limit</code> <code>(float, List[float])</code> <p>Choose the limit of x axis. Defaults to None.</p> <code>None</code> <code>y_limit</code> <code>(float, List[float])</code> <p>Choose the limit of y axis. Defaults to None.</p> <code>None</code> <code>use_log</code> <code>bool</code> <p>Choose whether log scale used. Defaults to False.</p> <code>False</code> <code>group_by</code> <code>str</code> <p>Choose which the plots are grouped by, which should be included.  Should be corresponding to keys in model_devi_job. Defaults to 'temps'.</p> <code>None</code> <code>f_trust_lo</code> <code>float</code> <p>The lower limit of max_deviation_force. Defaults to 0.1.</p> <code>0.1</code> <code>f_trust_hi</code> <code>float</code> <p>The higher limit of max_deviation_force. Defaults to 0.3.</p> <code>0.3</code> <code>select</code> <code>str</code> <p>Choose which param selected as plot zone. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>str</code> <p>The dependence of <code>select</code>.  Different from <code>group_by</code>, please pass only one number. Defaults to None.</p> <code>None</code> <code>kwargs</code> <code>_type_</code> <p>Additional keyword arguments. Include other params, such as: <code>temps</code>: please use the value of <code>group_by</code>, whose default input is <code>\"temps\"</code>. <code>label_unit</code>: the unit of <code>select_value</code>, such as '\u00c5'. Parameters of <code>canvas_style</code>: please refer to <code>catflow.graph.plotting.canvas_style</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>A plot for different desired values.</p> Source code in <code>catflow/tesla/base/exploration.py</code> <pre><code>def plot_single_iteration(\n        self,\n        iteration: int,\n        *,\n        x_limit: Optional[Union[float, List[float]]] = None,\n        y_limit: Optional[Union[float, List[float]]] = None,\n        use_log: bool = False,\n        group_by: Optional[str] = None,\n        f_trust_lo: float = 0.1,\n        f_trust_hi: float = 0.3,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        **kwargs\n) -&gt; Figure:\n    \"\"\"Generate a plot of model deviation in each iteration.\n\n    Args:\n        iteration (int, optional): The iteration. Defaults to current iteration.\n        x_limit (float, List[float], optional): Choose the limit of x axis. Defaults to None.\n        y_limit (float, List[float], optional): Choose the limit of y axis. Defaults to None.\n        use_log (bool, optional): Choose whether log scale used. Defaults to False.\n        group_by (str, optional): Choose which the plots are grouped by, which should be included. \n            Should be corresponding to keys in model_devi_job. Defaults to 'temps'.\n        f_trust_lo (float, optional): The lower limit of max_deviation_force. Defaults to 0.1.\n        f_trust_hi (float, optional): The higher limit of max_deviation_force. Defaults to 0.3.\n        select (str, optional): Choose which param selected as plot zone. Defaults to None.\n        select_value (str, optional): The dependence of `select`. \n            Different from `group_by`, please pass only one number. Defaults to None.\n        kwargs (_type_, optional): Additional keyword arguments. Include other params, such as:\n            `temps`: please use the value of `group_by`, whose default input is `\"temps\"`.\n            `label_unit`: the unit of `select_value`, such as '\u00c5'.\n            Parameters of `canvas_style`: please refer to `catflow.graph.plotting.canvas_style`.\n\n    Returns:\n        Figure: A plot for different desired values.\n    \"\"\"\n\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n\n    canvas_style(**kwargs)\n    fig = plt.figure(figsize=[12, 4 * num_item],\n                     constrained_layout=True)\n    gs = fig.add_gridspec(num_item, 3)\n\n    for i, plot_item in enumerate(plot_items):\n        steps, mdf = self._data_prepareation(\n            plot_item, iteration, group_by, select, select_value, **kwargs)\n\n        # left part\n        fig_left = fig.add_subplot(gs[i, :-1])  # type: ignore\n        fig_left_args = {\n            'x': steps,\n            'y': mdf,\n            'plot_item': plot_item,\n            'label_unit': kwargs.get('label_unit'),\n            'x_limit': x_limit,\n            'y_limit': y_limit,\n            'use_log': use_log,\n            'f_trust_lo': f_trust_lo,\n            'f_trust_hi': f_trust_hi,\n            'color': 'red',\n            'iteration': iteration,\n        }\n        PlottingExploartion.plot_mdf_time_curve(fig_left, fig_left_args)\n        global_ylim = fig_left.get_ylim()\n\n        # right part\n        fig_right = fig.add_subplot(gs[i, -1])  # type: ignore\n        fig_right_args = {\n            'data': mdf,\n            'plot_item': plot_item,\n            'label_unit': kwargs.get('label_unit'),\n            'y_limit': global_ylim,\n            'use_log': use_log,\n            'f_trust_lo': f_trust_lo,\n            'f_trust_hi': f_trust_hi,\n            'color': 'red',\n            'iteration': iteration,\n        }\n        PlottingExploartion.plot_mdf_distribution(\n            fig_right, fig_right_args, orientation='horizontal')\n        fig_right.set_xticklabels([])\n        fig_right.set_yticklabels([])\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/labeling/","title":"labeling","text":""},{"location":"reference/catflow/tesla/base/labeling/#catflow.tesla.base.labeling.LabelingAnalyzer","title":"<code>LabelingAnalyzer</code>","text":"<p>             Bases: <code>BaseAnalyzer</code></p> Source code in <code>catflow/tesla/base/labeling.py</code> <pre><code>class LabelingAnalyzer(BaseAnalyzer):\n\n    def __init__(\n        self, dp_task: BaseTask, \n        fp_style: Literal['vasp', 'cp2k'] = 'vasp'\n    ) -&gt; None:\n        super().__init__(dp_task)\n        self.fp_style = fp_style\n\n    def get_fp_tasks(self, iteration: int = 0) -&gt; List[Path]:\n        ...\n        return []\n\n    def fp_group_distance(self, iteration, atom_group, **kwargs):\n        \"\"\"\n        Analyse the distance of selected structures.\n        :param iteration: The iteration selected.\n        :param atom_group:A tuple contains the index number of two selected atoms.\n        :return: A plot of distance distribution.\n        \"\"\"\n        task_files = self.get_fp_tasks(iteration=iteration)\n\n        dis_loc = []\n        dis = []\n\n        _stc_name = self._fp_style()\n        for i in task_files:\n            stc_file_path = i / _stc_name # type: ignore\n            if stc_file_path.exists():\n                dis_loc.append(i)\n                stc = read(stc_file_path) \n                dis.append(stc.get_distance( # type: ignore\n                    atom_group[0], atom_group[1], mic=True))\n        diss = np.array(dis)\n\n        fig, ax = plt.subplots()\n        canvas_style(**kwargs)\n\n        ax.hist(diss, bins=np.arange(diss.min(), diss.max(), 0.01), # type: ignore\n                 label=f'iter {int(iteration)}', density=True)\n        ax.legend(fontsize=16)\n        ax.set_xlabel(\"d(\u00c5)\", fontsize=16)\n        ax.set_xticks(np.arange(diss.min(), diss.max(), step=1.0), fontsize=16)\n        ax.set_yticks(fontsize=16)\n        ax.set_title(\"Distibution of distance\", fontsize=16)\n        return fig\n\n    def fp_element_distance(self, iteration, ele_group, **kwargs):\n        \"\"\"\n        Analyse the distance of selected structures.\n        :param iteration: The iteration selected.\n        :param ele_group:A tuple contains the index number of two selected elements.\n        :return: A plot of distance distribution.\n        \"\"\"\n        dis = []\n        dis_loc = []\n        task_files = self.get_fp_tasks(iteration=iteration)\n        _stc_name = self._fp_style()\n\n        for i in task_files:\n            stc_file_path = i / _stc_name # type: ignore\n            if stc_file_path.exists():\n                dis_loc.append(i)\n                stc = read(stc_file_path)\n                symbol_list = stc.get_chemical_symbols() # type: ignore\n                ele_list_1 = [i for i in range(\n                    len(symbol_list)) if symbol_list[i] == ele_group[0]]\n                ele_list_2 = [i for i in range(\n                    len(symbol_list)) if symbol_list[i] == ele_group[0]]\n                min_dis = min([stc.get_distance(ii, jj, mic=True) # type: ignore\n                               for ii in ele_list_1 for jj in ele_list_2])\n                dis.append(min_dis)\n        diss = np.array(dis)\n\n        fig, ax = plt.subplots()\n        canvas_style(**kwargs)\n\n        ax.hist(diss, bins=np.arange(1, 6, 0.01),\n                 label=f'iter {int(iteration)}')\n        ax.legend(fontsize=16)\n        ax.set_xlabel(\"d(\u00c5)\", fontsize=16)\n        ax.set_xticks(np.arange(0, 6, step=0.5), fontsize=16)\n        ax.set_yticks(fontsize=16)\n        ax.set_title(\n            f\"Distibution of {ele_group[0]}-{ele_group[1]} distance\", fontsize=16)\n        return fig\n\n    def _fp_style(self):\n        styles = {\n            \"vasp\": \"POSCAR\",\n            \"cp2k\": \"coord.xyz\",\n        }\n        return styles.get(self.fp_style, None)\n\n    def _fp_output_style(self):\n        styles = {\n            \"vasp\": \"vasprun.xml\",\n            \"cp2k\": \"coord.xyz\",\n        }\n        return styles.get(self.fp_style, None)\n\n    def _fp_output_dpgen(self):\n        styles = {\n            \"vasp\": \"OUTCAR\",\n            \"cp2k\": \"output\",\n            \"qe\": \"output\",\n            \"siesta\": \"output\",\n            \"gaussian\": \"output\",\n            \"pwmat\": \"REPORT\",\n        }\n        return styles.get(self.fp_style, None)\n\n    def _fp_output_format(self):\n        styles = {\n            \"vasp\": \"vasp/outcar\",\n            \"cp2k\": \"cp2k/output\",\n        }\n        return styles.get(self.fp_style, None)\n</code></pre>"},{"location":"reference/catflow/tesla/base/labeling/#catflow.tesla.base.labeling.LabelingAnalyzer.fp_element_distance","title":"<code>fp_element_distance(iteration, ele_group, **kwargs)</code>","text":"<p>Analyse the distance of selected structures. :param iteration: The iteration selected. :param ele_group:A tuple contains the index number of two selected elements. :return: A plot of distance distribution.</p> Source code in <code>catflow/tesla/base/labeling.py</code> <pre><code>def fp_element_distance(self, iteration, ele_group, **kwargs):\n    \"\"\"\n    Analyse the distance of selected structures.\n    :param iteration: The iteration selected.\n    :param ele_group:A tuple contains the index number of two selected elements.\n    :return: A plot of distance distribution.\n    \"\"\"\n    dis = []\n    dis_loc = []\n    task_files = self.get_fp_tasks(iteration=iteration)\n    _stc_name = self._fp_style()\n\n    for i in task_files:\n        stc_file_path = i / _stc_name # type: ignore\n        if stc_file_path.exists():\n            dis_loc.append(i)\n            stc = read(stc_file_path)\n            symbol_list = stc.get_chemical_symbols() # type: ignore\n            ele_list_1 = [i for i in range(\n                len(symbol_list)) if symbol_list[i] == ele_group[0]]\n            ele_list_2 = [i for i in range(\n                len(symbol_list)) if symbol_list[i] == ele_group[0]]\n            min_dis = min([stc.get_distance(ii, jj, mic=True) # type: ignore\n                           for ii in ele_list_1 for jj in ele_list_2])\n            dis.append(min_dis)\n    diss = np.array(dis)\n\n    fig, ax = plt.subplots()\n    canvas_style(**kwargs)\n\n    ax.hist(diss, bins=np.arange(1, 6, 0.01),\n             label=f'iter {int(iteration)}')\n    ax.legend(fontsize=16)\n    ax.set_xlabel(\"d(\u00c5)\", fontsize=16)\n    ax.set_xticks(np.arange(0, 6, step=0.5), fontsize=16)\n    ax.set_yticks(fontsize=16)\n    ax.set_title(\n        f\"Distibution of {ele_group[0]}-{ele_group[1]} distance\", fontsize=16)\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/labeling/#catflow.tesla.base.labeling.LabelingAnalyzer.fp_group_distance","title":"<code>fp_group_distance(iteration, atom_group, **kwargs)</code>","text":"<p>Analyse the distance of selected structures. :param iteration: The iteration selected. :param atom_group:A tuple contains the index number of two selected atoms. :return: A plot of distance distribution.</p> Source code in <code>catflow/tesla/base/labeling.py</code> <pre><code>def fp_group_distance(self, iteration, atom_group, **kwargs):\n    \"\"\"\n    Analyse the distance of selected structures.\n    :param iteration: The iteration selected.\n    :param atom_group:A tuple contains the index number of two selected atoms.\n    :return: A plot of distance distribution.\n    \"\"\"\n    task_files = self.get_fp_tasks(iteration=iteration)\n\n    dis_loc = []\n    dis = []\n\n    _stc_name = self._fp_style()\n    for i in task_files:\n        stc_file_path = i / _stc_name # type: ignore\n        if stc_file_path.exists():\n            dis_loc.append(i)\n            stc = read(stc_file_path) \n            dis.append(stc.get_distance( # type: ignore\n                atom_group[0], atom_group[1], mic=True))\n    diss = np.array(dis)\n\n    fig, ax = plt.subplots()\n    canvas_style(**kwargs)\n\n    ax.hist(diss, bins=np.arange(diss.min(), diss.max(), 0.01), # type: ignore\n             label=f'iter {int(iteration)}', density=True)\n    ax.legend(fontsize=16)\n    ax.set_xlabel(\"d(\u00c5)\", fontsize=16)\n    ax.set_xticks(np.arange(diss.min(), diss.max(), step=1.0), fontsize=16)\n    ax.set_yticks(fontsize=16)\n    ax.set_title(\"Distibution of distance\", fontsize=16)\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/base/task/","title":"task","text":""},{"location":"reference/catflow/tesla/base/task/#catflow.tesla.base.task.BaseAnalyzer","title":"<code>BaseAnalyzer</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class to be implemented as analyzer for <code>DPTask</code></p> Source code in <code>catflow/tesla/base/task.py</code> <pre><code>class BaseAnalyzer(ABC):\n    \"\"\"Base class to be implemented as analyzer for `DPTask`\n    \"\"\"\n\n    def __init__(self, dp_task: BaseTask) -&gt; None:\n        self.dp_task = dp_task\n\n    def _iteration_dir(self, iteration: int, **kwargs) -&gt; str:\n        return \"\"\n\n    @classmethod\n    def setup_task(cls, **kwargs):\n        task = BaseTask(**kwargs)\n        return cls(task)\n</code></pre>"},{"location":"reference/catflow/tesla/base/task/#catflow.tesla.base.task.BaseTask","title":"<code>BaseTask</code>","text":"<p>             Bases: <code>object</code></p> <p>BaseTask is a base class reading a directory, where task run.</p> Source code in <code>catflow/tesla/base/task.py</code> <pre><code>class BaseTask(object):\n    \"\"\"BaseTask is a base class reading a directory, where task run.\n    \"\"\"\n\n    def __init__(self, path: str):\n        \"\"\"Generate a class of tesla task.\n\n        Args:\n            path (str): The path of the tesla task.\n        \"\"\"\n        self.path = Path(path).resolve()\n\n    @classmethod\n    def from_dict(cls, dp_task_dict: dict):\n        return cls(**dp_task_dict)\n</code></pre>"},{"location":"reference/catflow/tesla/base/task/#catflow.tesla.base.task.BaseTask.__init__","title":"<code>__init__(path)</code>","text":"<p>Generate a class of tesla task.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path of the tesla task.</p> required Source code in <code>catflow/tesla/base/task.py</code> <pre><code>def __init__(self, path: str):\n    \"\"\"Generate a class of tesla task.\n\n    Args:\n        path (str): The path of the tesla task.\n    \"\"\"\n    self.path = Path(path).resolve()\n</code></pre>"},{"location":"reference/catflow/tesla/base/training/","title":"training","text":""},{"location":"reference/catflow/tesla/base/training/#catflow.tesla.base.training.TrainingAnalyzer","title":"<code>TrainingAnalyzer</code>","text":"<p>             Bases: <code>BaseAnalyzer</code></p> <p>Analyzer for training tasks.</p> Source code in <code>catflow/tesla/base/training.py</code> <pre><code>class TrainingAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzer for training tasks.\n    \"\"\"\n\n    def __init__(\n        self,\n        dp_task: BaseTask,\n        validation: bool = False\n    ) -&gt; None:\n        super().__init__(dp_task)\n        self.validation = validation\n\n    def get_lcurve_path(self, iteration: int, model=0) -&gt; Path:\n        ...\n        return Path()\n\n    def load_lcurve(self, iteration: int, model=0):\n        lcurve_path = self.get_lcurve_path(iteration=iteration, model=model)\n\n        if self.validation is True:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=4),\n                'energy_validation': np.loadtxt(lcurve_path, usecols=3),\n                'force_train': np.loadtxt(lcurve_path, usecols=6),\n                'force_validation': np.loadtxt(lcurve_path, usecols=5),\n            }\n        else:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=2),\n                'force_train': np.loadtxt(lcurve_path, usecols=3)\n            }\n\n    def plot_lcurve(self, iteration: int, model=0, **kwargs):\n        lcurve_data = self.load_lcurve(iteration=iteration, model=model)\n\n        canvas_style(**kwargs)\n        fig, axs = plt.subplots(2, 1)\n\n        # energy figure\n        step = lcurve_data['step']\n        for key in lcurve_data.keys():\n            if key.startswith('energy_'):\n                axs[0].plot(step[10:], lcurve_data[key][10:],\n                            alpha=0.4, label=key.replace('energy_', ''))\n        axs[0].axhline(0.005, linestyle='dashed', color='red', label='5 meV')\n        axs[0].axhline(0.01, linestyle='dashed', color='blue', label='10 meV')\n        axs[0].axhline(0.05, linestyle='dashed', label='50 meV')\n        axs[0].set_xlabel('Number of training batch')\n        axs[0].set_ylabel('$E$(eV)')\n        axs[0].legend()\n\n        # force figure\n        for key in lcurve_data.keys():\n            if key.startswith('force_'):\n                axs[1].plot(\n                    step[10:], lcurve_data[key][10:], label=key.replace('force_', '')\n                )\n        axs[1].axhline(0.05, linestyle='dashed', color='red', label='50 meV/\u00c5')\n        axs[1].axhline(0.1, linestyle='dashed', color='blue', label='100 meV/\u00c5')\n        axs[1].axhline(0.2, linestyle='dashed', label='200 meV/\u00c5')\n        axs[1].set_xlabel('Number of training batch')\n        axs[1].set_ylabel('$F$(eV/\u00c5)')\n        axs[1].legend()\n\n        return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/","title":"dpgen","text":""},{"location":"reference/catflow/tesla/dpgen/exploration/","title":"exploration","text":""},{"location":"reference/catflow/tesla/dpgen/exploration/#catflow.tesla.dpgen.exploration.DPExplorationAnalyzer","title":"<code>DPExplorationAnalyzer</code>","text":"<p>             Bases: <code>ExplorationAnalyzer</code>, <code>DPAnalyzer</code></p> <p>Analyzer for DP exploration tasks.</p> Source code in <code>catflow/tesla/dpgen/exploration.py</code> <pre><code>class DPExplorationAnalyzer(ExplorationAnalyzer, DPAnalyzer):\n    \"\"\"Analyzer for DP exploration tasks.\"\"\"\n\n    def _iteration_tasks(self, iteration) -&gt; List[Path]:\n        n_iter = self._iteration_dir(control_step=2, iteration=iteration)\n        return list((self.dp_task.path / n_iter).glob('01.model_devi/task*'))\n\n    def load_task_job_dict(self, task: Path):\n        # load job config\n        try:\n            with open(task / 'job.json', 'r') as f:\n                job_dict = json.load(f)\n        except Exception as err:\n            logger.error(err)\n            job_dict = {}\n        return job_dict\n\n    def get_cur_job(self, iteration: Optional[int] = None) -&gt; dict:\n        \"\"\"Get `cur_job.json` for the selected iteration\n\n        Args:\n            iteration (int, optional): the iteration to get\n\n        Returns:\n            dict: current job parameters\n        \"\"\"\n        n_iter = self._iteration_dir(control_step=2, iteration=iteration)\n        try:\n            with open(\n                self.dp_task.path / n_iter / '01.model_devi' / 'cur_job.json',\n                'r'\n            ) as f:\n                job_dict = json.load(f)\n        except Exception as err:\n            logger.warning(err)\n            job_dict = {}\n        return job_dict\n\n    def _read_model_devi_trust_level(\n        self,\n        trust_level_key,\n        iteration: Optional[int] = None\n    ):\n        cur_job = self.get_cur_job(iteration)\n        trust_level = cur_job.get(trust_level_key)\n        if trust_level is None:\n            trust_level = self.dp_task.param_data[trust_level_key]\n        # Is average OK for different systems?\n        if isinstance(trust_level, Iterable):\n            trust_level = np.mean(trust_level)  # type: ignore\n        return trust_level\n\n    def plot_single_iteration(\n        self,\n        iteration: Optional[int] = None,\n        *,\n        x_limit: Optional[Union[float, List[float]]] = None,\n        y_limit: Optional[Union[float, List[float]]] = None,\n        use_log: bool = False,\n        group_by: Optional[str] = None,\n        f_trust_lo: Optional[float] = None,\n        f_trust_hi: Optional[float] = None,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        **kwargs\n    ) -&gt; Figure:\n        \"\"\"Generate a plot of model deviation in each iteration.\n\n        Args:\n            iteration (int, optional): The iteration. Defaults to current iteration.\n            x_limit (float, List[float], optional): Choose the limit of x axis. Defaults to None.\n            y_limit (float, List[float], optional): Choose the limit of y axis. Defaults to None.\n            use_log (bool, optional): Choose whether log scale used. Defaults to False.\n            group_by (str, optional): Choose which the plots are grouped by, which should be included. \n                Should be corresponding to keys in model_devi_job. Defaults to 'temps'.\n            select (str, optional): Choose which param selected as plot zone. Defaults to None.\n            select_value (str, optional): The dependence of `select`. \n                Different from `group_by`, please pass only one number. Defaults to None.\n            kwargs (_type_, optional): Additional keyword arguments. Include other params, such as:\n                `temps`: please use the value of `group_by`, whose default input is `\"temps\"`.\n                `label_unit`: the unit of `select_value`, such as '\u00c5'.\n                Parameters of `canvas_style`: please refer to `catflow.graph.plotting.canvas_style`.\n\n        Returns:\n            Figure: A plot for different desired values.\n        \"\"\"\n        if f_trust_hi is None:\n            f_trust_hi = self._read_model_devi_trust_level(\n                \"model_devi_f_trust_hi\", iteration)\n        if f_trust_lo is None:\n            f_trust_lo = self._read_model_devi_trust_level(\n                \"model_devi_f_trust_lo\", iteration)\n        if iteration is None:\n            iteration = self.dp_task.iteration\n\n        fig = super().plot_single_iteration(\n            iteration,\n            x_limit=x_limit,\n            y_limit=y_limit,\n            use_log=use_log,\n            group_by=group_by,\n            f_trust_lo=f_trust_lo,\n            f_trust_hi=f_trust_hi,\n            select=select,\n            select_value=select_value,\n            **kwargs\n        )\n        return fig\n\n    def plot_multi_iter_distribution(\n            self,\n            iterations: Iterable,\n            group_by: Optional[str] = None,\n            f_trust_lo: Optional[float] = None,\n            f_trust_hi: Optional[float] = None,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            x_limit: Optional[Union[float, List[float]]] = None,\n            y_limit: Optional[Union[float, List[float]]] = None,\n            **kwargs\n    ) -&gt; Figure:\n        \"\"\"Draw distribution in histogram of model deviation for multiple iterations.\n\n        Args:\n            iterations (Iterable): _description_\n            group_by (str, optional): _description_. Defaults to None.\n            select (str, optional): _description_. Defaults to None.\n            select_value (str, optional): _description_. Defaults to None.\n            f_trust_lo (Optional[float], optional): The lower limit of max_deviation_force. Defaults to None.\n            f_trust_hi (Optional[float], optional): The higher limit of max_deviation_force. Defaults to None.\n            x_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n            y_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n\n        Returns:\n            Figure: A figure containing distribution of model deviation for multiple iterations.\n        \"\"\"\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n        label_unit = kwargs.get('label_unit', 'K')\n\n        canvas_style(**kwargs)\n\n        nrows = square_grid(num_item)\n        fig, axs = plt.subplots(nrows, nrows, figsize=[\n                                12, 12], constrained_layout=True)\n\n        colors = plt.colormaps['viridis_r'](  # type: ignore\n            np.linspace(0.15, 0.85, len(iterations))  # type: ignore\n        )\n        for i, plot_item in enumerate(plot_items):\n            try:\n                ax = axs.flatten()[i]\n            except AttributeError:\n                ax = axs\n            for j, iteration in enumerate(iterations):\n                step, mdf = self._data_prepareation(\n                    plot_item, iteration, group_by, select, select_value, **kwargs)\n                if f_trust_lo is None:\n                    f_trust_lo = self._read_model_devi_trust_level(\n                        \"model_devi_f_trust_lo\", iteration)\n                if f_trust_hi is None:\n                    f_trust_hi = self._read_model_devi_trust_level(\n                        \"model_devi_f_trust_hi\", iteration)\n                ax_args = {\n                    'data': mdf,\n                    'plot_item': plot_item,\n                    'label_unit': kwargs.get('label_unit'),\n                    'f_trust_lo': f_trust_lo,\n                    'f_trust_hi': f_trust_hi,\n                    'iteration': iteration,\n                    'x_limit': x_limit,\n                    'y_limit': y_limit,\n                    'color': colors[j],\n                    'label': f'Iter {iteration}'\n                }\n                PlottingExploartion.plot_mdf_distribution(\n                    ax, ax_args, orientation='vertical')  # type: ignore\n            ax.set_ylabel('Distribution')  # type: ignore\n            ax.set_xlabel(r'$\\sigma_{f}^{max}$ (ev/\u00c5)')  # type: ignore\n            ax.legend()  # type: ignore\n        for i in range(num_item, nrows * nrows):\n            try:\n                fig.delaxes(axs.flatten()[i])\n            except AttributeError:\n                pass\n        return fig\n\n    def plot_ensemble_ratio_bar(\n            self,\n            iterations: Iterable,\n            group_by: Optional[str] = None,\n            select: Optional[str] = None,\n            select_value: Optional[str] = None,\n            f_trust_lo: Optional[float] = None,\n            f_trust_hi: Optional[float] = None,\n            **kwargs\n    ) -&gt; Figure:\n        \"\"\"Draw ensemble ratio bar for multiple iterations.\n\n        Args:\n            iterations (Iterable): _description_\n            group_by (Optional[str], optional): _description_. Defaults to None.\n            select (Optional[str], optional): _description_. Defaults to None.\n            select_value (Optional[str], optional): _description_. Defaults to None.\n            f_trust_lo (Optional[float], optional): _description_. Defaults to None.\n            f_trust_hi (Optional[float], optional): _description_. Defaults to None.\n\n        Returns:\n            Figure: _description_\n        \"\"\"\n\n        num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n        nrows = square_grid(num_item)\n\n        canvas_style(**kwargs)\n\n        fig, axs = plt.subplots(nrows, nrows)\n        for i, plot_item in enumerate(plot_items):\n            if type(axs) is plt.Axes:\n                ax = axs\n            else:\n                ax = axs.flatten()[i]  # type: ignore\n\n            ratios = np.zeros((len(iterations), 3))  # type: ignore\n\n            for j, iteration in enumerate(iterations):\n                df = self._load_model_devi_dataframe(\n                    plot_item, iteration, group_by, select, select_value, **kwargs)\n\n                if f_trust_lo is None:\n                    f_trust_lo = self._read_model_devi_trust_level(\n                        \"model_devi_f_trust_lo\", iteration)\n                if f_trust_hi is None:\n                    f_trust_hi = self._read_model_devi_trust_level(\n                        \"model_devi_f_trust_hi\", iteration)\n\n                accu_count = (df['max_devi_f'] &lt;= f_trust_lo).sum()\n                failed_count = (df['max_devi_f'] &gt; f_trust_hi).sum()\n                candidate_count = (\n                    (df['max_devi_f'] &gt; f_trust_lo) &amp;\n                    (df['max_devi_f'] &lt;= f_trust_hi)\n                ).sum()\n\n                all_count = accu_count + failed_count + candidate_count\n                count_array = np.array(\n                    [accu_count, candidate_count, failed_count])\n                ratios[j] = count_array / all_count\n\n            ax_args = {\n                'category_names': ['Accurate', 'Candidate', 'Failed'],\n                'ratios': ratios,\n                'iterations': iterations,\n            }\n            PlottingExploartion.plot_ensemble_ratio_bar(ax, ax_args)\n            handles, labels = ax.get_legend_handles_labels()\n        fig.supxlabel('Iteration')\n        fig.supylabel('Ratio')\n        fig.legend(handles, labels, loc='upper center',  # type: ignore\n                   ncol=3, bbox_to_anchor=(0.5, 1.0))\n        return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/exploration/#catflow.tesla.dpgen.exploration.DPExplorationAnalyzer.get_cur_job","title":"<code>get_cur_job(iteration=None)</code>","text":"<p>Get <code>cur_job.json</code> for the selected iteration</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>the iteration to get</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>current job parameters</p> Source code in <code>catflow/tesla/dpgen/exploration.py</code> <pre><code>def get_cur_job(self, iteration: Optional[int] = None) -&gt; dict:\n    \"\"\"Get `cur_job.json` for the selected iteration\n\n    Args:\n        iteration (int, optional): the iteration to get\n\n    Returns:\n        dict: current job parameters\n    \"\"\"\n    n_iter = self._iteration_dir(control_step=2, iteration=iteration)\n    try:\n        with open(\n            self.dp_task.path / n_iter / '01.model_devi' / 'cur_job.json',\n            'r'\n        ) as f:\n            job_dict = json.load(f)\n    except Exception as err:\n        logger.warning(err)\n        job_dict = {}\n    return job_dict\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/exploration/#catflow.tesla.dpgen.exploration.DPExplorationAnalyzer.plot_ensemble_ratio_bar","title":"<code>plot_ensemble_ratio_bar(iterations, group_by=None, select=None, select_value=None, f_trust_lo=None, f_trust_hi=None, **kwargs)</code>","text":"<p>Draw ensemble ratio bar for multiple iterations.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>Iterable</code> <p>description</p> required <code>group_by</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>select</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>Optional[str]</code> <p>description. Defaults to None.</p> <code>None</code> <code>f_trust_lo</code> <code>Optional[float]</code> <p>description. Defaults to None.</p> <code>None</code> <code>f_trust_hi</code> <code>Optional[float]</code> <p>description. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>description</p> Source code in <code>catflow/tesla/dpgen/exploration.py</code> <pre><code>def plot_ensemble_ratio_bar(\n        self,\n        iterations: Iterable,\n        group_by: Optional[str] = None,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        f_trust_lo: Optional[float] = None,\n        f_trust_hi: Optional[float] = None,\n        **kwargs\n) -&gt; Figure:\n    \"\"\"Draw ensemble ratio bar for multiple iterations.\n\n    Args:\n        iterations (Iterable): _description_\n        group_by (Optional[str], optional): _description_. Defaults to None.\n        select (Optional[str], optional): _description_. Defaults to None.\n        select_value (Optional[str], optional): _description_. Defaults to None.\n        f_trust_lo (Optional[float], optional): _description_. Defaults to None.\n        f_trust_hi (Optional[float], optional): _description_. Defaults to None.\n\n    Returns:\n        Figure: _description_\n    \"\"\"\n\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n    nrows = square_grid(num_item)\n\n    canvas_style(**kwargs)\n\n    fig, axs = plt.subplots(nrows, nrows)\n    for i, plot_item in enumerate(plot_items):\n        if type(axs) is plt.Axes:\n            ax = axs\n        else:\n            ax = axs.flatten()[i]  # type: ignore\n\n        ratios = np.zeros((len(iterations), 3))  # type: ignore\n\n        for j, iteration in enumerate(iterations):\n            df = self._load_model_devi_dataframe(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n\n            if f_trust_lo is None:\n                f_trust_lo = self._read_model_devi_trust_level(\n                    \"model_devi_f_trust_lo\", iteration)\n            if f_trust_hi is None:\n                f_trust_hi = self._read_model_devi_trust_level(\n                    \"model_devi_f_trust_hi\", iteration)\n\n            accu_count = (df['max_devi_f'] &lt;= f_trust_lo).sum()\n            failed_count = (df['max_devi_f'] &gt; f_trust_hi).sum()\n            candidate_count = (\n                (df['max_devi_f'] &gt; f_trust_lo) &amp;\n                (df['max_devi_f'] &lt;= f_trust_hi)\n            ).sum()\n\n            all_count = accu_count + failed_count + candidate_count\n            count_array = np.array(\n                [accu_count, candidate_count, failed_count])\n            ratios[j] = count_array / all_count\n\n        ax_args = {\n            'category_names': ['Accurate', 'Candidate', 'Failed'],\n            'ratios': ratios,\n            'iterations': iterations,\n        }\n        PlottingExploartion.plot_ensemble_ratio_bar(ax, ax_args)\n        handles, labels = ax.get_legend_handles_labels()\n    fig.supxlabel('Iteration')\n    fig.supylabel('Ratio')\n    fig.legend(handles, labels, loc='upper center',  # type: ignore\n               ncol=3, bbox_to_anchor=(0.5, 1.0))\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/exploration/#catflow.tesla.dpgen.exploration.DPExplorationAnalyzer.plot_multi_iter_distribution","title":"<code>plot_multi_iter_distribution(iterations, group_by=None, f_trust_lo=None, f_trust_hi=None, select=None, select_value=None, x_limit=None, y_limit=None, **kwargs)</code>","text":"<p>Draw distribution in histogram of model deviation for multiple iterations.</p> <p>Parameters:</p> Name Type Description Default <code>iterations</code> <code>Iterable</code> <p>description</p> required <code>group_by</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>select</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>str</code> <p>description. Defaults to None.</p> <code>None</code> <code>f_trust_lo</code> <code>Optional[float]</code> <p>The lower limit of max_deviation_force. Defaults to None.</p> <code>None</code> <code>f_trust_hi</code> <code>Optional[float]</code> <p>The higher limit of max_deviation_force. Defaults to None.</p> <code>None</code> <code>x_limit</code> <code>Union[float, List[float]]</code> <p>description. Defaults to None.</p> <code>None</code> <code>y_limit</code> <code>Union[float, List[float]]</code> <p>description. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>A figure containing distribution of model deviation for multiple iterations.</p> Source code in <code>catflow/tesla/dpgen/exploration.py</code> <pre><code>def plot_multi_iter_distribution(\n        self,\n        iterations: Iterable,\n        group_by: Optional[str] = None,\n        f_trust_lo: Optional[float] = None,\n        f_trust_hi: Optional[float] = None,\n        select: Optional[str] = None,\n        select_value: Optional[str] = None,\n        x_limit: Optional[Union[float, List[float]]] = None,\n        y_limit: Optional[Union[float, List[float]]] = None,\n        **kwargs\n) -&gt; Figure:\n    \"\"\"Draw distribution in histogram of model deviation for multiple iterations.\n\n    Args:\n        iterations (Iterable): _description_\n        group_by (str, optional): _description_. Defaults to None.\n        select (str, optional): _description_. Defaults to None.\n        select_value (str, optional): _description_. Defaults to None.\n        f_trust_lo (Optional[float], optional): The lower limit of max_deviation_force. Defaults to None.\n        f_trust_hi (Optional[float], optional): The higher limit of max_deviation_force. Defaults to None.\n        x_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n        y_limit (Union[float, List[float]], optional): _description_. Defaults to None.\n\n    Returns:\n        Figure: A figure containing distribution of model deviation for multiple iterations.\n    \"\"\"\n    num_item, plot_items = self._convert_group_by(group_by, **kwargs)\n    label_unit = kwargs.get('label_unit', 'K')\n\n    canvas_style(**kwargs)\n\n    nrows = square_grid(num_item)\n    fig, axs = plt.subplots(nrows, nrows, figsize=[\n                            12, 12], constrained_layout=True)\n\n    colors = plt.colormaps['viridis_r'](  # type: ignore\n        np.linspace(0.15, 0.85, len(iterations))  # type: ignore\n    )\n    for i, plot_item in enumerate(plot_items):\n        try:\n            ax = axs.flatten()[i]\n        except AttributeError:\n            ax = axs\n        for j, iteration in enumerate(iterations):\n            step, mdf = self._data_prepareation(\n                plot_item, iteration, group_by, select, select_value, **kwargs)\n            if f_trust_lo is None:\n                f_trust_lo = self._read_model_devi_trust_level(\n                    \"model_devi_f_trust_lo\", iteration)\n            if f_trust_hi is None:\n                f_trust_hi = self._read_model_devi_trust_level(\n                    \"model_devi_f_trust_hi\", iteration)\n            ax_args = {\n                'data': mdf,\n                'plot_item': plot_item,\n                'label_unit': kwargs.get('label_unit'),\n                'f_trust_lo': f_trust_lo,\n                'f_trust_hi': f_trust_hi,\n                'iteration': iteration,\n                'x_limit': x_limit,\n                'y_limit': y_limit,\n                'color': colors[j],\n                'label': f'Iter {iteration}'\n            }\n            PlottingExploartion.plot_mdf_distribution(\n                ax, ax_args, orientation='vertical')  # type: ignore\n        ax.set_ylabel('Distribution')  # type: ignore\n        ax.set_xlabel(r'$\\sigma_{f}^{max}$ (ev/\u00c5)')  # type: ignore\n        ax.legend()  # type: ignore\n    for i in range(num_item, nrows * nrows):\n        try:\n            fig.delaxes(axs.flatten()[i])\n        except AttributeError:\n            pass\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/exploration/#catflow.tesla.dpgen.exploration.DPExplorationAnalyzer.plot_single_iteration","title":"<code>plot_single_iteration(iteration=None, *, x_limit=None, y_limit=None, use_log=False, group_by=None, f_trust_lo=None, f_trust_hi=None, select=None, select_value=None, **kwargs)</code>","text":"<p>Generate a plot of model deviation in each iteration.</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>The iteration. Defaults to current iteration.</p> <code>None</code> <code>x_limit</code> <code>(float, List[float])</code> <p>Choose the limit of x axis. Defaults to None.</p> <code>None</code> <code>y_limit</code> <code>(float, List[float])</code> <p>Choose the limit of y axis. Defaults to None.</p> <code>None</code> <code>use_log</code> <code>bool</code> <p>Choose whether log scale used. Defaults to False.</p> <code>False</code> <code>group_by</code> <code>str</code> <p>Choose which the plots are grouped by, which should be included.  Should be corresponding to keys in model_devi_job. Defaults to 'temps'.</p> <code>None</code> <code>select</code> <code>str</code> <p>Choose which param selected as plot zone. Defaults to None.</p> <code>None</code> <code>select_value</code> <code>str</code> <p>The dependence of <code>select</code>.  Different from <code>group_by</code>, please pass only one number. Defaults to None.</p> <code>None</code> <code>kwargs</code> <code>_type_</code> <p>Additional keyword arguments. Include other params, such as: <code>temps</code>: please use the value of <code>group_by</code>, whose default input is <code>\"temps\"</code>. <code>label_unit</code>: the unit of <code>select_value</code>, such as '\u00c5'. Parameters of <code>canvas_style</code>: please refer to <code>catflow.graph.plotting.canvas_style</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>A plot for different desired values.</p> Source code in <code>catflow/tesla/dpgen/exploration.py</code> <pre><code>def plot_single_iteration(\n    self,\n    iteration: Optional[int] = None,\n    *,\n    x_limit: Optional[Union[float, List[float]]] = None,\n    y_limit: Optional[Union[float, List[float]]] = None,\n    use_log: bool = False,\n    group_by: Optional[str] = None,\n    f_trust_lo: Optional[float] = None,\n    f_trust_hi: Optional[float] = None,\n    select: Optional[str] = None,\n    select_value: Optional[str] = None,\n    **kwargs\n) -&gt; Figure:\n    \"\"\"Generate a plot of model deviation in each iteration.\n\n    Args:\n        iteration (int, optional): The iteration. Defaults to current iteration.\n        x_limit (float, List[float], optional): Choose the limit of x axis. Defaults to None.\n        y_limit (float, List[float], optional): Choose the limit of y axis. Defaults to None.\n        use_log (bool, optional): Choose whether log scale used. Defaults to False.\n        group_by (str, optional): Choose which the plots are grouped by, which should be included. \n            Should be corresponding to keys in model_devi_job. Defaults to 'temps'.\n        select (str, optional): Choose which param selected as plot zone. Defaults to None.\n        select_value (str, optional): The dependence of `select`. \n            Different from `group_by`, please pass only one number. Defaults to None.\n        kwargs (_type_, optional): Additional keyword arguments. Include other params, such as:\n            `temps`: please use the value of `group_by`, whose default input is `\"temps\"`.\n            `label_unit`: the unit of `select_value`, such as '\u00c5'.\n            Parameters of `canvas_style`: please refer to `catflow.graph.plotting.canvas_style`.\n\n    Returns:\n        Figure: A plot for different desired values.\n    \"\"\"\n    if f_trust_hi is None:\n        f_trust_hi = self._read_model_devi_trust_level(\n            \"model_devi_f_trust_hi\", iteration)\n    if f_trust_lo is None:\n        f_trust_lo = self._read_model_devi_trust_level(\n            \"model_devi_f_trust_lo\", iteration)\n    if iteration is None:\n        iteration = self.dp_task.iteration\n\n    fig = super().plot_single_iteration(\n        iteration,\n        x_limit=x_limit,\n        y_limit=y_limit,\n        use_log=use_log,\n        group_by=group_by,\n        f_trust_lo=f_trust_lo,\n        f_trust_hi=f_trust_hi,\n        select=select,\n        select_value=select_value,\n        **kwargs\n    )\n    return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/labeling/","title":"labeling","text":""},{"location":"reference/catflow/tesla/dpgen/task/","title":"task","text":""},{"location":"reference/catflow/tesla/dpgen/task/#catflow.tesla.dpgen.task.DPAnalyzer","title":"<code>DPAnalyzer</code>","text":"<p>             Bases: <code>BaseAnalyzer</code></p> <p>Base class to be implemented as analyzer for <code>DPTask</code></p> Source code in <code>catflow/tesla/dpgen/task.py</code> <pre><code>class DPAnalyzer(BaseAnalyzer):\n    \"\"\"Base class to be implemented as analyzer for `DPTask`\n    \"\"\"\n\n    def __init__(self, dp_task: DPTask, **kwargs) -&gt; None:\n        super().__init__(dp_task)\n        if type(self.dp_task) is not DPTask:\n            self.dp_task = DPTask.from_dict(**self.dp_task.__dict__, **kwargs)\n\n    def _iteration_control_code(\n        self,\n        control_step: int,\n        iteration: Optional[int] = None\n    ):\n        if iteration is None:\n            if self.dp_task.step_code &lt; control_step:\n                iteration = self.dp_task.iteration - 1\n            else:\n                iteration = self.dp_task.iteration\n        return iteration\n\n    def _iteration_dir(self, **kwargs):\n        control_step = kwargs.get('control_step', 2)\n        iteration = self._iteration_control_code(\n            control_step=control_step,\n            iteration=kwargs.get('iteration')\n        )\n        return 'iter.' + str(iteration).zfill(6)\n\n    @classmethod\n    def setup_task(cls, **kwargs):\n        task = DPTask(**kwargs)\n        return cls(task)\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/task/#catflow.tesla.dpgen.task.DPTask","title":"<code>DPTask</code>","text":"<p>             Bases: <code>BaseTask</code></p> <p>DPTask is a class reading a DP-GEN directory, where the DP-GEN task run.</p> Source code in <code>catflow/tesla/dpgen/task.py</code> <pre><code>class DPTask(BaseTask):\n    \"\"\"DPTask is a class reading a DP-GEN directory, where the DP-GEN task run.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        param_file: str = 'param.json',\n        machine_file: str = 'machine.json',\n        record_file: str = 'record.dpgen'\n    ) -&gt; None:\n        \"\"\"Generate a class of tesla task.\n\n        Args:\n            path (str): The path of the tesla task.\n            param_file (str): The param json file name.\n            machine_file (str): The machine json file name.\n            record_file (str): The record file name.\n            deepmd_version (str): DeepMD-kit version used. Default: 2.0.\n        \"\"\"\n        super().__init__(path)\n\n        self.param_file = param_file\n        self.machine_file = machine_file\n        self.record_file = record_file\n        self._load_task()\n\n    def _load_task(self):\n        \"\"\"set properties for instance.\n        \"\"\"\n        self._read_record()\n        self._read_param_data()\n        self._read_machine_data()\n        if self.step_code in [0, 3, 6]:\n            self.state = 'Waiting'\n        elif self.step_code in [1, 4, 7]:\n            self.state = 'Parsing'\n        else:\n            self.state = 'Stopped'\n        if self.step_code &lt; 3:\n            self.step = 'Training'\n        elif self.step_code &lt; 6:\n            self.step = 'Exploring'\n        else:\n            self.step = 'Labeling'\n\n    def _read_record(self):\n        import numpy as np\n        _record_path = self.path / self.record_file\n        steps = np.loadtxt(_record_path)\n        if steps.shape == (2,):\n            # support miko-tasker like record\n            self.iteration = int(steps[0])\n            self.step_code = int(steps[1])\n        else:\n            self.iteration = int(steps[-1][0])\n            self.step_code = int(steps[-1][1])\n\n    def _read_param_data(self):\n        _param_path = self.path / self.param_file\n        with open(_param_path) as f:\n            self.param_data = json.load(f)\n\n    def _read_machine_data(self):\n        _param_path = self.path / self.machine_file\n        with open(_param_path) as f:\n            self.machine_data = json.load(f)\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/task/#catflow.tesla.dpgen.task.DPTask.__init__","title":"<code>__init__(path, param_file='param.json', machine_file='machine.json', record_file='record.dpgen')</code>","text":"<p>Generate a class of tesla task.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path of the tesla task.</p> required <code>param_file</code> <code>str</code> <p>The param json file name.</p> <code>'param.json'</code> <code>machine_file</code> <code>str</code> <p>The machine json file name.</p> <code>'machine.json'</code> <code>record_file</code> <code>str</code> <p>The record file name.</p> <code>'record.dpgen'</code> <code>deepmd_version</code> <code>str</code> <p>DeepMD-kit version used. Default: 2.0.</p> required Source code in <code>catflow/tesla/dpgen/task.py</code> <pre><code>def __init__(\n    self,\n    path: str,\n    param_file: str = 'param.json',\n    machine_file: str = 'machine.json',\n    record_file: str = 'record.dpgen'\n) -&gt; None:\n    \"\"\"Generate a class of tesla task.\n\n    Args:\n        path (str): The path of the tesla task.\n        param_file (str): The param json file name.\n        machine_file (str): The machine json file name.\n        record_file (str): The record file name.\n        deepmd_version (str): DeepMD-kit version used. Default: 2.0.\n    \"\"\"\n    super().__init__(path)\n\n    self.param_file = param_file\n    self.machine_file = machine_file\n    self.record_file = record_file\n    self._load_task()\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/training/","title":"training","text":""},{"location":"reference/catflow/tesla/dpgen/training/#catflow.tesla.dpgen.training.DPTrainingAnalyzer","title":"<code>DPTrainingAnalyzer</code>","text":"<p>             Bases: <code>TrainingAnalyzer</code>, <code>DPAnalyzer</code></p> <p>Analyzer for training tasks.</p> Source code in <code>catflow/tesla/dpgen/training.py</code> <pre><code>class DPTrainingAnalyzer(TrainingAnalyzer, DPAnalyzer):\n    \"\"\"Analyzer for training tasks.\n    \"\"\"\n\n    def get_lcurve_path(self, iteration: int, model=0) -&gt; Path:\n        _iteration_dir = self._iteration_dir(iteration=iteration)\n        lcurve_path = self.dp_task.path / _iteration_dir / \\\n            f'00.train/{str(model).zfill(3)}/lcurve.out'\n        return lcurve_path\n\n    def load_lcurve(self, iteration: int, model=0):\n        lcurve_path = self.get_lcurve_path(iteration=iteration, model=model)\n\n        if self.validation is True:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=4),\n                'energy_test': np.loadtxt(lcurve_path, usecols=3),\n                'force_train': np.loadtxt(lcurve_path, usecols=6),\n                'force_test': np.loadtxt(lcurve_path, usecols=5),\n            }\n        else:\n            return {\n                'step': np.loadtxt(lcurve_path, usecols=0),\n                'energy_train': np.loadtxt(lcurve_path, usecols=2),\n                'force_train': np.loadtxt(lcurve_path, usecols=3)\n            }\n\n    def plot_lcurve(self, iteration: Optional[int] = None, model=0, **kwargs):\n        \"\"\"plot learning curve of the training task\n\n        Args:\n            iteration (int): Iteration of the training task\n            model (int, optional): Index of trained model. Defaults to 0.\n\n        Returns:\n            fig: plt.figure\n        \"\"\"\n        if iteration is None:\n            iteration = self._iteration_control_code(\n                control_step=2, iteration=self.dp_task.iteration\n            )\n\n        fig = super().plot_lcurve(iteration=iteration, model=model, **kwargs)\n\n        return fig\n</code></pre>"},{"location":"reference/catflow/tesla/dpgen/training/#catflow.tesla.dpgen.training.DPTrainingAnalyzer.plot_lcurve","title":"<code>plot_lcurve(iteration=None, model=0, **kwargs)</code>","text":"<p>plot learning curve of the training task</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>Iteration of the training task</p> <code>None</code> <code>model</code> <code>int</code> <p>Index of trained model. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>fig</code> <p>plt.figure</p> Source code in <code>catflow/tesla/dpgen/training.py</code> <pre><code>def plot_lcurve(self, iteration: Optional[int] = None, model=0, **kwargs):\n    \"\"\"plot learning curve of the training task\n\n    Args:\n        iteration (int): Iteration of the training task\n        model (int, optional): Index of trained model. Defaults to 0.\n\n    Returns:\n        fig: plt.figure\n    \"\"\"\n    if iteration is None:\n        iteration = self._iteration_control_code(\n            control_step=2, iteration=self.dp_task.iteration\n        )\n\n    fig = super().plot_lcurve(iteration=iteration, model=model, **kwargs)\n\n    return fig\n</code></pre>"},{"location":"reference/catflow/utils/","title":"utils","text":""},{"location":"reference/catflow/utils/files/","title":"files","text":""},{"location":"reference/catflow/utils/lammps/","title":"lammps","text":""},{"location":"reference/catflow/utils/log_factory/","title":"log_factory","text":""},{"location":"reference/catflow/utils/log_factory/#catflow.utils.log_factory.LogFactory","title":"<code>LogFactory</code>","text":"<p>             Bases: <code>object</code></p> <p>For logging</p> Source code in <code>catflow/utils/log_factory.py</code> <pre><code>class LogFactory(object):\n    \"\"\"\n    For logging\n    \"\"\"\n    def __init__(self, logger=None, log_dir=None, log_name=\"catflow.log\"):\n        self.log_path = Path.cwd() if log_dir is None else Path(log_dir)\n        self.logger = logging.getLogger(logger)\n        self.logger.setLevel(logging.DEBUG)\n        self.log_name = self.log_path / log_name\n\n        # create file handler which logs even debug messages\n        file_handler = logging.FileHandler(self.log_name, delay=True)\n        file_handler.setLevel(logging.DEBUG)\n        # create console handler with a higher log level\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.INFO)\n\n        formatter = logging.Formatter('%(asctime)s - %(levelname)s : %(message)s')\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n        self.logger.addHandler(file_handler)\n        self.logger.addHandler(console_handler)\n\n    def get_log(self):\n        return self.logger\n</code></pre>"},{"location":"reference/catflow/utils/output/","title":"output","text":""}]}